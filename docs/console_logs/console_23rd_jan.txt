Tested incomplete 100M v3 trainng model (on 20/30 epochs)

Last login: Wed Jan 21 10:23:23 on ttys000
chaitanyakartik@Chaitanyas-MacBook-Air:~ $ ssh ubuntu@47.29.24.119

Authorized uses only. All activity may be monitored and reported.
Welcome to Ubuntu 22.04.5 LTS (GNU/Linux 5.15.0-144-generic x86_64)

 * Documentation:  https://help.ubuntu.com
 * Management:     https://landscape.canonical.com
 * Support:        https://ubuntu.com/pro

 System information as of Thu Jan 22 07:22:52 PM IST 2026

  System load:    0.0               Processes:               295
  Usage of /home: 43.7% of 4.99GB   Users logged in:         0
  Memory usage:   4%                IPv4 address for enp3s0: 10.0.0.234
  Swap usage:     0%

 * Strictly confined Kubernetes makes edge and IoT secure. Learn how MicroK8s
   just raised the bar for easy, resilient and secure K8s cluster deployment.

   https://ubuntu.com/engage/secure-kubernetes-at-the-edge

Expanded Security Maintenance for Applications is not enabled.

97 updates can be applied immediately.
75 of these updates are standard security updates.
To see these additional updates run: apt list --upgradable

Enable ESM Apps to receive additional future security updates.
See https://ubuntu.com/esm or run: sudo pro status


The list of available updates is more than a week old.
To check for new updates run: sudo apt update
New release '24.04.3 LTS' available.
Run 'do-release-upgrade' to upgrade to it.


Authorized uses only. All activity may be monitored and reported.
Last login: Thu Jan 22 15:48:22 2026 from 14.139.34.155
ubuntu@bh-01:~$ ssh neurodx@10.0.0.147
Authorized uses only. All activity may be monitored and reported.
neurodx@10.0.0.147's password: 
Welcome to Ubuntu 24.04.2 LTS (GNU/Linux 6.8.0-56-generic x86_64)

 * Documentation:  https://help.ubuntu.com
 * Management:     https://landscape.canonical.com
 * Support:        https://ubuntu.com/pro

 System information as of Thu Jan 22 07:22:59 PM IST 2026

  System load:    0.79              Processes:               872
  Usage of /home: 55.8% of 4.94GB   Users logged in:         1
  Memory usage:   4%                IPv4 address for enp3s0: 10.0.0.147
  Swap usage:     0%

  => /var/log/audit is using 100.0% of 4.94GB

 * Strictly confined Kubernetes makes edge and IoT secure. Learn how MicroK8s
   just raised the bar for easy, resilient and secure K8s cluster deployment.

   https://ubuntu.com/engage/secure-kubernetes-at-the-edge

Expanded Security Maintenance for Applications is not enabled.

234 updates can be applied immediately.
139 of these updates are standard security updates.
To see these additional updates run: apt list --upgradable

13 additional security updates can be applied with ESM Apps.
Learn more about enabling ESM Apps service at https://ubuntu.com/esm


Last login: Thu Jan 22 09:52:09 2026 from 10.0.0.234

(base) neurodx@h200-nvl-2x:~$ 
(base) neurodx@h200-nvl-2x:~$ sudo su
root@h200-nvl-2x:/home/neurodx# cd /mnt/data
source asr-env/bin/activate 
cd asr-finetuning
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# pip install https://github.com/kpu/kenlm/archive/master.zip
sudo apt-get install -y libboost-all-dev
Collecting https://github.com/kpu/kenlm/archive/master.zip
  Downloading https://github.com/kpu/kenlm/archive/master.zip
     \ 553.6 kB 4.2 MB/s 0:00:00
  Installing build dependencies ... done
  Getting requirements to build wheel ... done
  Preparing metadata (pyproject.toml) ... done
Building wheels for collected packages: kenlm
  Building wheel for kenlm (pyproject.toml) ... done
  Created wheel for kenlm: filename=kenlm-0.2.0-cp312-cp312-linux_x86_64.whl size=3143661 sha256=a4e99eb79fb6e987f8d4bdf4ee384ef3852492a37586e043682086827bcda298
  Stored in directory: /tmp/pip-ephem-wheel-cache-pj21fe7y/wheels/92/c8/12/56d187154e078f0eaa74d059017fc1afe1c4d91fbce02ce8d9
Successfully built kenlm
Installing collected packages: kenlm
Successfully installed kenlm-0.2.0
Reading package lists... Done
Building dependency tree... Done
Reading state information... Done
The following packages were automatically installed and are no longer required:
  libdrm-nouveau2 libdrm-radeon1 libgl1-amber-dri libglapi-mesa libllvm19 libxcb-dri2-0 linux-headers-6.8.0-52 linux-headers-6.8.0-52-generic linux-image-6.8.0-52-generic linux-modules-6.8.0-52-generic
  linux-modules-extra-6.8.0-52-generic linux-tools-6.8.0-52 linux-tools-6.8.0-52-generic
Use 'sudo apt autoremove' to remove them.
The following additional packages will be installed:
  autoconf automake autotools-dev gfortran gfortran-13 gfortran-13-x86-64-linux-gnu gfortran-x86-64-linux-gnu ibverbs-providers icu-devtools libamd-comgr2 libamdhip64-5 libboost-atomic-dev
  libboost-atomic1.83-dev libboost-atomic1.83.0 libboost-chrono-dev libboost-chrono1.83-dev libboost-chrono1.83.0t64 libboost-container-dev libboost-container1.83-dev libboost-container1.83.0
  libboost-context-dev libboost-context1.83-dev libboost-context1.83.0 libboost-coroutine-dev libboost-coroutine1.83-dev libboost-coroutine1.83.0 libboost-date-time-dev libboost-date-time1.83-dev
  libboost-date-time1.83.0 libboost-dev libboost-exception-dev libboost-exception1.83-dev libboost-fiber-dev libboost-fiber1.83-dev libboost-fiber1.83.0 libboost-filesystem-dev libboost-filesystem1.83-dev
  libboost-filesystem1.83.0 libboost-graph-dev libboost-graph-parallel-dev libboost-graph-parallel1.83-dev libboost-graph-parallel1.83.0 libboost-graph1.83-dev libboost-graph1.83.0 libboost-iostreams-dev
  libboost-iostreams1.83-dev libboost-iostreams1.83.0 libboost-json-dev libboost-json1.83-dev libboost-json1.83.0 libboost-locale-dev libboost-locale1.83-dev libboost-locale1.83.0 libboost-log-dev
  libboost-log1.83-dev libboost-log1.83.0 libboost-math-dev libboost-math1.83-dev libboost-math1.83.0 libboost-mpi-dev libboost-mpi-python-dev libboost-mpi-python1.83-dev libboost-mpi-python1.83.0
  libboost-mpi1.83-dev libboost-mpi1.83.0 libboost-nowide-dev libboost-nowide1.83-dev libboost-nowide1.83.0 libboost-numpy-dev libboost-numpy1.83-dev libboost-numpy1.83.0 libboost-program-options-dev
  libboost-program-options1.83-dev libboost-program-options1.83.0 libboost-python-dev libboost-python1.83-dev libboost-python1.83.0 libboost-random-dev libboost-random1.83-dev libboost-random1.83.0
  libboost-regex-dev libboost-regex1.83-dev libboost-regex1.83.0 libboost-serialization-dev libboost-serialization1.83-dev libboost-serialization1.83.0 libboost-stacktrace-dev libboost-stacktrace1.83-dev
  libboost-stacktrace1.83.0 libboost-system-dev libboost-system1.83-dev libboost-system1.83.0 libboost-test-dev libboost-test1.83-dev libboost-test1.83.0 libboost-thread-dev libboost-thread1.83-dev
  libboost-thread1.83.0 libboost-timer-dev libboost-timer1.83-dev libboost-timer1.83.0 libboost-tools-dev libboost-type-erasure-dev libboost-type-erasure1.83-dev libboost-type-erasure1.83.0
  libboost-url-dev libboost-url1.83-dev libboost-url1.83.0 libboost-wave-dev libboost-wave1.83-dev libboost-wave1.83.0 libboost1.83-dev libboost1.83-tools-dev libcaf-openmpi-3t64 libcoarrays-dev
  libcoarrays-openmpi-dev libevent-2.1-7t64 libevent-dev libevent-extra-2.1-7t64 libevent-openssl-2.1-7t64 libevent-pthreads-2.1-7t64 libfabric1 libgfortran-13-dev libhsa-runtime64-1 libhsakmt1
  libhwloc-dev libhwloc-plugins libhwloc15 libibverbs-dev libibverbs1 libicu-dev libjs-jquery-ui libllvm17t64 libltdl-dev libmunge2 libnl-3-dev libnl-route-3-dev libnuma-dev libopenmpi-dev libopenmpi3t64
  libpmix-dev libpmix2t64 libpsm-infinipath1 libpsm2-2 librdmacm1t64 libtool libucx0 m4 mpi-default-bin mpi-default-dev openmpi-bin openmpi-common
Suggested packages:
  autoconf-archive gnu-standards autoconf-doc gettext gfortran-multilib gfortran-doc gfortran-13-multilib gfortran-13-doc libboost-doc graphviz libboost1.83-doc gccxml libboost-contract1.83-dev
  libmpfrc++-dev libntl-dev xsltproc doxygen docbook-xml docbook-xsl default-jdk fop libhwloc-contrib-plugins icu-doc libjs-jquery-ui-docs libtool-doc openmpi-doc gcj-jdk m4-doc
The following NEW packages will be installed:
  autoconf automake autotools-dev gfortran gfortran-13 gfortran-13-x86-64-linux-gnu gfortran-x86-64-linux-gnu icu-devtools libamd-comgr2 libamdhip64-5 libboost-all-dev libboost-atomic-dev
  libboost-atomic1.83-dev libboost-atomic1.83.0 libboost-chrono-dev libboost-chrono1.83-dev libboost-chrono1.83.0t64 libboost-container-dev libboost-container1.83-dev libboost-container1.83.0
  libboost-context-dev libboost-context1.83-dev libboost-context1.83.0 libboost-coroutine-dev libboost-coroutine1.83-dev libboost-coroutine1.83.0 libboost-date-time-dev libboost-date-time1.83-dev
  libboost-date-time1.83.0 libboost-dev libboost-exception-dev libboost-exception1.83-dev libboost-fiber-dev libboost-fiber1.83-dev libboost-fiber1.83.0 libboost-filesystem-dev libboost-filesystem1.83-dev
  libboost-filesystem1.83.0 libboost-graph-dev libboost-graph-parallel-dev libboost-graph-parallel1.83-dev libboost-graph-parallel1.83.0 libboost-graph1.83-dev libboost-graph1.83.0 libboost-iostreams-dev
  libboost-iostreams1.83-dev libboost-iostreams1.83.0 libboost-json-dev libboost-json1.83-dev libboost-json1.83.0 libboost-locale-dev libboost-locale1.83-dev libboost-locale1.83.0 libboost-log-dev
  libboost-log1.83-dev libboost-log1.83.0 libboost-math-dev libboost-math1.83-dev libboost-math1.83.0 libboost-mpi-dev libboost-mpi-python-dev libboost-mpi-python1.83-dev libboost-mpi-python1.83.0
  libboost-mpi1.83-dev libboost-mpi1.83.0 libboost-nowide-dev libboost-nowide1.83-dev libboost-nowide1.83.0 libboost-numpy-dev libboost-numpy1.83-dev libboost-numpy1.83.0 libboost-program-options-dev
  libboost-program-options1.83-dev libboost-program-options1.83.0 libboost-python-dev libboost-python1.83-dev libboost-python1.83.0 libboost-random-dev libboost-random1.83-dev libboost-random1.83.0
  libboost-regex-dev libboost-regex1.83-dev libboost-regex1.83.0 libboost-serialization-dev libboost-serialization1.83-dev libboost-serialization1.83.0 libboost-stacktrace-dev libboost-stacktrace1.83-dev
  libboost-stacktrace1.83.0 libboost-system-dev libboost-system1.83-dev libboost-system1.83.0 libboost-test-dev libboost-test1.83-dev libboost-test1.83.0 libboost-thread-dev libboost-thread1.83-dev
  libboost-thread1.83.0 libboost-timer-dev libboost-timer1.83-dev libboost-timer1.83.0 libboost-tools-dev libboost-type-erasure-dev libboost-type-erasure1.83-dev libboost-type-erasure1.83.0
  libboost-url-dev libboost-url1.83-dev libboost-url1.83.0 libboost-wave-dev libboost-wave1.83-dev libboost-wave1.83.0 libboost1.83-dev libboost1.83-tools-dev libcaf-openmpi-3t64 libcoarrays-dev
  libcoarrays-openmpi-dev libevent-2.1-7t64 libevent-dev libevent-extra-2.1-7t64 libevent-openssl-2.1-7t64 libevent-pthreads-2.1-7t64 libfabric1 libgfortran-13-dev libhsa-runtime64-1 libhsakmt1
  libhwloc-dev libhwloc-plugins libhwloc15 libibverbs-dev libicu-dev libjs-jquery-ui libllvm17t64 libltdl-dev libmunge2 libnl-3-dev libnl-route-3-dev libnuma-dev libopenmpi-dev libopenmpi3t64 libpmix-dev
  libpmix2t64 libpsm-infinipath1 libpsm2-2 librdmacm1t64 libtool libucx0 m4 mpi-default-bin mpi-default-dev openmpi-bin openmpi-common
The following packages will be upgraded:
  ibverbs-providers libibverbs1
2 upgraded, 151 newly installed, 0 to remove and 251 not upgraded.
Need to get 125 MB of archives.
After this operation, 718 MB of additional disk space will be used.
Get:1 http://100.64.144.92:8081/repository/ubuntu2404 noble-updates/main amd64 libibverbs1 amd64 50.0-2ubuntu0.2 [68.0 kB]
Get:2 http://100.64.144.92:8081/repository/ubuntu2404 noble-updates/main amd64 ibverbs-providers amd64 50.0-2ubuntu0.2 [381 kB]
Get:3 http://100.64.144.92:8081/repository/ubuntu2404 noble/main amd64 m4 amd64 1.4.19-4build1 [244 kB]
Get:4 http://100.64.144.92:8081/repository/ubuntu2404 noble/main amd64 autoconf all 2.71-3 [339 kB]
Get:5 http://100.64.144.92:8081/repository/ubuntu2404 noble/main amd64 autotools-dev all 20220109.1 [44.9 kB]
Get:6 http://100.64.144.92:8081/repository/ubuntu2404 noble/main amd64 automake all 1:1.16.5-1.3ubuntu1 [558 kB]
Get:7 http://100.64.144.92:8081/repository/ubuntu2404 noble-updates/main amd64 libgfortran-13-dev amd64 13.3.0-6ubuntu2~24.04 [928 kB]
Get:8 http://100.64.144.92:8081/repository/ubuntu2404 noble-updates/main amd64 gfortran-13-x86-64-linux-gnu amd64 13.3.0-6ubuntu2~24.04 [11.4 MB]
Get:9 http://100.64.144.92:8081/repository/ubuntu2404 noble-updates/main amd64 gfortran-13 amd64 13.3.0-6ubuntu2~24.04 [13.9 kB]
Get:10 http://100.64.144.92:8081/repository/ubuntu2404 noble/main amd64 gfortran-x86-64-linux-gnu amd64 4:13.2.0-7ubuntu1 [1,024 B]
Get:11 http://100.64.144.92:8081/repository/ubuntu2404 noble/main amd64 gfortran amd64 4:13.2.0-7ubuntu1 [1,176 B]
Get:12 http://100.64.144.92:8081/repository/ubuntu2404 noble-updates/main amd64 icu-devtools amd64 74.2-1ubuntu3.1 [212 kB]
Get:13 http://100.64.144.92:8081/repository/ubuntu2404 noble/main amd64 libllvm17t64 amd64 1:17.0.6-9ubuntu1 [26.2 MB]
Get:14 http://100.64.144.92:8081/repository/ubuntu2404 noble/universe amd64 libamd-comgr2 amd64 6.0+git20231212.4510c28+dfsg-3build2 [14.4 MB]
Get:15 http://100.64.144.92:8081/repository/ubuntu2404 noble/universe amd64 libhsakmt1 amd64 5.7.0-1build1 [62.9 kB]
Get:16 http://100.64.144.92:8081/repository/ubuntu2404 noble/universe amd64 libhsa-runtime64-1 amd64 5.7.1-2build1 [491 kB]
Get:17 http://100.64.144.92:8081/repository/ubuntu2404 noble/universe amd64 libamdhip64-5 amd64 5.7.1-3 [9,621 kB]
Get:18 http://100.64.144.92:8081/repository/ubuntu2404 noble-updates/main amd64 libboost1.83-dev amd64 1.83.0-2.1ubuntu3.1 [10.7 MB]
Get:19 http://100.64.144.92:8081/repository/ubuntu2404 noble/main amd64 libboost-dev amd64 1.83.0.1ubuntu2 [4,308 B]
Get:20 http://100.64.144.92:8081/repository/ubuntu2404 noble-updates/main amd64 libboost1.83-tools-dev amd64 1.83.0-2.1ubuntu3.1 [1,402 kB]
Get:21 http://100.64.144.92:8081/repository/ubuntu2404 noble/universe amd64 libboost-tools-dev amd64 1.83.0.1ubuntu2 [4,238 B]                                                                               
Get:22 http://100.64.144.92:8081/repository/ubuntu2404 noble-updates/main amd64 libboost-atomic1.83.0 amd64 1.83.0-2.1ubuntu3.1 [240 kB]                                                                     
Get:23 http://100.64.144.92:8081/repository/ubuntu2404 noble-updates/main amd64 libboost-atomic1.83-dev amd64 1.83.0-2.1ubuntu3.1 [235 kB]                                                                   
Get:24 http://100.64.144.92:8081/repository/ubuntu2404 noble/universe amd64 libboost-atomic-dev amd64 1.83.0.1ubuntu2 [4,360 B]                                                                              
Get:25 http://100.64.144.92:8081/repository/ubuntu2404 noble-updates/main amd64 libboost-chrono1.83.0t64 amd64 1.83.0-2.1ubuntu3.1 [244 kB]                                                                  
Get:26 http://100.64.144.92:8081/repository/ubuntu2404 noble-updates/main amd64 libboost-chrono1.83-dev amd64 1.83.0-2.1ubuntu3.1 [246 kB]                                                                   
Get:27 http://100.64.144.92:8081/repository/ubuntu2404 noble/universe amd64 libboost-chrono-dev amd64 1.83.0.1ubuntu2 [4,672 B]                                                                              
Get:28 http://100.64.144.92:8081/repository/ubuntu2404 noble-updates/universe amd64 libboost-container1.83.0 amd64 1.83.0-2.1ubuntu3.1 [261 kB]                                                              
Get:29 http://100.64.144.92:8081/repository/ubuntu2404 noble-updates/universe amd64 libboost-container1.83-dev amd64 1.83.0-2.1ubuntu3.1 [865 kB]                                                            
Get:30 http://100.64.144.92:8081/repository/ubuntu2404 noble/universe amd64 libboost-container-dev amd64 1.83.0.1ubuntu2 [4,530 B]                                                                           
Get:31 http://100.64.144.92:8081/repository/ubuntu2404 noble-updates/main amd64 libboost-date-time1.83.0 amd64 1.83.0-2.1ubuntu3.1 [236 kB]                                                                  
Get:32 http://100.64.144.92:8081/repository/ubuntu2404 noble-updates/main amd64 libboost-serialization1.83.0 amd64 1.83.0-2.1ubuntu3.1 [341 kB]                                                              
Get:33 http://100.64.144.92:8081/repository/ubuntu2404 noble-updates/main amd64 libboost-serialization1.83-dev amd64 1.83.0-2.1ubuntu3.1 [387 kB]                                                            
Get:34 http://100.64.144.92:8081/repository/ubuntu2404 noble-updates/main amd64 libboost-date-time1.83-dev amd64 1.83.0-2.1ubuntu3.1 [239 kB]                                                                
Get:35 http://100.64.144.92:8081/repository/ubuntu2404 noble-updates/main amd64 libboost-system1.83.0 amd64 1.83.0-2.1ubuntu3.1 [236 kB]                                                                     
Get:36 http://100.64.144.92:8081/repository/ubuntu2404 noble-updates/main amd64 libboost-system1.83-dev amd64 1.83.0-2.1ubuntu3.1 [231 kB]                                                                   
Get:37 http://100.64.144.92:8081/repository/ubuntu2404 noble-updates/main amd64 libboost-thread1.83.0 amd64 1.83.0-2.1ubuntu3.1 [276 kB]                                                                     
Get:38 http://100.64.144.92:8081/repository/ubuntu2404 noble-updates/main amd64 libboost-thread1.83-dev amd64 1.83.0-2.1ubuntu3.1 [282 kB]                                                                   
Get:39 http://100.64.144.92:8081/repository/ubuntu2404 noble-updates/main amd64 libboost-context1.83.0 amd64 1.83.0-2.1ubuntu3.1 [237 kB]                                                                    
Get:40 http://100.64.144.92:8081/repository/ubuntu2404 noble-updates/universe amd64 libboost-context1.83-dev amd64 1.83.0-2.1ubuntu3.1 [232 kB]                                                              
Get:41 http://100.64.144.92:8081/repository/ubuntu2404 noble/universe amd64 libboost-context-dev amd64 1.83.0.1ubuntu2 [4,276 B]                                                                             
Get:42 http://100.64.144.92:8081/repository/ubuntu2404 noble-updates/universe amd64 libboost-coroutine1.83.0 amd64 1.83.0-2.1ubuntu3.1 [234 kB]                                                              
Get:43 http://100.64.144.92:8081/repository/ubuntu2404 noble-updates/universe amd64 libboost-coroutine1.83-dev amd64 1.83.0-2.1ubuntu3.1 [237 kB]                                                            
Get:44 http://100.64.144.92:8081/repository/ubuntu2404 noble/universe amd64 libboost-coroutine-dev amd64 1.83.0.1ubuntu2 [4,344 B]                                                                           
Get:45 http://100.64.144.92:8081/repository/ubuntu2404 noble/universe amd64 libboost-date-time-dev amd64 1.83.0.1ubuntu2 [4,058 B]                                                                           
Get:46 http://100.64.144.92:8081/repository/ubuntu2404 noble-updates/universe amd64 libboost-exception1.83-dev amd64 1.83.0-2.1ubuntu3.1 [229 kB]                                                            
Get:47 http://100.64.144.92:8081/repository/ubuntu2404 noble/universe amd64 libboost-exception-dev amd64 1.83.0.1ubuntu2 [4,058 B]                                                                           
Get:48 http://100.64.144.92:8081/repository/ubuntu2404 noble-updates/main amd64 libboost-filesystem1.83.0 amd64 1.83.0-2.1ubuntu3.1 [283 kB]                                                                 
Get:49 http://100.64.144.92:8081/repository/ubuntu2404 noble-updates/universe amd64 libboost-filesystem1.83-dev amd64 1.83.0-2.1ubuntu3.1 [301 kB]                                                           
Get:50 http://100.64.144.92:8081/repository/ubuntu2404 noble-updates/universe amd64 libboost-fiber1.83.0 amd64 1.83.0-2.1ubuntu3.1 [254 kB]                                                                  
Get:51 http://100.64.144.92:8081/repository/ubuntu2404 noble-updates/universe amd64 libboost-fiber1.83-dev amd64 1.83.0-2.1ubuntu3.1 [268 kB]                                                                
Get:52 http://100.64.144.92:8081/repository/ubuntu2404 noble/universe amd64 libboost-fiber-dev amd64 1.83.0.1ubuntu2 [4,486 B]                                                                               
Get:53 http://100.64.144.92:8081/repository/ubuntu2404 noble/universe amd64 libboost-filesystem-dev amd64 1.83.0.1ubuntu2 [4,096 B]                                                                          
Get:54 http://100.64.144.92:8081/repository/ubuntu2404 noble-updates/universe amd64 libboost-graph1.83.0 amd64 1.83.0-2.1ubuntu3.1 [361 kB]                                                                  
Get:55 http://100.64.144.92:8081/repository/ubuntu2404 noble-updates/main amd64 libboost-regex1.83.0 amd64 1.83.0-2.1ubuntu3.1 [339 kB]                                                                      
Get:56 http://100.64.144.92:8081/repository/ubuntu2404 noble-updates/main amd64 libicu-dev amd64 74.2-1ubuntu3.1 [11.9 MB]                                                                                   
Get:57 http://100.64.144.92:8081/repository/ubuntu2404 noble-updates/main amd64 libboost-regex1.83-dev amd64 1.83.0-2.1ubuntu3.1 [355 kB]                                                                    
Get:58 http://100.64.144.92:8081/repository/ubuntu2404 noble-updates/universe amd64 libboost-test1.83.0 amd64 1.83.0-2.1ubuntu3.1 [454 kB]                                                                   
Get:59 http://100.64.144.92:8081/repository/ubuntu2404 noble-updates/universe amd64 libboost-test1.83-dev amd64 1.83.0-2.1ubuntu3.1 [566 kB]                                                                 
Get:60 http://100.64.144.92:8081/repository/ubuntu2404 noble-updates/universe amd64 libboost-graph1.83-dev amd64 1.83.0-2.1ubuntu3.1 [399 kB]                                                                
Get:61 http://100.64.144.92:8081/repository/ubuntu2404 noble/universe amd64 libboost-graph-dev amd64 1.83.0.1ubuntu2 [4,160 B]                                                                               
Get:62 http://100.64.144.92:8081/repository/ubuntu2404 noble/main amd64 libevent-pthreads-2.1-7t64 amd64 2.1.12-stable-9ubuntu2 [7,982 B]                                                                    
Get:63 http://100.64.144.92:8081/repository/ubuntu2404 noble/universe amd64 libpsm-infinipath1 amd64 3.3+20.604758e7-6.3build1 [178 kB]                                                                      
Get:64 http://100.64.144.92:8081/repository/ubuntu2404 noble/universe amd64 libpsm2-2 amd64 11.2.185-2build1 [194 kB]                                                                                        
Get:65 http://100.64.144.92:8081/repository/ubuntu2404 noble-updates/main amd64 librdmacm1t64 amd64 50.0-2ubuntu0.2 [70.7 kB]                                                                                
Get:66 http://100.64.144.92:8081/repository/ubuntu2404 noble/universe amd64 libfabric1 amd64 1.17.0-3build2 [657 kB]                                                                                         
Get:67 http://100.64.144.92:8081/repository/ubuntu2404 noble/universe amd64 libhwloc15 amd64 2.10.0-1build1 [172 kB]                                                                                         
Get:68 http://100.64.144.92:8081/repository/ubuntu2404 noble/universe amd64 libmunge2 amd64 0.5.15-4build1 [14.7 kB]                                                                                         
Get:69 http://100.64.144.92:8081/repository/ubuntu2404 noble/universe amd64 libhwloc-plugins amd64 2.10.0-1build1 [15.7 kB]                                                                                  
Get:70 http://100.64.144.92:8081/repository/ubuntu2404 noble/universe amd64 libpmix2t64 amd64 5.0.1-4.1build1 [697 kB]                                                                                       
Get:71 http://100.64.144.92:8081/repository/ubuntu2404 noble/universe amd64 libucx0 amd64 1.16.0+ds-5ubuntu1 [1,140 kB]                                                                                      
Get:72 http://100.64.144.92:8081/repository/ubuntu2404 noble/universe amd64 libopenmpi3t64 amd64 4.1.6-7ubuntu2 [2,563 kB]                                                                                   
Get:73 http://100.64.144.92:8081/repository/ubuntu2404 noble-updates/universe amd64 libboost-mpi1.83.0 amd64 1.83.0-2.1ubuntu3.1 [271 kB]                                                                    
Get:74 http://100.64.144.92:8081/repository/ubuntu2404 noble-updates/universe amd64 libboost-graph-parallel1.83.0 amd64 1.83.0-2.1ubuntu3.1 [278 kB]                                                         
Get:75 http://100.64.144.92:8081/repository/ubuntu2404 noble-updates/universe amd64 libboost-graph-parallel1.83-dev amd64 1.83.0-2.1ubuntu3.1 [288 kB]                                                       
Get:76 http://100.64.144.92:8081/repository/ubuntu2404 noble/universe amd64 libboost-graph-parallel-dev amd64 1.83.0.1ubuntu2 [4,192 B]                                                                      
Get:77 http://100.64.144.92:8081/repository/ubuntu2404 noble-updates/main amd64 libboost-iostreams1.83.0 amd64 1.83.0-2.1ubuntu3.1 [259 kB]                                                                  
Get:78 http://100.64.144.92:8081/repository/ubuntu2404 noble-updates/universe amd64 libboost-iostreams1.83-dev amd64 1.83.0-2.1ubuntu3.1 [264 kB]                                                            
Get:79 http://100.64.144.92:8081/repository/ubuntu2404 noble/universe amd64 libboost-iostreams-dev amd64 1.83.0.1ubuntu2 [4,046 B]                                                                           
Get:80 http://100.64.144.92:8081/repository/ubuntu2404 noble-updates/universe amd64 libboost-json1.83.0 amd64 1.83.0-2.1ubuntu3.1 [365 kB]                                                                   
Get:81 http://100.64.144.92:8081/repository/ubuntu2404 noble-updates/universe amd64 libboost-json1.83-dev amd64 1.83.0-2.1ubuntu3.1 [380 kB]                                                                 
Get:82 http://100.64.144.92:8081/repository/ubuntu2404 noble/universe amd64 libboost-json-dev amd64 1.83.0.1ubuntu2 [4,172 B]                                                                                
Get:83 http://100.64.144.92:8081/repository/ubuntu2404 noble-updates/main amd64 libboost-locale1.83.0 amd64 1.83.0-2.1ubuntu3.1 [413 kB]                                                                     
Get:84 http://100.64.144.92:8081/repository/ubuntu2404 noble-updates/universe amd64 libboost-locale1.83-dev amd64 1.83.0-2.1ubuntu3.1 [582 kB]                                                               
Get:85 http://100.64.144.92:8081/repository/ubuntu2404 noble/universe amd64 libboost-locale-dev amd64 1.83.0.1ubuntu2 [4,378 B]                                                                              
Get:86 http://100.64.144.92:8081/repository/ubuntu2404 noble-updates/universe amd64 libboost-log1.83.0 amd64 1.83.0-2.1ubuntu3.1 [675 kB]                                                                    
Get:87 http://100.64.144.92:8081/repository/ubuntu2404 noble-updates/universe amd64 libboost-log1.83-dev amd64 1.83.0-2.1ubuntu3.1 [937 kB]                                                                  
Get:88 http://100.64.144.92:8081/repository/ubuntu2404 noble/universe amd64 libboost-log-dev amd64 1.83.0.1ubuntu2 [4,260 B]                                                                                 
Get:89 http://100.64.144.92:8081/repository/ubuntu2404 noble-updates/universe amd64 libboost-math1.83.0 amd64 1.83.0-2.1ubuntu3.1 [440 kB]                                                                   
Get:90 http://100.64.144.92:8081/repository/ubuntu2404 noble-updates/universe amd64 libboost-math1.83-dev amd64 1.83.0-2.1ubuntu3.1 [586 kB]                                                                 
Get:91 http://100.64.144.92:8081/repository/ubuntu2404 noble/universe amd64 libboost-math-dev amd64 1.83.0.1ubuntu2 [4,264 B]                                                                                
Get:92 http://100.64.144.92:8081/repository/ubuntu2404 noble/universe amd64 openmpi-common all 4.1.6-7ubuntu2 [170 kB]                                                                                       
Get:93 http://100.64.144.92:8081/repository/ubuntu2404 noble-updates/main amd64 libnl-3-dev amd64 3.7.0-0.3build1.1 [99.5 kB]                                                                                
Get:94 http://100.64.144.92:8081/repository/ubuntu2404 noble-updates/main amd64 libnl-route-3-dev amd64 3.7.0-0.3build1.1 [216 kB]                                                                           
Get:95 http://100.64.144.92:8081/repository/ubuntu2404 noble-updates/main amd64 libibverbs-dev amd64 50.0-2ubuntu0.2 [686 kB]                                                                                
Get:96 http://100.64.144.92:8081/repository/ubuntu2404 noble/main amd64 libnuma-dev amd64 2.0.18-1build1 [37.0 kB]                                                                                           
Get:97 http://100.64.144.92:8081/repository/ubuntu2404 noble/main amd64 libltdl-dev amd64 2.4.7-7build1 [168 kB]                                                                                             
Get:98 http://100.64.144.92:8081/repository/ubuntu2404 noble/universe amd64 libhwloc-dev amd64 2.10.0-1build1 [268 kB]                                                                                       
Get:99 http://100.64.144.92:8081/repository/ubuntu2404 noble/main amd64 libevent-2.1-7t64 amd64 2.1.12-stable-9ubuntu2 [145 kB]                                                                              
Get:100 http://100.64.144.92:8081/repository/ubuntu2404 noble/main amd64 libevent-extra-2.1-7t64 amd64 2.1.12-stable-9ubuntu2 [64.2 kB]                                                                      
Get:101 http://100.64.144.92:8081/repository/ubuntu2404 noble/main amd64 libevent-openssl-2.1-7t64 amd64 2.1.12-stable-9ubuntu2 [15.7 kB]                                                                    
Get:102 http://100.64.144.92:8081/repository/ubuntu2404 noble/main amd64 libevent-dev amd64 2.1.12-stable-9ubuntu2 [274 kB]                                                                                  
Get:103 http://100.64.144.92:8081/repository/ubuntu2404 noble/universe amd64 libpmix-dev amd64 5.0.1-4.1build1 [4,018 kB]                                                                                    
Get:104 http://100.64.144.92:8081/repository/ubuntu2404 noble/universe amd64 libjs-jquery-ui all 1.13.2+dfsg-1 [252 kB]                                                                                      
Get:105 http://100.64.144.92:8081/repository/ubuntu2404 noble/universe amd64 openmpi-bin amd64 4.1.6-7ubuntu2 [114 kB]                                                                                       
Get:106 http://100.64.144.92:8081/repository/ubuntu2404 noble/universe amd64 libopenmpi-dev amd64 4.1.6-7ubuntu2 [864 kB]                                                                                    
Get:107 http://100.64.144.92:8081/repository/ubuntu2404 noble/universe amd64 mpi-default-dev amd64 1.15build1 [3,154 B]                                                                                      
Get:108 http://100.64.144.92:8081/repository/ubuntu2404 noble-updates/universe amd64 libboost-mpi1.83-dev amd64 1.83.0-2.1ubuntu3.1 [296 kB]                                                                 
Get:109 http://100.64.144.92:8081/repository/ubuntu2404 noble/universe amd64 libboost-mpi-dev amd64 1.83.0.1ubuntu2 [4,144 B]                                                                                
Get:110 http://100.64.144.92:8081/repository/ubuntu2404 noble-updates/main amd64 libboost-python1.83.0 amd64 1.83.0-2.1ubuntu3.1 [312 kB]                                                                    
Get:111 http://100.64.144.92:8081/repository/ubuntu2404 noble/universe amd64 mpi-default-bin amd64 1.15build1 [2,376 B]                                                                                      
Get:112 http://100.64.144.92:8081/repository/ubuntu2404 noble-updates/universe amd64 libboost-mpi-python1.83.0 amd64 1.83.0-2.1ubuntu3.1 [362 kB]                                                            
Get:113 http://100.64.144.92:8081/repository/ubuntu2404 noble-updates/universe amd64 libboost-mpi-python1.83-dev amd64 1.83.0-2.1ubuntu3.1 [237 kB]                                                          
Get:114 http://100.64.144.92:8081/repository/ubuntu2404 noble/universe amd64 libboost-mpi-python-dev amd64 1.83.0.1ubuntu2 [4,196 B]                                                                         
Get:115 http://100.64.144.92:8081/repository/ubuntu2404 noble-updates/universe amd64 libboost-numpy1.83.0 amd64 1.83.0-2.1ubuntu3.1 [242 kB]                                                                 
Get:116 http://100.64.144.92:8081/repository/ubuntu2404 noble-updates/universe amd64 libboost-numpy1.83-dev amd64 1.83.0-2.1ubuntu3.1 [247 kB]                                                               
Get:117 http://100.64.144.92:8081/repository/ubuntu2404 noble/universe amd64 libboost-numpy-dev amd64 1.83.0.1ubuntu2 [4,100 B]                                                                              
Get:118 http://100.64.144.92:8081/repository/ubuntu2404 noble-updates/main amd64 libboost-program-options1.83.0 amd64 1.83.0-2.1ubuntu3.1 [320 kB]                                                           
Get:119 http://100.64.144.92:8081/repository/ubuntu2404 noble-updates/main amd64 libboost-program-options1.83-dev amd64 1.83.0-2.1ubuntu3.1 [388 kB]                                                         
Get:120 http://100.64.144.92:8081/repository/ubuntu2404 noble/main amd64 libboost-program-options-dev amd64 1.83.0.1ubuntu2 [4,086 B]                                                                        
Get:121 http://100.64.144.92:8081/repository/ubuntu2404 noble-updates/universe amd64 libboost-python1.83-dev amd64 1.83.0-2.1ubuntu3.1 [337 kB]                                                              
Get:122 http://100.64.144.92:8081/repository/ubuntu2404 noble/universe amd64 libboost-python-dev amd64 1.83.0.1ubuntu2 [4,344 B]                                                                             
Get:123 http://100.64.144.92:8081/repository/ubuntu2404 noble-updates/universe amd64 libboost-random1.83.0 amd64 1.83.0-2.1ubuntu3.1 [242 kB]                                                                
Get:124 http://100.64.144.92:8081/repository/ubuntu2404 noble-updates/universe amd64 libboost-random1.83-dev amd64 1.83.0-2.1ubuntu3.1 [241 kB]                                                              
Get:125 http://100.64.144.92:8081/repository/ubuntu2404 noble/universe amd64 libboost-random-dev amd64 1.83.0.1ubuntu2 [4,062 B]                                                                             
Get:126 http://100.64.144.92:8081/repository/ubuntu2404 noble/main amd64 libboost-regex-dev amd64 1.83.0.1ubuntu2 [4,324 B]                                                                                  
Get:127 http://100.64.144.92:8081/repository/ubuntu2404 noble/universe amd64 libboost-serialization-dev amd64 1.83.0.1ubuntu2 [4,280 B]                                                                      
Get:128 http://100.64.144.92:8081/repository/ubuntu2404 noble-updates/universe amd64 libboost-stacktrace1.83.0 amd64 1.83.0-2.1ubuntu3.1 [290 kB]                                                            
Get:129 http://100.64.144.92:8081/repository/ubuntu2404 noble-updates/universe amd64 libboost-stacktrace1.83-dev amd64 1.83.0-2.1ubuntu3.1 [246 kB]                                                          
Get:130 http://100.64.144.92:8081/repository/ubuntu2404 noble/universe amd64 libboost-stacktrace-dev amd64 1.83.0.1ubuntu2 [4,068 B]                                                                         
Get:131 http://100.64.144.92:8081/repository/ubuntu2404 noble/universe amd64 libboost-system-dev amd64 1.83.0.1ubuntu2 [4,206 B]                                                                             
Get:132 http://100.64.144.92:8081/repository/ubuntu2404 noble/universe amd64 libboost-test-dev amd64 1.83.0.1ubuntu2 [4,090 B]                                                                               
Get:133 http://100.64.144.92:8081/repository/ubuntu2404 noble/main amd64 libboost-thread-dev amd64 1.83.0.1ubuntu2 [4,088 B]                                                                                 
Get:134 http://100.64.144.92:8081/repository/ubuntu2404 noble-updates/universe amd64 libboost-timer1.83.0 amd64 1.83.0-2.1ubuntu3.1 [241 kB]                                                                 
Get:135 http://100.64.144.92:8081/repository/ubuntu2404 noble-updates/universe amd64 libboost-timer1.83-dev amd64 1.83.0-2.1ubuntu3.1 [236 kB]                                                               
Get:136 http://100.64.144.92:8081/repository/ubuntu2404 noble/universe amd64 libboost-timer-dev amd64 1.83.0.1ubuntu2 [4,190 B]                                                                              
Get:137 http://100.64.144.92:8081/repository/ubuntu2404 noble-updates/universe amd64 libboost-type-erasure1.83.0 amd64 1.83.0-2.1ubuntu3.1 [246 kB]                                                          
Get:138 http://100.64.144.92:8081/repository/ubuntu2404 noble-updates/universe amd64 libboost-type-erasure1.83-dev amd64 1.83.0-2.1ubuntu3.1 [250 kB]                                                        
Get:139 http://100.64.144.92:8081/repository/ubuntu2404 noble/universe amd64 libboost-type-erasure-dev amd64 1.83.0.1ubuntu2 [4,162 B]                                                                       
Get:140 http://100.64.144.92:8081/repository/ubuntu2404 noble-updates/main amd64 libboost-url1.83.0 amd64 1.83.0-2.1ubuntu3.1 [343 kB]                                                                       
Get:141 http://100.64.144.92:8081/repository/ubuntu2404 noble-updates/universe amd64 libboost-url1.83-dev amd64 1.83.0-2.1ubuntu3.1 [444 kB]                                                                 
Get:142 http://100.64.144.92:8081/repository/ubuntu2404 noble/universe amd64 libboost-url-dev amd64 1.83.0.1ubuntu2 [4,192 B]                                                                                
Get:143 http://100.64.144.92:8081/repository/ubuntu2404 noble-updates/universe amd64 libboost-wave1.83.0 amd64 1.83.0-2.1ubuntu3.1 [454 kB]                                                                  
Get:144 http://100.64.144.92:8081/repository/ubuntu2404 noble-updates/universe amd64 libboost-wave1.83-dev amd64 1.83.0-2.1ubuntu3.1 [499 kB]                                                                
Get:145 http://100.64.144.92:8081/repository/ubuntu2404 noble/universe amd64 libboost-wave-dev amd64 1.83.0.1ubuntu2 [4,096 B]                                                                               
Get:146 http://100.64.144.92:8081/repository/ubuntu2404 noble-updates/universe amd64 libboost-nowide1.83.0 amd64 1.83.0-2.1ubuntu3.1 [240 kB]                                                                
Get:147 http://100.64.144.92:8081/repository/ubuntu2404 noble-updates/universe amd64 libboost-nowide1.83-dev amd64 1.83.0-2.1ubuntu3.1 [236 kB]                                                              
Get:148 http://100.64.144.92:8081/repository/ubuntu2404 noble/universe amd64 libboost-nowide-dev amd64 1.83.0.1ubuntu2 [4,136 B]                                                                             
Get:149 http://100.64.144.92:8081/repository/ubuntu2404 noble/universe amd64 libboost-all-dev amd64 1.83.0.1ubuntu2 [2,286 B]                                                                                
Get:150 http://100.64.144.92:8081/repository/ubuntu2404 noble/universe amd64 libcaf-openmpi-3t64 amd64 2.10.2+ds-2.1build2 [39.1 kB]                                                                         
Get:151 http://100.64.144.92:8081/repository/ubuntu2404 noble/universe amd64 libcoarrays-dev amd64 2.10.2+ds-2.1build2 [37.5 kB]                                                                             
Get:152 http://100.64.144.92:8081/repository/ubuntu2404 noble/universe amd64 libcoarrays-openmpi-dev amd64 2.10.2+ds-2.1build2 [372 kB]                                                                      
Get:153 http://100.64.144.92:8081/repository/ubuntu2404 noble/main amd64 libtool all 2.4.7-7build1 [166 kB]                                                                                                  
Fetched 125 MB in 29s (4,362 kB/s)                                                                                                                                                                           
N: Ignoring file 'ubuntu.sources.bkp' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension
Extracting templates from packages: 19%N: Ignoring file 'ubuntu.sources.bkp' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension
Extracting templates from packages: 39%N: Ignoring file 'ubuntu.sources.bkp' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension
Extracting templates from packages: 58%N: Ignoring file 'ubuntu.sources.bkp' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension
Extracting templates from packages: 78%N: Ignoring file 'ubuntu.sources.bkp' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension
Extracting templates from packages: 98%N: Ignoring file 'ubuntu.sources.bkp' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension
Extracting templates from packages: 100%
(Reading database ... 186068 files and directories currently installed.)
Preparing to unpack .../000-libibverbs1_50.0-2ubuntu0.2_amd64.deb ...
Unpacking libibverbs1:amd64 (50.0-2ubuntu0.2) over (50.0-2build2) ...
Preparing to unpack .../001-ibverbs-providers_50.0-2ubuntu0.2_amd64.deb ...
Unpacking ibverbs-providers:amd64 (50.0-2ubuntu0.2) over (50.0-2build2) ...
Selecting previously unselected package m4.
Preparing to unpack .../002-m4_1.4.19-4build1_amd64.deb ...
Unpacking m4 (1.4.19-4build1) ...
Selecting previously unselected package autoconf.
Preparing to unpack .../003-autoconf_2.71-3_all.deb ...
Unpacking autoconf (2.71-3) ...
Selecting previously unselected package autotools-dev.
Preparing to unpack .../004-autotools-dev_20220109.1_all.deb ...
Unpacking autotools-dev (20220109.1) ...
Selecting previously unselected package automake.
Preparing to unpack .../005-automake_1%3a1.16.5-1.3ubuntu1_all.deb ...
Unpacking automake (1:1.16.5-1.3ubuntu1) ...
Selecting previously unselected package libgfortran-13-dev:amd64.
Preparing to unpack .../006-libgfortran-13-dev_13.3.0-6ubuntu2~24.04_amd64.deb ...
Unpacking libgfortran-13-dev:amd64 (13.3.0-6ubuntu2~24.04) ...
Selecting previously unselected package gfortran-13-x86-64-linux-gnu.
Preparing to unpack .../007-gfortran-13-x86-64-linux-gnu_13.3.0-6ubuntu2~24.04_amd64.deb ...
Unpacking gfortran-13-x86-64-linux-gnu (13.3.0-6ubuntu2~24.04) ...
Selecting previously unselected package gfortran-13.
Preparing to unpack .../008-gfortran-13_13.3.0-6ubuntu2~24.04_amd64.deb ...
Unpacking gfortran-13 (13.3.0-6ubuntu2~24.04) ...
Selecting previously unselected package gfortran-x86-64-linux-gnu.
Preparing to unpack .../009-gfortran-x86-64-linux-gnu_4%3a13.2.0-7ubuntu1_amd64.deb ...
Unpacking gfortran-x86-64-linux-gnu (4:13.2.0-7ubuntu1) ...
Selecting previously unselected package gfortran.
Preparing to unpack .../010-gfortran_4%3a13.2.0-7ubuntu1_amd64.deb ...
Unpacking gfortran (4:13.2.0-7ubuntu1) ...
Selecting previously unselected package icu-devtools.
Preparing to unpack .../011-icu-devtools_74.2-1ubuntu3.1_amd64.deb ...
Unpacking icu-devtools (74.2-1ubuntu3.1) ...
Selecting previously unselected package libllvm17t64:amd64.
Preparing to unpack .../012-libllvm17t64_1%3a17.0.6-9ubuntu1_amd64.deb ...
Unpacking libllvm17t64:amd64 (1:17.0.6-9ubuntu1) ...
Selecting previously unselected package libamd-comgr2:amd64.
Preparing to unpack .../013-libamd-comgr2_6.0+git20231212.4510c28+dfsg-3build2_amd64.deb ...
Unpacking libamd-comgr2:amd64 (6.0+git20231212.4510c28+dfsg-3build2) ...
Selecting previously unselected package libhsakmt1:amd64.
Preparing to unpack .../014-libhsakmt1_5.7.0-1build1_amd64.deb ...
Unpacking libhsakmt1:amd64 (5.7.0-1build1) ...
Selecting previously unselected package libhsa-runtime64-1.
Preparing to unpack .../015-libhsa-runtime64-1_5.7.1-2build1_amd64.deb ...
Unpacking libhsa-runtime64-1 (5.7.1-2build1) ...
Selecting previously unselected package libamdhip64-5.
Preparing to unpack .../016-libamdhip64-5_5.7.1-3_amd64.deb ...
Unpacking libamdhip64-5 (5.7.1-3) ...
Selecting previously unselected package libboost1.83-dev:amd64.
Preparing to unpack .../017-libboost1.83-dev_1.83.0-2.1ubuntu3.1_amd64.deb ...
Unpacking libboost1.83-dev:amd64 (1.83.0-2.1ubuntu3.1) ...
Selecting previously unselected package libboost-dev:amd64.
Preparing to unpack .../018-libboost-dev_1.83.0.1ubuntu2_amd64.deb ...
Unpacking libboost-dev:amd64 (1.83.0.1ubuntu2) ...
Selecting previously unselected package libboost1.83-tools-dev.
Preparing to unpack .../019-libboost1.83-tools-dev_1.83.0-2.1ubuntu3.1_amd64.deb ...
Unpacking libboost1.83-tools-dev (1.83.0-2.1ubuntu3.1) ...
Selecting previously unselected package libboost-tools-dev.
Preparing to unpack .../020-libboost-tools-dev_1.83.0.1ubuntu2_amd64.deb ...
Unpacking libboost-tools-dev (1.83.0.1ubuntu2) ...
Selecting previously unselected package libboost-atomic1.83.0:amd64.
Preparing to unpack .../021-libboost-atomic1.83.0_1.83.0-2.1ubuntu3.1_amd64.deb ...
Unpacking libboost-atomic1.83.0:amd64 (1.83.0-2.1ubuntu3.1) ...
Selecting previously unselected package libboost-atomic1.83-dev:amd64.
Preparing to unpack .../022-libboost-atomic1.83-dev_1.83.0-2.1ubuntu3.1_amd64.deb ...
Unpacking libboost-atomic1.83-dev:amd64 (1.83.0-2.1ubuntu3.1) ...
Selecting previously unselected package libboost-atomic-dev:amd64.
Preparing to unpack .../023-libboost-atomic-dev_1.83.0.1ubuntu2_amd64.deb ...
Unpacking libboost-atomic-dev:amd64 (1.83.0.1ubuntu2) ...
Selecting previously unselected package libboost-chrono1.83.0t64:amd64.
Preparing to unpack .../024-libboost-chrono1.83.0t64_1.83.0-2.1ubuntu3.1_amd64.deb ...
Unpacking libboost-chrono1.83.0t64:amd64 (1.83.0-2.1ubuntu3.1) ...
Selecting previously unselected package libboost-chrono1.83-dev:amd64.
Preparing to unpack .../025-libboost-chrono1.83-dev_1.83.0-2.1ubuntu3.1_amd64.deb ...
Unpacking libboost-chrono1.83-dev:amd64 (1.83.0-2.1ubuntu3.1) ...
Selecting previously unselected package libboost-chrono-dev:amd64.
Preparing to unpack .../026-libboost-chrono-dev_1.83.0.1ubuntu2_amd64.deb ...
Unpacking libboost-chrono-dev:amd64 (1.83.0.1ubuntu2) ...
Selecting previously unselected package libboost-container1.83.0:amd64.
Preparing to unpack .../027-libboost-container1.83.0_1.83.0-2.1ubuntu3.1_amd64.deb ...
Unpacking libboost-container1.83.0:amd64 (1.83.0-2.1ubuntu3.1) ...
Selecting previously unselected package libboost-container1.83-dev:amd64.
Preparing to unpack .../028-libboost-container1.83-dev_1.83.0-2.1ubuntu3.1_amd64.deb ...
Unpacking libboost-container1.83-dev:amd64 (1.83.0-2.1ubuntu3.1) ...
Selecting previously unselected package libboost-container-dev:amd64.
Preparing to unpack .../029-libboost-container-dev_1.83.0.1ubuntu2_amd64.deb ...
Unpacking libboost-container-dev:amd64 (1.83.0.1ubuntu2) ...
Selecting previously unselected package libboost-date-time1.83.0:amd64.
Preparing to unpack .../030-libboost-date-time1.83.0_1.83.0-2.1ubuntu3.1_amd64.deb ...
Unpacking libboost-date-time1.83.0:amd64 (1.83.0-2.1ubuntu3.1) ...
Selecting previously unselected package libboost-serialization1.83.0:amd64.
Preparing to unpack .../031-libboost-serialization1.83.0_1.83.0-2.1ubuntu3.1_amd64.deb ...
Unpacking libboost-serialization1.83.0:amd64 (1.83.0-2.1ubuntu3.1) ...
Selecting previously unselected package libboost-serialization1.83-dev:amd64.
Preparing to unpack .../032-libboost-serialization1.83-dev_1.83.0-2.1ubuntu3.1_amd64.deb ...
Unpacking libboost-serialization1.83-dev:amd64 (1.83.0-2.1ubuntu3.1) ...
Selecting previously unselected package libboost-date-time1.83-dev:amd64.
Preparing to unpack .../033-libboost-date-time1.83-dev_1.83.0-2.1ubuntu3.1_amd64.deb ...
Unpacking libboost-date-time1.83-dev:amd64 (1.83.0-2.1ubuntu3.1) ...
Selecting previously unselected package libboost-system1.83.0:amd64.
Preparing to unpack .../034-libboost-system1.83.0_1.83.0-2.1ubuntu3.1_amd64.deb ...
Unpacking libboost-system1.83.0:amd64 (1.83.0-2.1ubuntu3.1) ...
Selecting previously unselected package libboost-system1.83-dev:amd64.
Preparing to unpack .../035-libboost-system1.83-dev_1.83.0-2.1ubuntu3.1_amd64.deb ...
Unpacking libboost-system1.83-dev:amd64 (1.83.0-2.1ubuntu3.1) ...
Selecting previously unselected package libboost-thread1.83.0:amd64.
Preparing to unpack .../036-libboost-thread1.83.0_1.83.0-2.1ubuntu3.1_amd64.deb ...
Unpacking libboost-thread1.83.0:amd64 (1.83.0-2.1ubuntu3.1) ...
Selecting previously unselected package libboost-thread1.83-dev:amd64.
Preparing to unpack .../037-libboost-thread1.83-dev_1.83.0-2.1ubuntu3.1_amd64.deb ...
Unpacking libboost-thread1.83-dev:amd64 (1.83.0-2.1ubuntu3.1) ...
Selecting previously unselected package libboost-context1.83.0:amd64.
Preparing to unpack .../038-libboost-context1.83.0_1.83.0-2.1ubuntu3.1_amd64.deb ...
Unpacking libboost-context1.83.0:amd64 (1.83.0-2.1ubuntu3.1) ...
Selecting previously unselected package libboost-context1.83-dev:amd64.
Preparing to unpack .../039-libboost-context1.83-dev_1.83.0-2.1ubuntu3.1_amd64.deb ...
Unpacking libboost-context1.83-dev:amd64 (1.83.0-2.1ubuntu3.1) ...
Selecting previously unselected package libboost-context-dev:amd64.
Preparing to unpack .../040-libboost-context-dev_1.83.0.1ubuntu2_amd64.deb ...
Unpacking libboost-context-dev:amd64 (1.83.0.1ubuntu2) ...
Selecting previously unselected package libboost-coroutine1.83.0:amd64.
Preparing to unpack .../041-libboost-coroutine1.83.0_1.83.0-2.1ubuntu3.1_amd64.deb ...
Unpacking libboost-coroutine1.83.0:amd64 (1.83.0-2.1ubuntu3.1) ...
Selecting previously unselected package libboost-coroutine1.83-dev:amd64.
Preparing to unpack .../042-libboost-coroutine1.83-dev_1.83.0-2.1ubuntu3.1_amd64.deb ...
Unpacking libboost-coroutine1.83-dev:amd64 (1.83.0-2.1ubuntu3.1) ...
Selecting previously unselected package libboost-coroutine-dev:amd64.
Preparing to unpack .../043-libboost-coroutine-dev_1.83.0.1ubuntu2_amd64.deb ...
Unpacking libboost-coroutine-dev:amd64 (1.83.0.1ubuntu2) ...
Selecting previously unselected package libboost-date-time-dev:amd64.
Preparing to unpack .../044-libboost-date-time-dev_1.83.0.1ubuntu2_amd64.deb ...
Unpacking libboost-date-time-dev:amd64 (1.83.0.1ubuntu2) ...
Selecting previously unselected package libboost-exception1.83-dev:amd64.
Preparing to unpack .../045-libboost-exception1.83-dev_1.83.0-2.1ubuntu3.1_amd64.deb ...
Unpacking libboost-exception1.83-dev:amd64 (1.83.0-2.1ubuntu3.1) ...
Selecting previously unselected package libboost-exception-dev:amd64.
Preparing to unpack .../046-libboost-exception-dev_1.83.0.1ubuntu2_amd64.deb ...
Unpacking libboost-exception-dev:amd64 (1.83.0.1ubuntu2) ...
Selecting previously unselected package libboost-filesystem1.83.0:amd64.
Preparing to unpack .../047-libboost-filesystem1.83.0_1.83.0-2.1ubuntu3.1_amd64.deb ...
Unpacking libboost-filesystem1.83.0:amd64 (1.83.0-2.1ubuntu3.1) ...
Selecting previously unselected package libboost-filesystem1.83-dev:amd64.
Preparing to unpack .../048-libboost-filesystem1.83-dev_1.83.0-2.1ubuntu3.1_amd64.deb ...
Unpacking libboost-filesystem1.83-dev:amd64 (1.83.0-2.1ubuntu3.1) ...
Selecting previously unselected package libboost-fiber1.83.0:amd64.
Preparing to unpack .../049-libboost-fiber1.83.0_1.83.0-2.1ubuntu3.1_amd64.deb ...
Unpacking libboost-fiber1.83.0:amd64 (1.83.0-2.1ubuntu3.1) ...
Selecting previously unselected package libboost-fiber1.83-dev:amd64.
Preparing to unpack .../050-libboost-fiber1.83-dev_1.83.0-2.1ubuntu3.1_amd64.deb ...
Unpacking libboost-fiber1.83-dev:amd64 (1.83.0-2.1ubuntu3.1) ...
Selecting previously unselected package libboost-fiber-dev:amd64.
Preparing to unpack .../051-libboost-fiber-dev_1.83.0.1ubuntu2_amd64.deb ...
Unpacking libboost-fiber-dev:amd64 (1.83.0.1ubuntu2) ...
Selecting previously unselected package libboost-filesystem-dev:amd64.
Preparing to unpack .../052-libboost-filesystem-dev_1.83.0.1ubuntu2_amd64.deb ...
Unpacking libboost-filesystem-dev:amd64 (1.83.0.1ubuntu2) ...
Selecting previously unselected package libboost-graph1.83.0:amd64.
Preparing to unpack .../053-libboost-graph1.83.0_1.83.0-2.1ubuntu3.1_amd64.deb ...
Unpacking libboost-graph1.83.0:amd64 (1.83.0-2.1ubuntu3.1) ...
Selecting previously unselected package libboost-regex1.83.0:amd64.
Preparing to unpack .../054-libboost-regex1.83.0_1.83.0-2.1ubuntu3.1_amd64.deb ...
Unpacking libboost-regex1.83.0:amd64 (1.83.0-2.1ubuntu3.1) ...
Selecting previously unselected package libicu-dev:amd64.
Preparing to unpack .../055-libicu-dev_74.2-1ubuntu3.1_amd64.deb ...
Unpacking libicu-dev:amd64 (74.2-1ubuntu3.1) ...
Selecting previously unselected package libboost-regex1.83-dev:amd64.
Preparing to unpack .../056-libboost-regex1.83-dev_1.83.0-2.1ubuntu3.1_amd64.deb ...
Unpacking libboost-regex1.83-dev:amd64 (1.83.0-2.1ubuntu3.1) ...
Selecting previously unselected package libboost-test1.83.0:amd64.
Preparing to unpack .../057-libboost-test1.83.0_1.83.0-2.1ubuntu3.1_amd64.deb ...
Unpacking libboost-test1.83.0:amd64 (1.83.0-2.1ubuntu3.1) ...
Selecting previously unselected package libboost-test1.83-dev:amd64.
Preparing to unpack .../058-libboost-test1.83-dev_1.83.0-2.1ubuntu3.1_amd64.deb ...
Unpacking libboost-test1.83-dev:amd64 (1.83.0-2.1ubuntu3.1) ...
Selecting previously unselected package libboost-graph1.83-dev:amd64.
Preparing to unpack .../059-libboost-graph1.83-dev_1.83.0-2.1ubuntu3.1_amd64.deb ...
Unpacking libboost-graph1.83-dev:amd64 (1.83.0-2.1ubuntu3.1) ...
Selecting previously unselected package libboost-graph-dev:amd64.
Preparing to unpack .../060-libboost-graph-dev_1.83.0.1ubuntu2_amd64.deb ...
Unpacking libboost-graph-dev:amd64 (1.83.0.1ubuntu2) ...
Selecting previously unselected package libevent-pthreads-2.1-7t64:amd64.
Preparing to unpack .../061-libevent-pthreads-2.1-7t64_2.1.12-stable-9ubuntu2_amd64.deb ...
Unpacking libevent-pthreads-2.1-7t64:amd64 (2.1.12-stable-9ubuntu2) ...
Selecting previously unselected package libpsm-infinipath1.
Preparing to unpack .../062-libpsm-infinipath1_3.3+20.604758e7-6.3build1_amd64.deb ...
Unpacking libpsm-infinipath1 (3.3+20.604758e7-6.3build1) ...
Selecting previously unselected package libpsm2-2.
Preparing to unpack .../063-libpsm2-2_11.2.185-2build1_amd64.deb ...
Unpacking libpsm2-2 (11.2.185-2build1) ...
Selecting previously unselected package librdmacm1t64:amd64.
Preparing to unpack .../064-librdmacm1t64_50.0-2ubuntu0.2_amd64.deb ...
Unpacking librdmacm1t64:amd64 (50.0-2ubuntu0.2) ...
Selecting previously unselected package libfabric1:amd64.
Preparing to unpack .../065-libfabric1_1.17.0-3build2_amd64.deb ...
Unpacking libfabric1:amd64 (1.17.0-3build2) ...
Selecting previously unselected package libhwloc15:amd64.
Preparing to unpack .../066-libhwloc15_2.10.0-1build1_amd64.deb ...
Unpacking libhwloc15:amd64 (2.10.0-1build1) ...
Selecting previously unselected package libmunge2:amd64.
Preparing to unpack .../067-libmunge2_0.5.15-4build1_amd64.deb ...
Unpacking libmunge2:amd64 (0.5.15-4build1) ...
Selecting previously unselected package libhwloc-plugins:amd64.
Preparing to unpack .../068-libhwloc-plugins_2.10.0-1build1_amd64.deb ...
Unpacking libhwloc-plugins:amd64 (2.10.0-1build1) ...
Selecting previously unselected package libpmix2t64:amd64.
Preparing to unpack .../069-libpmix2t64_5.0.1-4.1build1_amd64.deb ...
Unpacking libpmix2t64:amd64 (5.0.1-4.1build1) ...
Selecting previously unselected package libucx0:amd64.
Preparing to unpack .../070-libucx0_1.16.0+ds-5ubuntu1_amd64.deb ...
Unpacking libucx0:amd64 (1.16.0+ds-5ubuntu1) ...
Selecting previously unselected package libopenmpi3t64:amd64.
Preparing to unpack .../071-libopenmpi3t64_4.1.6-7ubuntu2_amd64.deb ...
Unpacking libopenmpi3t64:amd64 (4.1.6-7ubuntu2) ...
Selecting previously unselected package libboost-mpi1.83.0.
Preparing to unpack .../072-libboost-mpi1.83.0_1.83.0-2.1ubuntu3.1_amd64.deb ...
Unpacking libboost-mpi1.83.0 (1.83.0-2.1ubuntu3.1) ...
Selecting previously unselected package libboost-graph-parallel1.83.0.
Preparing to unpack .../073-libboost-graph-parallel1.83.0_1.83.0-2.1ubuntu3.1_amd64.deb ...
Unpacking libboost-graph-parallel1.83.0 (1.83.0-2.1ubuntu3.1) ...
Selecting previously unselected package libboost-graph-parallel1.83-dev.
Preparing to unpack .../074-libboost-graph-parallel1.83-dev_1.83.0-2.1ubuntu3.1_amd64.deb ...
Unpacking libboost-graph-parallel1.83-dev (1.83.0-2.1ubuntu3.1) ...
Selecting previously unselected package libboost-graph-parallel-dev.
Preparing to unpack .../075-libboost-graph-parallel-dev_1.83.0.1ubuntu2_amd64.deb ...
Unpacking libboost-graph-parallel-dev (1.83.0.1ubuntu2) ...
Selecting previously unselected package libboost-iostreams1.83.0:amd64.
Preparing to unpack .../076-libboost-iostreams1.83.0_1.83.0-2.1ubuntu3.1_amd64.deb ...
Unpacking libboost-iostreams1.83.0:amd64 (1.83.0-2.1ubuntu3.1) ...
Selecting previously unselected package libboost-iostreams1.83-dev:amd64.
Preparing to unpack .../077-libboost-iostreams1.83-dev_1.83.0-2.1ubuntu3.1_amd64.deb ...
Unpacking libboost-iostreams1.83-dev:amd64 (1.83.0-2.1ubuntu3.1) ...
Selecting previously unselected package libboost-iostreams-dev:amd64.
Preparing to unpack .../078-libboost-iostreams-dev_1.83.0.1ubuntu2_amd64.deb ...
Unpacking libboost-iostreams-dev:amd64 (1.83.0.1ubuntu2) ...
Selecting previously unselected package libboost-json1.83.0:amd64.
Preparing to unpack .../079-libboost-json1.83.0_1.83.0-2.1ubuntu3.1_amd64.deb ...
Unpacking libboost-json1.83.0:amd64 (1.83.0-2.1ubuntu3.1) ...
Selecting previously unselected package libboost-json1.83-dev:amd64.
Preparing to unpack .../080-libboost-json1.83-dev_1.83.0-2.1ubuntu3.1_amd64.deb ...
Unpacking libboost-json1.83-dev:amd64 (1.83.0-2.1ubuntu3.1) ...
Selecting previously unselected package libboost-json-dev:amd64.
Preparing to unpack .../081-libboost-json-dev_1.83.0.1ubuntu2_amd64.deb ...
Unpacking libboost-json-dev:amd64 (1.83.0.1ubuntu2) ...
Selecting previously unselected package libboost-locale1.83.0:amd64.
Preparing to unpack .../082-libboost-locale1.83.0_1.83.0-2.1ubuntu3.1_amd64.deb ...
Unpacking libboost-locale1.83.0:amd64 (1.83.0-2.1ubuntu3.1) ...
Selecting previously unselected package libboost-locale1.83-dev:amd64.
Preparing to unpack .../083-libboost-locale1.83-dev_1.83.0-2.1ubuntu3.1_amd64.deb ...
Unpacking libboost-locale1.83-dev:amd64 (1.83.0-2.1ubuntu3.1) ...
Selecting previously unselected package libboost-locale-dev:amd64.
Preparing to unpack .../084-libboost-locale-dev_1.83.0.1ubuntu2_amd64.deb ...
Unpacking libboost-locale-dev:amd64 (1.83.0.1ubuntu2) ...
Selecting previously unselected package libboost-log1.83.0.
Preparing to unpack .../085-libboost-log1.83.0_1.83.0-2.1ubuntu3.1_amd64.deb ...
Unpacking libboost-log1.83.0 (1.83.0-2.1ubuntu3.1) ...
Selecting previously unselected package libboost-log1.83-dev.
Preparing to unpack .../086-libboost-log1.83-dev_1.83.0-2.1ubuntu3.1_amd64.deb ...
Unpacking libboost-log1.83-dev (1.83.0-2.1ubuntu3.1) ...
Selecting previously unselected package libboost-log-dev.
Preparing to unpack .../087-libboost-log-dev_1.83.0.1ubuntu2_amd64.deb ...
Unpacking libboost-log-dev (1.83.0.1ubuntu2) ...
Selecting previously unselected package libboost-math1.83.0:amd64.
Preparing to unpack .../088-libboost-math1.83.0_1.83.0-2.1ubuntu3.1_amd64.deb ...
Unpacking libboost-math1.83.0:amd64 (1.83.0-2.1ubuntu3.1) ...
Selecting previously unselected package libboost-math1.83-dev:amd64.
Preparing to unpack .../089-libboost-math1.83-dev_1.83.0-2.1ubuntu3.1_amd64.deb ...
Unpacking libboost-math1.83-dev:amd64 (1.83.0-2.1ubuntu3.1) ...
Selecting previously unselected package libboost-math-dev:amd64.
Preparing to unpack .../090-libboost-math-dev_1.83.0.1ubuntu2_amd64.deb ...
Unpacking libboost-math-dev:amd64 (1.83.0.1ubuntu2) ...
Selecting previously unselected package openmpi-common.
Preparing to unpack .../091-openmpi-common_4.1.6-7ubuntu2_all.deb ...
Unpacking openmpi-common (4.1.6-7ubuntu2) ...
Selecting previously unselected package libnl-3-dev:amd64.
Preparing to unpack .../092-libnl-3-dev_3.7.0-0.3build1.1_amd64.deb ...
Unpacking libnl-3-dev:amd64 (3.7.0-0.3build1.1) ...
Selecting previously unselected package libnl-route-3-dev:amd64.
Preparing to unpack .../093-libnl-route-3-dev_3.7.0-0.3build1.1_amd64.deb ...
Unpacking libnl-route-3-dev:amd64 (3.7.0-0.3build1.1) ...
Selecting previously unselected package libibverbs-dev:amd64.
Preparing to unpack .../094-libibverbs-dev_50.0-2ubuntu0.2_amd64.deb ...
Unpacking libibverbs-dev:amd64 (50.0-2ubuntu0.2) ...
Selecting previously unselected package libnuma-dev:amd64.
Preparing to unpack .../095-libnuma-dev_2.0.18-1build1_amd64.deb ...
Unpacking libnuma-dev:amd64 (2.0.18-1build1) ...
Selecting previously unselected package libltdl-dev:amd64.
Preparing to unpack .../096-libltdl-dev_2.4.7-7build1_amd64.deb ...
Unpacking libltdl-dev:amd64 (2.4.7-7build1) ...
Selecting previously unselected package libhwloc-dev:amd64.
Preparing to unpack .../097-libhwloc-dev_2.10.0-1build1_amd64.deb ...
Unpacking libhwloc-dev:amd64 (2.10.0-1build1) ...
Selecting previously unselected package libevent-2.1-7t64:amd64.
Preparing to unpack .../098-libevent-2.1-7t64_2.1.12-stable-9ubuntu2_amd64.deb ...
Unpacking libevent-2.1-7t64:amd64 (2.1.12-stable-9ubuntu2) ...
Selecting previously unselected package libevent-extra-2.1-7t64:amd64.
Preparing to unpack .../099-libevent-extra-2.1-7t64_2.1.12-stable-9ubuntu2_amd64.deb ...
Unpacking libevent-extra-2.1-7t64:amd64 (2.1.12-stable-9ubuntu2) ...
Selecting previously unselected package libevent-openssl-2.1-7t64:amd64.
Preparing to unpack .../100-libevent-openssl-2.1-7t64_2.1.12-stable-9ubuntu2_amd64.deb ...
Unpacking libevent-openssl-2.1-7t64:amd64 (2.1.12-stable-9ubuntu2) ...
Selecting previously unselected package libevent-dev.
Preparing to unpack .../101-libevent-dev_2.1.12-stable-9ubuntu2_amd64.deb ...
Unpacking libevent-dev (2.1.12-stable-9ubuntu2) ...
Selecting previously unselected package libpmix-dev:amd64.
Preparing to unpack .../102-libpmix-dev_5.0.1-4.1build1_amd64.deb ...
Unpacking libpmix-dev:amd64 (5.0.1-4.1build1) ...
Selecting previously unselected package libjs-jquery-ui.
Preparing to unpack .../103-libjs-jquery-ui_1.13.2+dfsg-1_all.deb ...
Unpacking libjs-jquery-ui (1.13.2+dfsg-1) ...
Selecting previously unselected package openmpi-bin.
Preparing to unpack .../104-openmpi-bin_4.1.6-7ubuntu2_amd64.deb ...
Unpacking openmpi-bin (4.1.6-7ubuntu2) ...
Selecting previously unselected package libopenmpi-dev:amd64.
Preparing to unpack .../105-libopenmpi-dev_4.1.6-7ubuntu2_amd64.deb ...
Unpacking libopenmpi-dev:amd64 (4.1.6-7ubuntu2) ...
Selecting previously unselected package mpi-default-dev.
Preparing to unpack .../106-mpi-default-dev_1.15build1_amd64.deb ...
Unpacking mpi-default-dev (1.15build1) ...
Selecting previously unselected package libboost-mpi1.83-dev.
Preparing to unpack .../107-libboost-mpi1.83-dev_1.83.0-2.1ubuntu3.1_amd64.deb ...
Unpacking libboost-mpi1.83-dev (1.83.0-2.1ubuntu3.1) ...
Selecting previously unselected package libboost-mpi-dev.
Preparing to unpack .../108-libboost-mpi-dev_1.83.0.1ubuntu2_amd64.deb ...
Unpacking libboost-mpi-dev (1.83.0.1ubuntu2) ...
Selecting previously unselected package libboost-python1.83.0.
Preparing to unpack .../109-libboost-python1.83.0_1.83.0-2.1ubuntu3.1_amd64.deb ...
Unpacking libboost-python1.83.0 (1.83.0-2.1ubuntu3.1) ...
Selecting previously unselected package mpi-default-bin.
Preparing to unpack .../110-mpi-default-bin_1.15build1_amd64.deb ...
Unpacking mpi-default-bin (1.15build1) ...
Selecting previously unselected package libboost-mpi-python1.83.0.
Preparing to unpack .../111-libboost-mpi-python1.83.0_1.83.0-2.1ubuntu3.1_amd64.deb ...
Unpacking libboost-mpi-python1.83.0 (1.83.0-2.1ubuntu3.1) ...
Selecting previously unselected package libboost-mpi-python1.83-dev.
Preparing to unpack .../112-libboost-mpi-python1.83-dev_1.83.0-2.1ubuntu3.1_amd64.deb ...
Unpacking libboost-mpi-python1.83-dev (1.83.0-2.1ubuntu3.1) ...
Selecting previously unselected package libboost-mpi-python-dev.
Preparing to unpack .../113-libboost-mpi-python-dev_1.83.0.1ubuntu2_amd64.deb ...
Unpacking libboost-mpi-python-dev (1.83.0.1ubuntu2) ...
Selecting previously unselected package libboost-numpy1.83.0.
Preparing to unpack .../114-libboost-numpy1.83.0_1.83.0-2.1ubuntu3.1_amd64.deb ...
Unpacking libboost-numpy1.83.0 (1.83.0-2.1ubuntu3.1) ...
Selecting previously unselected package libboost-numpy1.83-dev.
Preparing to unpack .../115-libboost-numpy1.83-dev_1.83.0-2.1ubuntu3.1_amd64.deb ...
Unpacking libboost-numpy1.83-dev (1.83.0-2.1ubuntu3.1) ...
Selecting previously unselected package libboost-numpy-dev.
Preparing to unpack .../116-libboost-numpy-dev_1.83.0.1ubuntu2_amd64.deb ...
Unpacking libboost-numpy-dev (1.83.0.1ubuntu2) ...
Selecting previously unselected package libboost-program-options1.83.0:amd64.
Preparing to unpack .../117-libboost-program-options1.83.0_1.83.0-2.1ubuntu3.1_amd64.deb ...
Unpacking libboost-program-options1.83.0:amd64 (1.83.0-2.1ubuntu3.1) ...
Selecting previously unselected package libboost-program-options1.83-dev:amd64.
Preparing to unpack .../118-libboost-program-options1.83-dev_1.83.0-2.1ubuntu3.1_amd64.deb ...
Unpacking libboost-program-options1.83-dev:amd64 (1.83.0-2.1ubuntu3.1) ...
Selecting previously unselected package libboost-program-options-dev:amd64.
Preparing to unpack .../119-libboost-program-options-dev_1.83.0.1ubuntu2_amd64.deb ...
Unpacking libboost-program-options-dev:amd64 (1.83.0.1ubuntu2) ...
Selecting previously unselected package libboost-python1.83-dev.
Preparing to unpack .../120-libboost-python1.83-dev_1.83.0-2.1ubuntu3.1_amd64.deb ...
Unpacking libboost-python1.83-dev (1.83.0-2.1ubuntu3.1) ...
Selecting previously unselected package libboost-python-dev.
Preparing to unpack .../121-libboost-python-dev_1.83.0.1ubuntu2_amd64.deb ...
Unpacking libboost-python-dev (1.83.0.1ubuntu2) ...
Selecting previously unselected package libboost-random1.83.0:amd64.
Preparing to unpack .../122-libboost-random1.83.0_1.83.0-2.1ubuntu3.1_amd64.deb ...
Unpacking libboost-random1.83.0:amd64 (1.83.0-2.1ubuntu3.1) ...
Selecting previously unselected package libboost-random1.83-dev:amd64.
Preparing to unpack .../123-libboost-random1.83-dev_1.83.0-2.1ubuntu3.1_amd64.deb ...
Unpacking libboost-random1.83-dev:amd64 (1.83.0-2.1ubuntu3.1) ...
Selecting previously unselected package libboost-random-dev:amd64.
Preparing to unpack .../124-libboost-random-dev_1.83.0.1ubuntu2_amd64.deb ...
Unpacking libboost-random-dev:amd64 (1.83.0.1ubuntu2) ...
Selecting previously unselected package libboost-regex-dev:amd64.
Preparing to unpack .../125-libboost-regex-dev_1.83.0.1ubuntu2_amd64.deb ...
Unpacking libboost-regex-dev:amd64 (1.83.0.1ubuntu2) ...
Selecting previously unselected package libboost-serialization-dev:amd64.
Preparing to unpack .../126-libboost-serialization-dev_1.83.0.1ubuntu2_amd64.deb ...
Unpacking libboost-serialization-dev:amd64 (1.83.0.1ubuntu2) ...
Selecting previously unselected package libboost-stacktrace1.83.0:amd64.
Preparing to unpack .../127-libboost-stacktrace1.83.0_1.83.0-2.1ubuntu3.1_amd64.deb ...
Unpacking libboost-stacktrace1.83.0:amd64 (1.83.0-2.1ubuntu3.1) ...
Selecting previously unselected package libboost-stacktrace1.83-dev:amd64.
Preparing to unpack .../128-libboost-stacktrace1.83-dev_1.83.0-2.1ubuntu3.1_amd64.deb ...
Unpacking libboost-stacktrace1.83-dev:amd64 (1.83.0-2.1ubuntu3.1) ...
Selecting previously unselected package libboost-stacktrace-dev:amd64.
Preparing to unpack .../129-libboost-stacktrace-dev_1.83.0.1ubuntu2_amd64.deb ...
Unpacking libboost-stacktrace-dev:amd64 (1.83.0.1ubuntu2) ...
Selecting previously unselected package libboost-system-dev:amd64.
Preparing to unpack .../130-libboost-system-dev_1.83.0.1ubuntu2_amd64.deb ...
Unpacking libboost-system-dev:amd64 (1.83.0.1ubuntu2) ...
Selecting previously unselected package libboost-test-dev:amd64.
Preparing to unpack .../131-libboost-test-dev_1.83.0.1ubuntu2_amd64.deb ...
Unpacking libboost-test-dev:amd64 (1.83.0.1ubuntu2) ...
Selecting previously unselected package libboost-thread-dev:amd64.
Preparing to unpack .../132-libboost-thread-dev_1.83.0.1ubuntu2_amd64.deb ...
Unpacking libboost-thread-dev:amd64 (1.83.0.1ubuntu2) ...
Selecting previously unselected package libboost-timer1.83.0:amd64.
Preparing to unpack .../133-libboost-timer1.83.0_1.83.0-2.1ubuntu3.1_amd64.deb ...
Unpacking libboost-timer1.83.0:amd64 (1.83.0-2.1ubuntu3.1) ...
Selecting previously unselected package libboost-timer1.83-dev:amd64.
Preparing to unpack .../134-libboost-timer1.83-dev_1.83.0-2.1ubuntu3.1_amd64.deb ...
Unpacking libboost-timer1.83-dev:amd64 (1.83.0-2.1ubuntu3.1) ...
Selecting previously unselected package libboost-timer-dev:amd64.
Preparing to unpack .../135-libboost-timer-dev_1.83.0.1ubuntu2_amd64.deb ...
Unpacking libboost-timer-dev:amd64 (1.83.0.1ubuntu2) ...
Selecting previously unselected package libboost-type-erasure1.83.0:amd64.
Preparing to unpack .../136-libboost-type-erasure1.83.0_1.83.0-2.1ubuntu3.1_amd64.deb ...
Unpacking libboost-type-erasure1.83.0:amd64 (1.83.0-2.1ubuntu3.1) ...
Selecting previously unselected package libboost-type-erasure1.83-dev:amd64.
Preparing to unpack .../137-libboost-type-erasure1.83-dev_1.83.0-2.1ubuntu3.1_amd64.deb ...
Unpacking libboost-type-erasure1.83-dev:amd64 (1.83.0-2.1ubuntu3.1) ...
Selecting previously unselected package libboost-type-erasure-dev:amd64.
Preparing to unpack .../138-libboost-type-erasure-dev_1.83.0.1ubuntu2_amd64.deb ...
Unpacking libboost-type-erasure-dev:amd64 (1.83.0.1ubuntu2) ...
Selecting previously unselected package libboost-url1.83.0:amd64.
Preparing to unpack .../139-libboost-url1.83.0_1.83.0-2.1ubuntu3.1_amd64.deb ...
Unpacking libboost-url1.83.0:amd64 (1.83.0-2.1ubuntu3.1) ...
Selecting previously unselected package libboost-url1.83-dev:amd64.
Preparing to unpack .../140-libboost-url1.83-dev_1.83.0-2.1ubuntu3.1_amd64.deb ...
Unpacking libboost-url1.83-dev:amd64 (1.83.0-2.1ubuntu3.1) ...
Selecting previously unselected package libboost-url-dev:amd64.
Preparing to unpack .../141-libboost-url-dev_1.83.0.1ubuntu2_amd64.deb ...
Unpacking libboost-url-dev:amd64 (1.83.0.1ubuntu2) ...
Selecting previously unselected package libboost-wave1.83.0:amd64.
Preparing to unpack .../142-libboost-wave1.83.0_1.83.0-2.1ubuntu3.1_amd64.deb ...
Unpacking libboost-wave1.83.0:amd64 (1.83.0-2.1ubuntu3.1) ...
Selecting previously unselected package libboost-wave1.83-dev:amd64.
Preparing to unpack .../143-libboost-wave1.83-dev_1.83.0-2.1ubuntu3.1_amd64.deb ...
Unpacking libboost-wave1.83-dev:amd64 (1.83.0-2.1ubuntu3.1) ...
Selecting previously unselected package libboost-wave-dev:amd64.
Preparing to unpack .../144-libboost-wave-dev_1.83.0.1ubuntu2_amd64.deb ...
Unpacking libboost-wave-dev:amd64 (1.83.0.1ubuntu2) ...
Selecting previously unselected package libboost-nowide1.83.0.
Preparing to unpack .../145-libboost-nowide1.83.0_1.83.0-2.1ubuntu3.1_amd64.deb ...
Unpacking libboost-nowide1.83.0 (1.83.0-2.1ubuntu3.1) ...
Selecting previously unselected package libboost-nowide1.83-dev.
Preparing to unpack .../146-libboost-nowide1.83-dev_1.83.0-2.1ubuntu3.1_amd64.deb ...
Unpacking libboost-nowide1.83-dev (1.83.0-2.1ubuntu3.1) ...
Selecting previously unselected package libboost-nowide-dev.
Preparing to unpack .../147-libboost-nowide-dev_1.83.0.1ubuntu2_amd64.deb ...
Unpacking libboost-nowide-dev (1.83.0.1ubuntu2) ...
Selecting previously unselected package libboost-all-dev.
Preparing to unpack .../148-libboost-all-dev_1.83.0.1ubuntu2_amd64.deb ...
Unpacking libboost-all-dev (1.83.0.1ubuntu2) ...
Selecting previously unselected package libcaf-openmpi-3t64:amd64.
Preparing to unpack .../149-libcaf-openmpi-3t64_2.10.2+ds-2.1build2_amd64.deb ...
Unpacking libcaf-openmpi-3t64:amd64 (2.10.2+ds-2.1build2) ...
Selecting previously unselected package libcoarrays-dev:amd64.
Preparing to unpack .../150-libcoarrays-dev_2.10.2+ds-2.1build2_amd64.deb ...
Unpacking libcoarrays-dev:amd64 (2.10.2+ds-2.1build2) ...
Selecting previously unselected package libcoarrays-openmpi-dev:amd64.
Preparing to unpack .../151-libcoarrays-openmpi-dev_2.10.2+ds-2.1build2_amd64.deb ...
Unpacking libcoarrays-openmpi-dev:amd64 (2.10.2+ds-2.1build2) ...
Selecting previously unselected package libtool.
Preparing to unpack .../152-libtool_2.4.7-7build1_all.deb ...
Unpacking libtool (2.4.7-7build1) ...
Setting up libboost-python1.83.0 (1.83.0-2.1ubuntu3.1) ...
Setting up libboost-program-options1.83.0:amd64 (1.83.0-2.1ubuntu3.1) ...
Setting up libibverbs1:amd64 (50.0-2ubuntu0.2) ...
Setting up libboost-stacktrace1.83.0:amd64 (1.83.0-2.1ubuntu3.1) ...
Setting up libboost1.83-dev:amd64 (1.83.0-2.1ubuntu3.1) ...
Setting up libboost-nowide1.83.0 (1.83.0-2.1ubuntu3.1) ...
Setting up libboost-date-time1.83.0:amd64 (1.83.0-2.1ubuntu3.1) ...
Setting up libboost-json1.83.0:amd64 (1.83.0-2.1ubuntu3.1) ...
Setting up ibverbs-providers:amd64 (50.0-2ubuntu0.2) ...
Setting up libboost-timer1.83.0:amd64 (1.83.0-2.1ubuntu3.1) ...
Setting up libevent-pthreads-2.1-7t64:amd64 (2.1.12-stable-9ubuntu2) ...
Setting up libboost-regex1.83.0:amd64 (1.83.0-2.1ubuntu3.1) ...
Setting up libevent-openssl-2.1-7t64:amd64 (2.1.12-stable-9ubuntu2) ...
Setting up libboost-system1.83.0:amd64 (1.83.0-2.1ubuntu3.1) ...
Setting up libboost-context1.83.0:amd64 (1.83.0-2.1ubuntu3.1) ...
Setting up libboost-program-options1.83-dev:amd64 (1.83.0-2.1ubuntu3.1) ...
Setting up libboost-random1.83.0:amd64 (1.83.0-2.1ubuntu3.1) ...
Setting up libboost-thread1.83.0:amd64 (1.83.0-2.1ubuntu3.1) ...
Setting up m4 (1.4.19-4build1) ...
Setting up libevent-2.1-7t64:amd64 (2.1.12-stable-9ubuntu2) ...
Setting up libboost-filesystem1.83.0:amd64 (1.83.0-2.1ubuntu3.1) ...
Setting up libboost-url1.83.0:amd64 (1.83.0-2.1ubuntu3.1) ...
Setting up libnuma-dev:amd64 (2.0.18-1build1) ...
Setting up libboost-atomic1.83.0:amd64 (1.83.0-2.1ubuntu3.1) ...
Setting up libboost-serialization1.83.0:amd64 (1.83.0-2.1ubuntu3.1) ...
Setting up libboost-numpy1.83.0 (1.83.0-2.1ubuntu3.1) ...
Setting up autotools-dev (20220109.1) ...
Setting up libjs-jquery-ui (1.13.2+dfsg-1) ...
Setting up libmunge2:amd64 (0.5.15-4build1) ...
Setting up libllvm17t64:amd64 (1:17.0.6-9ubuntu1) ...
Setting up libboost-program-options-dev:amd64 (1.83.0.1ubuntu2) ...
Setting up libboost-chrono1.83.0t64:amd64 (1.83.0-2.1ubuntu3.1) ...
Setting up libboost-iostreams1.83.0:amd64 (1.83.0-2.1ubuntu3.1) ...
Setting up libboost-python1.83-dev (1.83.0-2.1ubuntu3.1) ...
Setting up libboost-nowide1.83-dev (1.83.0-2.1ubuntu3.1) ...
Setting up libhwloc15:amd64 (2.10.0-1build1) ...
Setting up libboost-stacktrace1.83-dev:amd64 (1.83.0-2.1ubuntu3.1) ...
Setting up libboost-numpy1.83-dev (1.83.0-2.1ubuntu3.1) ...
Setting up icu-devtools (74.2-1ubuntu3.1) ...
Setting up libboost-test1.83.0:amd64 (1.83.0-2.1ubuntu3.1) ...
Setting up libboost-fiber1.83.0:amd64 (1.83.0-2.1ubuntu3.1) ...
Setting up libboost-atomic1.83-dev:amd64 (1.83.0-2.1ubuntu3.1) ...
Setting up autoconf (2.71-3) ...
Setting up libevent-extra-2.1-7t64:amd64 (2.1.12-stable-9ubuntu2) ...
Setting up libboost-atomic-dev:amd64 (1.83.0.1ubuntu2) ...
Setting up libnl-3-dev:amd64 (3.7.0-0.3build1.1) ...
Setting up libboost-exception1.83-dev:amd64 (1.83.0-2.1ubuntu3.1) ...
Setting up libboost-stacktrace-dev:amd64 (1.83.0.1ubuntu2) ...
Setting up libboost-graph1.83.0:amd64 (1.83.0-2.1ubuntu3.1) ...
Setting up libpsm2-2 (11.2.185-2build1) ...
Setting up openmpi-common (4.1.6-7ubuntu2) ...
Setting up libboost-container1.83.0:amd64 (1.83.0-2.1ubuntu3.1) ...
Setting up librdmacm1t64:amd64 (50.0-2ubuntu0.2) ...
Setting up libboost-type-erasure1.83.0:amd64 (1.83.0-2.1ubuntu3.1) ...
Setting up libboost-dev:amd64 (1.83.0.1ubuntu2) ...
Setting up libamd-comgr2:amd64 (6.0+git20231212.4510c28+dfsg-3build2) ...
Setting up libboost-system1.83-dev:amd64 (1.83.0-2.1ubuntu3.1) ...
Setting up libpsm-infinipath1 (3.3+20.604758e7-6.3build1) ...
update-alternatives: using /usr/lib/libpsm1/libpsm_infinipath.so.1.16 to provide /usr/lib/x86_64-linux-gnu/libpsm_infinipath.so.1 (libpsm_infinipath.so.1) in auto mode
Setting up libboost-math1.83.0:amd64 (1.83.0-2.1ubuntu3.1) ...
Setting up libgfortran-13-dev:amd64 (13.3.0-6ubuntu2~24.04) ...
Setting up libicu-dev:amd64 (74.2-1ubuntu3.1) ...
Setting up libboost1.83-tools-dev (1.83.0-2.1ubuntu3.1) ...
Setting up libhsakmt1:amd64 (5.7.0-1build1) ...
Setting up automake (1:1.16.5-1.3ubuntu1) ...
update-alternatives: using /usr/bin/automake-1.16 to provide /usr/bin/automake (automake) in auto mode
Setting up libfabric1:amd64 (1.17.0-3build2) ...
Setting up libboost-wave1.83.0:amd64 (1.83.0-2.1ubuntu3.1) ...
Setting up libboost-coroutine1.83.0:amd64 (1.83.0-2.1ubuntu3.1) ...
Setting up libboost-chrono1.83-dev:amd64 (1.83.0-2.1ubuntu3.1) ...
Setting up libboost-math1.83-dev:amd64 (1.83.0-2.1ubuntu3.1) ...
Setting up libtool (2.4.7-7build1) ...
Setting up libboost-chrono-dev:amd64 (1.83.0.1ubuntu2) ...
Setting up libboost-log1.83.0 (1.83.0-2.1ubuntu3.1) ...
Setting up libboost-math-dev:amd64 (1.83.0.1ubuntu2) ...
Setting up libboost-system-dev:amd64 (1.83.0.1ubuntu2) ...
Setting up libboost-serialization1.83-dev:amd64 (1.83.0-2.1ubuntu3.1) ...
Setting up libboost-locale1.83.0:amd64 (1.83.0-2.1ubuntu3.1) ...
Setting up libboost-test1.83-dev:amd64 (1.83.0-2.1ubuntu3.1) ...
Setting up libboost-url1.83-dev:amd64 (1.83.0-2.1ubuntu3.1) ...
Setting up libboost-tools-dev (1.83.0.1ubuntu2) ...
Setting up libboost-filesystem1.83-dev:amd64 (1.83.0-2.1ubuntu3.1) ...
Setting up libboost-exception-dev:amd64 (1.83.0.1ubuntu2) ...
Setting up libhwloc-plugins:amd64 (2.10.0-1build1) ...
Setting up libboost-nowide-dev (1.83.0.1ubuntu2) ...
Setting up gfortran-13-x86-64-linux-gnu (13.3.0-6ubuntu2~24.04) ...
Setting up libboost-python-dev (1.83.0.1ubuntu2) ...
Setting up libboost-test-dev:amd64 (1.83.0.1ubuntu2) ...
Setting up libnl-route-3-dev:amd64 (3.7.0-0.3build1.1) ...
Setting up libltdl-dev:amd64 (2.4.7-7build1) ...
Setting up libboost-timer1.83-dev:amd64 (1.83.0-2.1ubuntu3.1) ...
Setting up libboost-container1.83-dev:amd64 (1.83.0-2.1ubuntu3.1) ...
Setting up gfortran-13 (13.3.0-6ubuntu2~24.04) ...
Setting up libboost-date-time1.83-dev:amd64 (1.83.0-2.1ubuntu3.1) ...
Setting up libboost-numpy-dev (1.83.0.1ubuntu2) ...
Setting up libevent-dev (2.1.12-stable-9ubuntu2) ...
Setting up libboost-regex1.83-dev:amd64 (1.83.0-2.1ubuntu3.1) ...
Setting up libboost-random1.83-dev:amd64 (1.83.0-2.1ubuntu3.1) ...
Setting up libboost-serialization-dev:amd64 (1.83.0.1ubuntu2) ...
Setting up libpmix2t64:amd64 (5.0.1-4.1build1) ...
Setting up libboost-date-time-dev:amd64 (1.83.0.1ubuntu2) ...
Setting up libhsa-runtime64-1 (5.7.1-2build1) ...
Setting up libboost-url-dev:amd64 (1.83.0.1ubuntu2) ...
Setting up libhwloc-dev:amd64 (2.10.0-1build1) ...
Setting up libboost-regex-dev:amd64 (1.83.0.1ubuntu2) ...
Setting up libboost-timer-dev:amd64 (1.83.0.1ubuntu2) ...
Setting up libboost-filesystem-dev:amd64 (1.83.0.1ubuntu2) ...
Setting up libpmix-dev:amd64 (5.0.1-4.1build1) ...
Setting up libboost-thread1.83-dev:amd64 (1.83.0-2.1ubuntu3.1) ...
Setting up libboost-json1.83-dev:amd64 (1.83.0-2.1ubuntu3.1) ...
Setting up libboost-wave1.83-dev:amd64 (1.83.0-2.1ubuntu3.1) ...
Setting up libboost-locale1.83-dev:amd64 (1.83.0-2.1ubuntu3.1) ...
Setting up libcoarrays-dev:amd64 (2.10.2+ds-2.1build2) ...
Setting up libboost-iostreams1.83-dev:amd64 (1.83.0-2.1ubuntu3.1) ...
Setting up libboost-type-erasure1.83-dev:amd64 (1.83.0-2.1ubuntu3.1) ...
Setting up libboost-random-dev:amd64 (1.83.0.1ubuntu2) ...
Setting up libboost-locale-dev:amd64 (1.83.0.1ubuntu2) ...
Setting up libboost-wave-dev:amd64 (1.83.0.1ubuntu2) ...
Setting up libboost-iostreams-dev:amd64 (1.83.0.1ubuntu2) ...
Setting up libibverbs-dev:amd64 (50.0-2ubuntu0.2) ...
Setting up gfortran-x86-64-linux-gnu (4:13.2.0-7ubuntu1) ...
Setting up libboost-graph1.83-dev:amd64 (1.83.0-2.1ubuntu3.1) ...
Setting up gfortran (4:13.2.0-7ubuntu1) ...
update-alternatives: using /usr/bin/gfortran to provide /usr/bin/f95 (f95) in auto mode
update-alternatives: warning: skip creation of /usr/share/man/man1/f95.1.gz because associated file /usr/share/man/man1/gfortran.1.gz (of link group f95) doesn't exist
update-alternatives: using /usr/bin/gfortran to provide /usr/bin/f77 (f77) in auto mode
update-alternatives: warning: skip creation of /usr/share/man/man1/f77.1.gz because associated file /usr/share/man/man1/gfortran.1.gz (of link group f77) doesn't exist
Setting up libboost-container-dev:amd64 (1.83.0.1ubuntu2) ...
Setting up libboost-type-erasure-dev:amd64 (1.83.0.1ubuntu2) ...
Setting up libboost-context1.83-dev:amd64 (1.83.0-2.1ubuntu3.1) ...
Setting up libboost-coroutine1.83-dev:amd64 (1.83.0-2.1ubuntu3.1) ...
Setting up libamdhip64-5 (5.7.1-3) ...
Setting up libboost-fiber1.83-dev:amd64 (1.83.0-2.1ubuntu3.1) ...
Setting up libboost-coroutine-dev:amd64 (1.83.0.1ubuntu2) ...
Setting up libboost-log1.83-dev (1.83.0-2.1ubuntu3.1) ...
Setting up libboost-json-dev:amd64 (1.83.0.1ubuntu2) ...
Setting up libboost-log-dev (1.83.0.1ubuntu2) ...
Setting up libboost-thread-dev:amd64 (1.83.0.1ubuntu2) ...
Setting up libboost-fiber-dev:amd64 (1.83.0.1ubuntu2) ...
Setting up libboost-graph-dev:amd64 (1.83.0.1ubuntu2) ...
Setting up libucx0:amd64 (1.16.0+ds-5ubuntu1) ...
Setting up libboost-context-dev:amd64 (1.83.0.1ubuntu2) ...
Setting up libopenmpi3t64:amd64 (4.1.6-7ubuntu2) ...
Setting up libboost-mpi1.83.0 (1.83.0-2.1ubuntu3.1) ...
Setting up openmpi-bin (4.1.6-7ubuntu2) ...
update-alternatives: using /usr/bin/mpirun.openmpi to provide /usr/bin/mpirun (mpirun) in auto mode
update-alternatives: using /usr/bin/mpicc.openmpi to provide /usr/bin/mpicc (mpi) in auto mode
Setting up libboost-graph-parallel1.83.0 (1.83.0-2.1ubuntu3.1) ...
Setting up mpi-default-bin (1.15build1) ...
Setting up libcaf-openmpi-3t64:amd64 (2.10.2+ds-2.1build2) ...
Setting up libopenmpi-dev:amd64 (4.1.6-7ubuntu2) ...
update-alternatives: using /usr/lib/x86_64-linux-gnu/openmpi/include to provide /usr/include/x86_64-linux-gnu/mpi (mpi-x86_64-linux-gnu) in auto mode
Setting up libboost-graph-parallel1.83-dev (1.83.0-2.1ubuntu3.1) ...
Setting up libboost-mpi-python1.83.0 (1.83.0-2.1ubuntu3.1) ...
Setting up libcoarrays-openmpi-dev:amd64 (2.10.2+ds-2.1build2) ...
update-alternatives: using /usr/lib/x86_64-linux-gnu/open-coarrays/openmpi/bin/caf to provide /usr/bin/caf.openmpi (caf-openmpi) in auto mode
update-alternatives: using /usr/bin/caf.openmpi to provide /usr/bin/caf (caf) in auto mode
Setting up libboost-graph-parallel-dev (1.83.0.1ubuntu2) ...
Setting up mpi-default-dev (1.15build1) ...
Setting up libboost-mpi1.83-dev (1.83.0-2.1ubuntu3.1) ...
Setting up libboost-mpi-dev (1.83.0.1ubuntu2) ...
Setting up libboost-mpi-python1.83-dev (1.83.0-2.1ubuntu3.1) ...
Setting up libboost-mpi-python-dev (1.83.0.1ubuntu2) ...
Setting up libboost-all-dev (1.83.0.1ubuntu2) ...
Processing triggers for libc-bin (2.39-0ubuntu8.4) ...
Processing triggers for man-db (2.12.0-4build2) ...
Processing triggers for install-info (7.1-3build2) ...
Scanning processes...                                                                                                                                                                                         
Scanning candidates...                                                                                                                                                                                        
Scanning linux images...                                                                                                                                                                                      

Running kernel seems to be up-to-date.

Restarting services...

Service restarts being deferred:
 systemctl restart NetworkManager.service
 /etc/needrestart/restart.d/dbus.service

No containers need to be restarted.

No user sessions are running outdated binaries.

No VM guests are running outdated hypervisor (qemu) binaries on this host.
N: Ignoring file 'ubuntu.sources.bkp' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension
W: Download is performed unsandboxed as root as file '/var/cache/apt/archives/partial/libibverbs1_50.0-2ubuntu0.2_amd64.deb' couldn't be accessed by user '_apt'. - pkgAcquire::Run (13: Permission denied)
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# ls data/training/v1
Kathbath
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# ls data/training/v1/Kathbath
raw_metadata.json  train_manifest.json  wavs
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# ls data/training/v2
iisc_mile  master_manifest.json  shrutilipi  vaani
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# python generate_master_manifest.py v1
python: can't open file '/mnt/data/asr-finetuning/generate_master_manifest.py': [Errno 2] No such file or directory
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# cd data/training
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning/data/training# python generate_master_manifest.py v1
---  Generating Master Manifest for v1 ---
    Found 1 datasets
    Reading Kathbath...
      + Added 67376 items (145.54 hours)

    Saving to /mnt/data/asr-finetuning/data/training/v1/master_manifest.json...
------------------------------------------------------------
 MASTER MANIFEST COMPLETE
   VERSION: v1
   TOTAL SAMPLES: 67376
   TOTAL DURATION: 145.54 hours
   LOCATION: /mnt/data/asr-finetuning/data/training/v1/master_manifest.json
------------------------------------------------------------
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning/data/training# ls data/training/v1
ls: cannot access 'data/training/v1': No such file or directory
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning/data/training# cd ..
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning/data# cd ..
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# ls data/training/v1
Kathbath  master_manifest.json
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# ls training/v2
ls: cannot access 'training/v2': No such file or directory
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# ls data/training/v2
iisc_mile  master_manifest.json  shrutilipi  vaani
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# python3 << 'EOF'
import os

# --- Configuration ---
OUTPUT_DIR = "data/training/v3"
OUTPUT_FILE = os.path.join(OUTPUT_DIR, "master_manifest.json")

SOURCES = [
    "data/processed_data/Kathbath/train_manifest.json",
    "data/processed_data/Shrutilipi/train_manifest.json",
    "data/processed_data/Vaani/train_manifest.json",
    "data/processed_data/IISc_MILE/train_manifest.json"
]

# 1. Create Output Directory
os.makedirs(OUTPUT_DIR, exist_ok=True)
print(f" Created/Verified directory: {OUTPUT_DIR}")

total_count = 0

# 2. Open Output File
print(f" Writing to: {OUTPUT_FILE}")
with open(OUTPUT_FILE, 'w', encoding='utf-8') as outfile:
    
    # 3. Loop through sources
    for src in SOURCES:
        if not os.path.exists(src):
            print(f"  WARNING: Source not found: {src}")
            continue
        
        print(f"    Merging: {src}")
        
        count = 0
        with open(src, 'r', encoding='utf-8') as infile:
            for line in infile:
                if line.strip():
                    outfile.write(line)
                    count += 1
        print(f"      -> Added {count} samples")
        total_count += count

print("-" * 50)
print(f" DONE. Total Samples: {total_count}")
EOF
 Created/Verified directory: data/training/v3
 Writing to: data/training/v3/master_manifest.json
  WARNING: Source not found: data/processed_data/Kathbath/train_manifest.json
    Merging: data/processed_data/Shrutilipi/train_manifest.json
      -> Added 10 samples
    Merging: data/processed_data/Vaani/train_manifest.json
      -> Added 10 samples
  WARNING: Source not found: data/processed_data/IISc_MILE/train_manifest.json
--------------------------------------------------
 DONE. Total Samples: 20
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# python3 << 'EOF'
import os

# --- Configuration ---
OUTPUT_DIR = "data/training/v2.1"
OUTPUT_FILE = os.path.join(OUTPUT_DIR, "master_manifest.json")

SOURCES = [
    "data/training/v1/master_manifest.json",
    "data/training/v2/master_manifest.json",
]

# 1. Create Output Directory
os.makedirs(OUTPUT_DIR, exist_ok=True)
print(f" Created/Verified directory: {OUTPUT_DIR}")

total_count = 0

# 2. Open Output File
print(f" Writing to: {OUTPUT_FILE}")
with open(OUTPUT_FILE, 'w', encoding='utf-8') as outfile:
    
    # 3. Loop through sources
    for src in SOURCES:
        if not os.path.exists(src):
            print(f"  WARNING: Source not found: {src}")
            continue
        
        print(f"    Merging: {src}")
        
        count = 0
        with open(src, 'r', encoding='utf-8') as infile:
            for line in infile:
                if line.strip():
                    outfile.write(line)
                    count += 1
        print(f"      -> Added {count} samples")
        total_count += count

print("-" * 50)
print(f" DONE. Total Samples: {total_count}")
EOF
 Created/Verified directory: data/training/v2.1
 Writing to: data/training/v2.1/master_manifest.json
    Merging: data/training/v1/master_manifest.json
      -> Added 67376 samples
    Merging: data/training/v2/master_manifest.json
      -> Added 349645 samples
--------------------------------------------------
 DONE. Total Samples: 417021
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# rm -rf data/training/v3
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# rm -rf data/training/v3
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# git status
Refresh index: 100% (110/110), done.
On branch gpu-box
Your branch is up to date with 'origin/gpu-box'.

Changes not staged for commit:
  (use "git add <file>..." to update what will be committed)
  (use "git restore <file>..." to discard changes in working directory)
	modified:   benchmark_results_conf16m/benchmark_report.json
	modified:   benchmark_results_conf16m/en_clean_read/predictions.json
	modified:   benchmark_results_conf16m/kn_clean_read/predictions.json
	modified:   benchmark_results_conf16m/kn_en_codeswitch/predictions.json
	modified:   data/final_dataset/master_train_manifest.json
	modified:   data/processed_data/IndicVoices/raw_metadata.json
	modified:   data/processed_data/IndicVoices/train_manifest.json
	modified:   data/processed_data/Shrutilipi/raw_metadata.json
	modified:   data/processed_data/Shrutilipi/train_manifest.json
	modified:   data/processed_data/Vaani/raw_metadata.json
	modified:   data/processed_data/Vaani/train_manifest.json
	modified:   data/training/v1/Kathbath/raw_metadata.json
	modified:   data/training/v1/Kathbath/train_manifest.json
	modified:   data/training/v2/iisc_mile/train_manifest.json
	modified:   data/training/v2/shrutilipi/raw_metadata.json
	modified:   data/training/v2/vaani/raw_metadata.json
	modified:   data/training/v2/vaani/train_manifest.json
	modified:   evaluation/benchmarking/curation/evaluation/benchmarking/data/v1/kn_clean_read.json
	modified:   evaluation/benchmarking/curation/evaluation/benchmarking/data/v1/kn_en_codeswitch.json
	modified:   evaluation/benchmarking/curation/test_data/Kathbath/raw_metadata.json
	modified:   evaluation/benchmarking/curation/test_data/Kathbath/test_manifest.json
	modified:   evaluation/benchmarking/curation/test_data/Vaani/raw_metadata.json
	modified:   evaluation/benchmarking/curation/test_data/Vaani/test_manifest.json
	modified:   evaluation/benchmarking/data/v1/en_clean_read.json
	modified:   evaluation/benchmarking/data/v1/kn_clean_read.json
	modified:   evaluation/benchmarking/data/v1/kn_en_codeswitch.json
	modified:   models/results_a14b_indicconf_600m/benchmark_report.json
	modified:   models/results_a14b_indicconf_600m/results/predictions.json
	modified:   models/results_ai4b_indicconf_100m/benchmark_report.json
	modified:   models/results_ai4b_indicconf_100m/results/predictions.json
	modified:   models/results_conf_100m_kathbath/predictions.json
	modified:   models/results_conf_16m_kathbath/predictions.json
	modified:   pipelines/personal_preprocessing_pipelines/dataset_schemas.json
	modified:   training/data_prep/verify_dataset.py
	modified:   training/train.py

Untracked files:
  (use "git add <file>..." to include in what will be committed)
	data/training/v1/master_manifest.json
	data/training/v2.1/
	data/training/v2/master_manifest.json
	models/benchmark_report.json
	models/report.txt
	models/results_conf_100m_scaleup_v2_final/
	models/results_conf_100m_v2/

no changes added to commit (use "git add" and/or "git commit -a")
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# git status --untracked-files=all
Refresh index: 100% (110/110), done.
On branch gpu-box
Your branch is up to date with 'origin/gpu-box'.

Changes not staged for commit:
  (use "git add <file>..." to update what will be committed)
  (use "git restore <file>..." to discard changes in working directory)
	modified:   benchmark_results_conf16m/benchmark_report.json
	modified:   benchmark_results_conf16m/en_clean_read/predictions.json
	modified:   benchmark_results_conf16m/kn_clean_read/predictions.json
	modified:   benchmark_results_conf16m/kn_en_codeswitch/predictions.json
	modified:   data/final_dataset/master_train_manifest.json
	modified:   data/processed_data/IndicVoices/raw_metadata.json
	modified:   data/processed_data/IndicVoices/train_manifest.json
	modified:   data/processed_data/Shrutilipi/raw_metadata.json
	modified:   data/processed_data/Shrutilipi/train_manifest.json
	modified:   data/processed_data/Vaani/raw_metadata.json
	modified:   data/processed_data/Vaani/train_manifest.json
	modified:   data/training/v1/Kathbath/raw_metadata.json
	modified:   data/training/v1/Kathbath/train_manifest.json
	modified:   data/training/v2/iisc_mile/train_manifest.json
	modified:   data/training/v2/shrutilipi/raw_metadata.json
	modified:   data/training/v2/vaani/raw_metadata.json
	modified:   data/training/v2/vaani/train_manifest.json
	modified:   evaluation/benchmarking/curation/evaluation/benchmarking/data/v1/kn_clean_read.json
	modified:   evaluation/benchmarking/curation/evaluation/benchmarking/data/v1/kn_en_codeswitch.json
	modified:   evaluation/benchmarking/curation/test_data/Kathbath/raw_metadata.json
	modified:   evaluation/benchmarking/curation/test_data/Kathbath/test_manifest.json
	modified:   evaluation/benchmarking/curation/test_data/Vaani/raw_metadata.json
	modified:   evaluation/benchmarking/curation/test_data/Vaani/test_manifest.json
	modified:   evaluation/benchmarking/data/v1/en_clean_read.json
	modified:   evaluation/benchmarking/data/v1/kn_clean_read.json
	modified:   evaluation/benchmarking/data/v1/kn_en_codeswitch.json
	modified:   models/results_a14b_indicconf_600m/benchmark_report.json
	modified:   models/results_a14b_indicconf_600m/results/predictions.json
	modified:   models/results_ai4b_indicconf_100m/benchmark_report.json
	modified:   models/results_ai4b_indicconf_100m/results/predictions.json
	modified:   models/results_conf_100m_kathbath/predictions.json
	modified:   models/results_conf_16m_kathbath/predictions.json
	modified:   pipelines/personal_preprocessing_pipelines/dataset_schemas.json
	modified:   training/data_prep/verify_dataset.py
	modified:   training/train.py

Untracked files:
  (use "git add <file>..." to include in what will be committed)
	data/training/v1/master_manifest.json
	data/training/v2.1/master_manifest.json
	data/training/v2/master_manifest.json
	models/benchmark_report.json
	models/report.txt
	models/results_conf_100m_scaleup_v2_final/predictions.json
	models/results_conf_100m_v2/predictions.json

no changes added to commit (use "git add" and/or "git commit -a")
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# git lfs track "**/predictions.json"
git lfs track "**/master_manifest.json"
git lfs track "**/train_manifest.json"
git lfs track "**/raw_metadata.json"
Tracking "**/predictions.json"
Tracking "**/master_manifest.json"
Tracking "**/train_manifest.json"
Tracking "**/raw_metadata.json"
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# git add .gitattributes
git add benchmark_results_conf16m models data
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# git lfs track "**/raw_metadata.json"
"**/raw_metadata.json" already supported
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# git status --untracked-files=all
On branch gpu-box
Your branch is up to date with 'origin/gpu-box'.

Changes to be committed:
  (use "git restore --staged <file>..." to unstage)
	modified:   .gitattributes
	modified:   benchmark_results_conf16m/benchmark_report.json
	modified:   benchmark_results_conf16m/en_clean_read/predictions.json
	modified:   benchmark_results_conf16m/kn_clean_read/predictions.json
	modified:   benchmark_results_conf16m/kn_en_codeswitch/predictions.json
	modified:   data/final_dataset/master_train_manifest.json
	modified:   data/processed_data/IndicVoices/raw_metadata.json
	modified:   data/processed_data/IndicVoices/train_manifest.json
	modified:   data/processed_data/Shrutilipi/raw_metadata.json
	modified:   data/processed_data/Shrutilipi/train_manifest.json
	modified:   data/processed_data/Vaani/raw_metadata.json
	modified:   data/processed_data/Vaani/train_manifest.json
	modified:   data/training/v1/Kathbath/raw_metadata.json
	modified:   data/training/v1/Kathbath/train_manifest.json
	new file:   data/training/v1/master_manifest.json
	new file:   data/training/v2.1/master_manifest.json
	modified:   data/training/v2/iisc_mile/train_manifest.json
	new file:   data/training/v2/master_manifest.json
	modified:   data/training/v2/shrutilipi/raw_metadata.json
	modified:   data/training/v2/vaani/raw_metadata.json
	modified:   data/training/v2/vaani/train_manifest.json
	new file:   models/benchmark_report.json
	new file:   models/report.txt
	modified:   models/results_a14b_indicconf_600m/benchmark_report.json
	modified:   models/results_a14b_indicconf_600m/results/predictions.json
	modified:   models/results_ai4b_indicconf_100m/benchmark_report.json
	modified:   models/results_ai4b_indicconf_100m/results/predictions.json
	modified:   models/results_conf_100m_kathbath/predictions.json
	new file:   models/results_conf_100m_scaleup_v2_final/predictions.json
	new file:   models/results_conf_100m_v2/predictions.json
	modified:   models/results_conf_16m_kathbath/predictions.json

Changes not staged for commit:
  (use "git add <file>..." to update what will be committed)
  (use "git restore <file>..." to discard changes in working directory)
	modified:   evaluation/benchmarking/curation/evaluation/benchmarking/data/v1/kn_clean_read.json
	modified:   evaluation/benchmarking/curation/evaluation/benchmarking/data/v1/kn_en_codeswitch.json
	modified:   evaluation/benchmarking/curation/test_data/Kathbath/raw_metadata.json
	modified:   evaluation/benchmarking/curation/test_data/Kathbath/test_manifest.json
	modified:   evaluation/benchmarking/curation/test_data/Vaani/raw_metadata.json
	modified:   evaluation/benchmarking/curation/test_data/Vaani/test_manifest.json
	modified:   evaluation/benchmarking/data/v1/en_clean_read.json
	modified:   evaluation/benchmarking/data/v1/kn_clean_read.json
	modified:   evaluation/benchmarking/data/v1/kn_en_codeswitch.json
	modified:   pipelines/personal_preprocessing_pipelines/dataset_schemas.json
	modified:   training/data_prep/verify_dataset.py
	modified:   training/train.py

(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# git lfs ls-files
a5c25819a2 * benchmark_results_conf16m/benchmark_report.json
c53894f4d7 * benchmark_results_conf16m/en_clean_read/predictions.json
a3cec516e1 * benchmark_results_conf16m/kn_clean_read/predictions.json
4bc267e9ce * benchmark_results_conf16m/kn_en_codeswitch/predictions.json
b13ddcaef5 * data/final_dataset/master_train_manifest.json
f097e5bda0 * data/processed_data/IndicVoices/raw_metadata.json
6fc8f7a237 * data/processed_data/IndicVoices/train_manifest.json
11c9459d6a * data/processed_data/Shrutilipi/raw_metadata.json
7e0f114af9 * data/processed_data/Shrutilipi/train_manifest.json
983a61fe54 * data/processed_data/Vaani/raw_metadata.json
aa0675ee14 * data/processed_data/Vaani/train_manifest.json
a7ae46a5ce * data/training/v1/Kathbath/raw_metadata.json
39bbbed33d * data/training/v1/Kathbath/train_manifest.json
39bbbed33d * data/training/v1/master_manifest.json
f95c88de44 * data/training/v2.1/master_manifest.json
f0c15ecd10 * data/training/v2/iisc_mile/train_manifest.json
4b3d89b74c * data/training/v2/master_manifest.json
16ba1f1f64 * data/training/v2/shrutilipi/raw_metadata.json
908601ddc9 * data/training/v2/vaani/raw_metadata.json
278432027b * data/training/v2/vaani/train_manifest.json
0bd3f77dc6 * models/benchmark_report.json
09a276e42d * models/results_a14b_indicconf_600m/benchmark_report.json
3b964a168a * models/results_a14b_indicconf_600m/results/predictions.json
9f6db226a0 * models/results_ai4b_indicconf_100m/benchmark_report.json
6335a5f105 * models/results_ai4b_indicconf_100m/results/predictions.json
712681ea0c * models/results_conf_100m_kathbath/predictions.json
17668c80b5 * models/results_conf_100m_scaleup_v2_final/predictions.json
e5840c2e16 * models/results_conf_100m_v2/predictions.json
3fe03faf48 * models/results_conf_16m_kathbath/predictions.json
b8a7749e95 * data/training/v2/shrutilipi/train_manifest.json
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# git add .
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# git commit -m "Add manifests and predictions using Git LFS"
[gpu-box 08902fb] Add manifests and predictions using Git LFS
 43 files changed, 151 insertions(+), 2435138 deletions(-)
 create mode 100644 data/training/v1/master_manifest.json
 create mode 100644 data/training/v2.1/master_manifest.json
 create mode 100644 data/training/v2/master_manifest.json
 create mode 100644 models/benchmark_report.json
 create mode 100644 models/report.txt
 create mode 100644 models/results_conf_100m_scaleup_v2_final/predictions.json
 create mode 100644 models/results_conf_100m_v2/predictions.json
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# git push
Username for 'https://github.com': chaitanyakartik
Password for 'https://chaitanyakartik@github.com': 
Username for 'https://github.com': chaitanyakartik
Password for 'https://chaitanyakartik@github.com': 
Uploading LFS objects: 100% (35/35), 514 MB | 29 MB/s, done.                                                                                                                                                  
Enumerating objects: 132, done.
Counting objects: 100% (132/132), done.
Delta compression using up to 48 threads
Compressing objects: 100% (70/70), done.
Writing objects: 100% (84/84), 9.11 KiB | 1.14 MiB/s, done.
Total 84 (delta 8), reused 0 (delta 0), pack-reused 0
remote: Resolving deltas: 100% (8/8), completed with 8 local objects.
To https://github.com/chaitanyakartik/asr-finetuning
   5827452..08902fb  gpu-box -> gpu-box
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# # 1. Enter the folder (Assuming it's named 'kenlm' or similar from your git/wget command)
cd kenlm

# 2. Create a build directory (Standard CMake practice)
mkdir -p build
cd build

# 3. Configure and Compile
# This uses the libboost libraries you just installed.
cmake ..
make -j 8
bash: cd: kenlm: No such file or directory
Command 'cmake' not found, but can be installed with:
apt install cmake
make: *** No targets specified and no makefile found.  Stop.
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning/build# apt install cmake
Reading package lists... Done
Building dependency tree... Done
Reading state information... Done
The following packages were automatically installed and are no longer required:
  libdrm-nouveau2 libdrm-radeon1 libgl1-amber-dri libglapi-mesa libllvm19 libxcb-dri2-0 linux-headers-6.8.0-52 linux-headers-6.8.0-52-generic linux-image-6.8.0-52-generic linux-modules-6.8.0-52-generic
  linux-modules-extra-6.8.0-52-generic linux-tools-6.8.0-52 linux-tools-6.8.0-52-generic
Use 'sudo apt autoremove' to remove them.
The following additional packages will be installed:
  cmake-data libjsoncpp25 librhash0
Suggested packages:
  cmake-doc cmake-format elpa-cmake-mode ninja-build
The following NEW packages will be installed:
  cmake cmake-data libjsoncpp25 librhash0
0 upgraded, 4 newly installed, 0 to remove and 251 not upgraded.
Need to get 13.6 MB of archives.
After this operation, 49.1 MB of additional disk space will be used.
N: Ignoring file 'ubuntu.sources.bkp' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension
Do you want to continue? [Y/n] y
Get:1 http://100.64.144.92:8081/repository/ubuntu2404 noble/main amd64 libjsoncpp25 amd64 1.9.5-6build1 [82.8 kB]
Get:2 http://100.64.144.92:8081/repository/ubuntu2404 noble/main amd64 librhash0 amd64 1.4.3-3build1 [129 kB]
Get:3 http://100.64.144.92:8081/repository/ubuntu2404 noble/main amd64 cmake-data all 3.28.3-1build7 [2,155 kB]
Get:4 http://100.64.144.92:8081/repository/ubuntu2404 noble/main amd64 cmake amd64 3.28.3-1build7 [11.2 MB]                                                                                                  
Fetched 13.6 MB in 6s (2,106 kB/s)                                                                                                                                                                           
N: Ignoring file 'ubuntu.sources.bkp' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension
Selecting previously unselected package libjsoncpp25:amd64.
(Reading database ... 208274 files and directories currently installed.)
Preparing to unpack .../libjsoncpp25_1.9.5-6build1_amd64.deb ...
Unpacking libjsoncpp25:amd64 (1.9.5-6build1) ...
Selecting previously unselected package librhash0:amd64.
Preparing to unpack .../librhash0_1.4.3-3build1_amd64.deb ...
Unpacking librhash0:amd64 (1.4.3-3build1) ...
Selecting previously unselected package cmake-data.
Preparing to unpack .../cmake-data_3.28.3-1build7_all.deb ...
Unpacking cmake-data (3.28.3-1build7) ...
Selecting previously unselected package cmake.
Preparing to unpack .../cmake_3.28.3-1build7_amd64.deb ...
Unpacking cmake (3.28.3-1build7) ...
Setting up libjsoncpp25:amd64 (1.9.5-6build1) ...
Setting up librhash0:amd64 (1.4.3-3build1) ...
Setting up cmake-data (3.28.3-1build7) ...
Setting up cmake (3.28.3-1build7) ...
Processing triggers for man-db (2.12.0-4build2) ...
Processing triggers for libc-bin (2.39-0ubuntu8.4) ...
Scanning processes...                                                                                                                                                                                         
Scanning candidates...                                                                                                                                                                                        
Scanning linux images...                                                                                                                                                                                      

Running kernel seems to be up-to-date.

Restarting services...

Service restarts being deferred:
 systemctl restart NetworkManager.service
 /etc/needrestart/restart.d/dbus.service

No containers need to be restarted.

No user sessions are running outdated binaries.

No VM guests are running outdated hypervisor (qemu) binaries on this host.
W: Download is performed unsandboxed as root as file '/var/cache/apt/archives/partial/libjsoncpp25_1.9.5-6build1_amd64.deb' couldn't be accessed by user '_apt'. - pkgAcquire::Run (13: Permission denied)
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning/build# # 1. Enter the folder (Assuming it's named 'kenlm' or similar from your git/wget command)
cd kenlm

# 2. Create a build directory (Standard CMake practice)
mkdir -p build
cd build

# 3. Configure and Compile
# This uses the libboost libraries you just installed.
cmake ..
make -j 8
bash: cd: kenlm: No such file or directory
CMake Warning:
  Ignoring extra path from command line:

   ".."


CMake Error: The source directory "/mnt/data/asr-finetuning/build" does not appear to contain CMakeLists.txt.
Specify --help for usage, or press the help button on the CMake GUI.
make: *** No targets specified and no makefile found.  Stop.
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning/build/build# cd ..
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning/build# cd ..
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# # 1. Enter the folder (Assuming it's named 'kenlm' or similar from your git/wget command)
cd kenlm

# 2. Create a build directory (Standard CMake practice)
mkdir -p build
cd build

# 3. Configure and Compile
# This uses the libboost libraries you just installed.
cmake ..
make -j 8
bash: cd: kenlm: No such file or directory
CMake Warning:
  Ignoring extra path from command line:

   ".."


CMake Error: The source directory "/mnt/data/asr-finetuning" does not appear to contain CMakeLists.txt.
Specify --help for usage, or press the help button on the CMake GUI.
make: *** No targets specified and no makefile found.  Stop.
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning/build# cd /mnt/data/asr-finetuning
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# ls -ld kenlm*
ls: cannot access 'kenlm*': No such file or directory
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# cd data
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning/data# ls -ld kenlm*
ls: cannot access 'kenlm*': No such file or directory
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning/data# cd training
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning/data/training# ls -ld kenlm*
ls: cannot access 'kenlm*': No such file or directory
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning/data/training# cd ../..
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# wget -O - https://kheafield.com/code/kenlm.tar.gz | tar xz
--2026-01-22 19:42:57--  https://kheafield.com/code/kenlm.tar.gz
Resolving kheafield.com (kheafield.com)... 129.80.89.152, 2603:c020:4009:8710:ca:11:17:0
Connecting to kheafield.com (kheafield.com)|129.80.89.152|:443... connected.
HTTP request sent, awaiting response... 200 OK
Length: 491888 (480K) [application/octet-stream]
Saving to: STDOUT

-                                                   100%[=================================================================================================================>] 480.36K   515KB/s    in 0.9s    

2026-01-22 19:42:59 (515 KB/s) - written to stdout [491888/491888]

(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# # 2. Go into the folder
cd kenlm

# 3. Build the tools (lmplz)
mkdir -p build
cd build
cmake ..
make -j 8
CMake Deprecation Warning at CMakeLists.txt:1 (cmake_minimum_required):
  Compatibility with CMake < 3.5 will be removed from a future version of
  CMake.

  Update the VERSION argument <min> value or use a ...<max> suffix to tell
  CMake that the project does not need compatibility with older versions.


-- The C compiler identification is GNU 13.3.0
-- The CXX compiler identification is GNU 13.3.0
-- Detecting C compiler ABI info
-- Detecting C compiler ABI info - done
-- Check for working C compiler: /usr/bin/cc - skipped
-- Detecting C compile features
-- Detecting C compile features - done
-- Detecting CXX compiler ABI info
-- Detecting CXX compiler ABI info - done
-- Check for working CXX compiler: /usr/bin/c++ - skipped
-- Detecting CXX compile features
-- Detecting CXX compile features - done
-- Could NOT find Eigen3 (missing: Eigen3_DIR)
-- Found Boost: /usr/lib/x86_64-linux-gnu/cmake/Boost-1.83.0/BoostConfig.cmake (found suitable version "1.83.0", minimum required is "1.41.0") found components: program_options system thread unit_test_framework 
-- Found Threads: TRUE  
-- Found ZLIB: /usr/lib/x86_64-linux-gnu/libz.so (found version "1.3")  
-- Could NOT find BZip2 (missing: BZIP2_LIBRARIES BZIP2_INCLUDE_DIR) 
-- Could NOT find LibLZMA (missing: LIBLZMA_LIBRARY LIBLZMA_INCLUDE_DIR LIBLZMA_HAS_AUTO_DECODER LIBLZMA_HAS_EASY_ENCODER LIBLZMA_HAS_LZMA_PRESET) 
-- Looking for clock_gettime in rt
-- Looking for clock_gettime in rt - found
-- Configuring done (0.7s)
-- Generating done (0.0s)
-- Build files have been written to: /mnt/data/asr-finetuning/kenlm/build
[  1%] Building CXX object util/CMakeFiles/kenlm_util.dir/double-conversion/bignum-dtoa.cc.o
[  3%] Building CXX object util/CMakeFiles/kenlm_util.dir/double-conversion/bignum.cc.o
[  3%] Building CXX object util/CMakeFiles/kenlm_util.dir/double-conversion/diy-fp.cc.o
[  5%] Building CXX object util/CMakeFiles/kenlm_util.dir/double-conversion/cached-powers.cc.o
[  8%] Building CXX object util/CMakeFiles/kenlm_util.dir/double-conversion/double-conversion.cc.o
[  8%] Building CXX object util/CMakeFiles/kenlm_util.dir/double-conversion/fixed-dtoa.cc.o
[  8%] Building CXX object util/CMakeFiles/kenlm_util.dir/double-conversion/fast-dtoa.cc.o
[ 10%] Building CXX object util/CMakeFiles/kenlm_util.dir/double-conversion/strtod.cc.o
[ 11%] Building CXX object util/CMakeFiles/kenlm_util.dir/stream/chain.cc.o
[ 12%] Building CXX object util/CMakeFiles/kenlm_util.dir/stream/count_records.cc.o
[ 13%] Building CXX object util/CMakeFiles/kenlm_util.dir/stream/io.cc.o
[ 15%] Building CXX object util/CMakeFiles/kenlm_util.dir/stream/line_input.cc.o
[ 16%] Building CXX object util/CMakeFiles/kenlm_util.dir/stream/multi_progress.cc.o
[ 17%] Building CXX object util/CMakeFiles/kenlm_util.dir/stream/rewindable_stream.cc.o
[ 18%] Building CXX object util/CMakeFiles/kenlm_util.dir/bit_packing.cc.o
[ 20%] Building CXX object util/CMakeFiles/kenlm_util.dir/ersatz_progress.cc.o
[ 21%] Building CXX object util/CMakeFiles/kenlm_util.dir/exception.cc.o
[ 22%] Building CXX object util/CMakeFiles/kenlm_util.dir/file.cc.o
[ 23%] Building CXX object util/CMakeFiles/kenlm_util.dir/file_piece.cc.o
[ 25%] Building CXX object util/CMakeFiles/kenlm_util.dir/float_to_string.cc.o
[ 26%] Building CXX object util/CMakeFiles/kenlm_util.dir/integer_to_string.cc.o
[ 27%] Building CXX object util/CMakeFiles/kenlm_util.dir/mmap.cc.o
[ 28%] Building CXX object util/CMakeFiles/kenlm_util.dir/murmur_hash.cc.o
[ 30%] Building CXX object util/CMakeFiles/kenlm_util.dir/parallel_read.cc.o
[ 31%] Building CXX object util/CMakeFiles/kenlm_util.dir/pool.cc.o
[ 32%] Building CXX object util/CMakeFiles/kenlm_util.dir/read_compressed.cc.o
[ 33%] Building CXX object util/CMakeFiles/kenlm_util.dir/scoped.cc.o
[ 35%] Building CXX object util/CMakeFiles/kenlm_util.dir/spaces.cc.o
[ 36%] Building CXX object util/CMakeFiles/kenlm_util.dir/string_piece.cc.o
[ 37%] Building CXX object util/CMakeFiles/kenlm_util.dir/usage.cc.o
[ 38%] Linking CXX static library ../lib/libkenlm_util.a
[ 38%] Built target kenlm_util
[ 40%] Building CXX object util/CMakeFiles/probing_hash_table_benchmark.dir/probing_hash_table_benchmark_main.cc.o
[ 46%] Building CXX object lm/filter/CMakeFiles/kenlm_filter.dir/arpa_io.cc.o
[ 46%] Building CXX object lm/filter/CMakeFiles/kenlm_filter.dir/vocab.cc.o
[ 46%] Building CXX object lm/CMakeFiles/kenlm.dir/bhiksha.cc.o
[ 46%] Building CXX object lm/filter/CMakeFiles/kenlm_filter.dir/phrase.cc.o
[ 46%] Building CXX object lm/CMakeFiles/kenlm.dir/config.cc.o
[ 47%] Building CXX object lm/CMakeFiles/kenlm.dir/binary_format.cc.o
[ 48%] Building CXX object lm/CMakeFiles/kenlm.dir/lm_exception.cc.o
In file included from /mnt/data/asr-finetuning/kenlm/lm/filter/arpa_io.hh:9,
                 from /mnt/data/asr-finetuning/kenlm/lm/filter/arpa_io.cc:1:
/mnt/data/asr-finetuning/kenlm/lm/filter/../../util/tokenize_piece.hh:99:77: warning: template<class _Category, class _Tp, class _Distance, class _Pointer, class _Reference> struct std::iterator is deprecated [-Wdeprecated-declarations]
   99 | template <class Find, bool SkipEmpty = false> class TokenIter : public std::iterator<std::forward_iterator_tag, const StringPiece, std::ptrdiff_t, const StringPiece *, const StringPiece &> {
      |                                                                             ^~~~~~~~
In file included from /usr/include/c++/13/bits/stl_iterator_base_funcs.h:66,
                 from /usr/include/c++/13/string:47,
                 from /usr/include/c++/13/bits/locale_classes.h:40,
                 from /usr/include/c++/13/bits/ios_base.h:41,
                 from /usr/include/c++/13/ios:44,
                 from /usr/include/c++/13/ostream:40,
                 from /mnt/data/asr-finetuning/kenlm/lm/filter/../../util/string_piece.hh:55,
                 from /mnt/data/asr-finetuning/kenlm/lm/filter/../../util/fake_ostream.hh:6,
                 from /mnt/data/asr-finetuning/kenlm/lm/filter/../../util/string_stream.hh:4,
                 from /mnt/data/asr-finetuning/kenlm/lm/filter/../../util/exception.hh:4,
                 from /mnt/data/asr-finetuning/kenlm/lm/filter/../lm_exception.hh:6,
                 from /mnt/data/asr-finetuning/kenlm/lm/filter/../read_arpa.hh:4,
                 from /mnt/data/asr-finetuning/kenlm/lm/filter/arpa_io.hh:5:
/usr/include/c++/13/bits/stl_iterator_base_types.h:127:34: note: declared here
  127 |     struct _GLIBCXX17_DEPRECATED iterator
      |                                  ^~~~~~~~
[ 50%] Building CXX object lm/CMakeFiles/kenlm.dir/model.cc.o
[ 51%] Building CXX object lm/CMakeFiles/kenlm.dir/quantize.cc.o
[ 52%] Building CXX object lm/CMakeFiles/kenlm.dir/read_arpa.cc.o
[ 53%] Building CXX object lm/CMakeFiles/kenlm.dir/search_hashed.cc.o
In file included from /mnt/data/asr-finetuning/kenlm/lm/filter/phrase.hh:6,
                 from /mnt/data/asr-finetuning/kenlm/lm/filter/phrase.cc:1:
/mnt/data/asr-finetuning/kenlm/lm/filter/../../util/tokenize_piece.hh:99:77: warning: template<class _Category, class _Tp, class _Distance, class _Pointer, class _Reference> struct std::iterator is deprecated [-Wdeprecated-declarations]
   99 | template <class Find, bool SkipEmpty = false> class TokenIter : public std::iterator<std::forward_iterator_tag, const StringPiece, std::ptrdiff_t, const StringPiece *, const StringPiece &> {
      |                                                                             ^~~~~~~~
In file included from /usr/include/c++/13/bits/stl_iterator_base_funcs.h:66,
                 from /usr/include/c++/13/string:47,
                 from /usr/include/c++/13/bits/locale_classes.h:40,
                 from /usr/include/c++/13/bits/ios_base.h:41,
                 from /usr/include/c++/13/ios:44,
                 from /usr/include/c++/13/ostream:40,
                 from /mnt/data/asr-finetuning/kenlm/lm/filter/../../util/string_piece.hh:55,
                 from /mnt/data/asr-finetuning/kenlm/lm/filter/phrase.hh:5:
/usr/include/c++/13/bits/stl_iterator_base_types.h:127:34: note: declared here
  127 |     struct _GLIBCXX17_DEPRECATED iterator
      |                                  ^~~~~~~~
[ 55%] Building CXX object lm/CMakeFiles/kenlm.dir/search_trie.cc.o
In file included from /mnt/data/asr-finetuning/kenlm/lm/filter/vocab.hh:6,
                 from /mnt/data/asr-finetuning/kenlm/lm/filter/vocab.cc:1:
/mnt/data/asr-finetuning/kenlm/lm/filter/../../util/multi_intersection.hh:14:61: warning: template<class _Arg1, class _Arg2, class _Result> struct std::binary_function is deprecated [-Wdeprecated-declarations]
   14 | template <class Range> struct RangeLessBySize : public std::binary_function<const Range &, const Range &, bool> {
      |                                                             ^~~~~~~~~~~~~~~
In file included from /usr/include/c++/13/string:49,
                 from /usr/include/c++/13/stdexcept:39,
                 from /usr/include/boost/optional/bad_optional_access.hpp:15,
                 from /usr/include/boost/optional/optional.hpp:34,
                 from /usr/include/boost/optional.hpp:15,
                 from /mnt/data/asr-finetuning/kenlm/lm/filter/../../util/multi_intersection.hh:4:
/usr/include/c++/13/bits/stl_function.h:131:12: note: declared here
  131 |     struct binary_function
      |            ^~~~~~~~~~~~~~~
In file included from /mnt/data/asr-finetuning/kenlm/lm/filter/vocab.hh:8:
/mnt/data/asr-finetuning/kenlm/lm/filter/../../util/string_piece_hash.hh:23:48: warning: template<class _Arg, class _Result> struct std::unary_function is deprecated [-Wdeprecated-declarations]
   23 | struct StringPieceCompatibleHash : public std::unary_function<const StringPiece &, size_t> {
      |                                                ^~~~~~~~~~~~~~
/usr/include/c++/13/bits/stl_function.h:117:12: note: declared here
  117 |     struct unary_function
      |            ^~~~~~~~~~~~~~
/mnt/data/asr-finetuning/kenlm/lm/filter/../../util/string_piece_hash.hh:29:50: warning: template<class _Arg1, class _Arg2, class _Result> struct std::binary_function is deprecated [-Wdeprecated-declarations]
   29 | struct StringPieceCompatibleEquals : public std::binary_function<const StringPiece &, const std::string &, bool> {
      |                                                  ^~~~~~~~~~~~~~~
/usr/include/c++/13/bits/stl_function.h:131:12: note: declared here
  131 |     struct binary_function
      |            ^~~~~~~~~~~~~~~
In file included from /mnt/data/asr-finetuning/kenlm/lm/filter/vocab.hh:9:
/mnt/data/asr-finetuning/kenlm/lm/filter/../../util/tokenize_piece.hh:99:77: warning: template<class _Category, class _Tp, class _Distance, class _Pointer, class _Reference> struct std::iterator is deprecated [-Wdeprecated-declarations]
   99 | template <class Find, bool SkipEmpty = false> class TokenIter : public std::iterator<std::forward_iterator_tag, const StringPiece, std::ptrdiff_t, const StringPiece *, const StringPiece &> {
      |                                                                             ^~~~~~~~
In file included from /usr/include/c++/13/bits/stl_iterator_base_funcs.h:66,
                 from /usr/include/c++/13/string:47:
/usr/include/c++/13/bits/stl_iterator_base_types.h:127:34: note: declared here
  127 |     struct _GLIBCXX17_DEPRECATED iterator
      |                                  ^~~~~~~~
[ 56%] Building CXX object lm/CMakeFiles/kenlm.dir/sizes.cc.o
In file included from /mnt/data/asr-finetuning/kenlm/lm/search_trie.cc:11:
/mnt/data/asr-finetuning/kenlm/lm/trie_sort.hh:31:34: warning: template<class _Arg1, class _Arg2, class _Result> struct std::binary_function is deprecated [-Wdeprecated-declarations]
   31 | class EntryCompare : public std::binary_function<const void*, const void*, bool> {
      |                                  ^~~~~~~~~~~~~~~
In file included from /usr/include/c++/13/string:49,
                 from /usr/include/c++/13/bits/locale_classes.h:40,
                 from /usr/include/c++/13/bits/ios_base.h:41,
                 from /usr/include/c++/13/ios:44,
                 from /usr/include/c++/13/ostream:40,
                 from /mnt/data/asr-finetuning/kenlm/lm/../util/string_piece.hh:55,
                 from /mnt/data/asr-finetuning/kenlm/lm/../util/fake_ostream.hh:6,
                 from /mnt/data/asr-finetuning/kenlm/lm/../util/string_stream.hh:4,
                 from /mnt/data/asr-finetuning/kenlm/lm/../util/exception.hh:4,
                 from /mnt/data/asr-finetuning/kenlm/lm/lm_exception.hh:6,
                 from /mnt/data/asr-finetuning/kenlm/lm/config.hh:4,
                 from /mnt/data/asr-finetuning/kenlm/lm/search_trie.hh:4,
                 from /mnt/data/asr-finetuning/kenlm/lm/search_trie.cc:2:
/usr/include/c++/13/bits/stl_function.h:131:12: note: declared here
  131 |     struct binary_function
      |            ^~~~~~~~~~~~~~~
In file included from /mnt/data/asr-finetuning/kenlm/lm/search_trie.cc:19:
/mnt/data/asr-finetuning/kenlm/lm/../util/sized_iterator.hh:130:86: warning: template<class _Arg1, class _Arg2, class _Result> struct std::binary_function is deprecated [-Wdeprecated-declarations]
  130 | template <class Delegate, class Proxy = SizedProxy> class SizedCompare : public std::binary_function<const Proxy &, const Proxy &, bool> {
      |                                                                                      ^~~~~~~~~~~~~~~
/usr/include/c++/13/bits/stl_function.h:131:12: note: declared here
  131 |     struct binary_function
      |            ^~~~~~~~~~~~~~~
/mnt/data/asr-finetuning/kenlm/lm/../util/sized_iterator.hh:157:71: warning: template<class _Arg1, class _Arg2, class _Result> struct std::binary_function is deprecated [-Wdeprecated-declarations]
  157 | template <class Delegate, unsigned Size> class JustPODDelegate : std::binary_function<const JustPOD<Size> &, const JustPOD<Size> &, bool> {
      |                                                                       ^~~~~~~~~~~~~~~
/usr/include/c++/13/bits/stl_function.h:131:12: note: declared here
  131 |     struct binary_function
      |            ^~~~~~~~~~~~~~~
/mnt/data/asr-finetuning/kenlm/lm/filter/phrase.cc:107:33: warning: template<class _Arg1, class _Arg2, class _Result> struct std::binary_function is deprecated [-Wdeprecated-declarations]
  107 | struct ArcGreater : public std::binary_function<const Arc *, const Arc *, bool> {
      |                                 ^~~~~~~~~~~~~~~
In file included from /usr/include/c++/13/string:49:
/usr/include/c++/13/bits/stl_function.h:131:12: note: declared here
  131 |     struct binary_function
      |            ^~~~~~~~~~~~~~~
[ 57%] Building CXX object lm/CMakeFiles/kenlm.dir/trie.cc.o
[ 58%] Building CXX object lm/CMakeFiles/kenlm.dir/trie_sort.cc.o
[ 60%] Building CXX object lm/CMakeFiles/kenlm.dir/value_build.cc.o
[ 61%] Building CXX object lm/CMakeFiles/kenlm.dir/virtual_interface.cc.o
In file included from /mnt/data/asr-finetuning/kenlm/lm/trie_sort.cc:1:
/mnt/data/asr-finetuning/kenlm/lm/trie_sort.hh:31:34: warning: template<class _Arg1, class _Arg2, class _Result> struct std::binary_function is deprecated [-Wdeprecated-declarations]
   31 | class EntryCompare : public std::binary_function<const void*, const void*, bool> {
      |                                  ^~~~~~~~~~~~~~~
In file included from /usr/include/c++/13/string:49,
                 from /usr/include/c++/13/bits/locale_classes.h:40,
                 from /usr/include/c++/13/bits/ios_base.h:41,
                 from /usr/include/c++/13/ios:44,
                 from /usr/include/c++/13/ostream:40,
                 from /mnt/data/asr-finetuning/kenlm/lm/../util/string_piece.hh:55,
                 from /mnt/data/asr-finetuning/kenlm/lm/../util/fake_ostream.hh:6,
                 from /mnt/data/asr-finetuning/kenlm/lm/../util/string_stream.hh:4,
                 from /mnt/data/asr-finetuning/kenlm/lm/../util/exception.hh:4,
                 from /mnt/data/asr-finetuning/kenlm/lm/../util/file.hh:4,
                 from /mnt/data/asr-finetuning/kenlm/lm/trie_sort.hh:9:
/usr/include/c++/13/bits/stl_function.h:131:12: note: declared here
  131 |     struct binary_function
      |            ^~~~~~~~~~~~~~~
In file included from /mnt/data/asr-finetuning/kenlm/lm/trie_sort.cc:13:
/mnt/data/asr-finetuning/kenlm/lm/../util/sized_iterator.hh:130:86: warning: template<class _Arg1, class _Arg2, class _Result> struct std::binary_function is deprecated [-Wdeprecated-declarations]
  130 | template <class Delegate, class Proxy = SizedProxy> class SizedCompare : public std::binary_function<const Proxy &, const Proxy &, bool> {
      |                                                                                      ^~~~~~~~~~~~~~~
/usr/include/c++/13/bits/stl_function.h:131:12: note: declared here
  131 |     struct binary_function
      |            ^~~~~~~~~~~~~~~
/mnt/data/asr-finetuning/kenlm/lm/../util/sized_iterator.hh:157:71: warning: template<class _Arg1, class _Arg2, class _Result> struct std::binary_function is deprecated [-Wdeprecated-declarations]
  157 | template <class Delegate, unsigned Size> class JustPODDelegate : std::binary_function<const JustPOD<Size> &, const JustPOD<Size> &, bool> {
      |                                                                       ^~~~~~~~~~~~~~~
/usr/include/c++/13/bits/stl_function.h:131:12: note: declared here
  131 |     struct binary_function
      |            ^~~~~~~~~~~~~~~
[ 62%] Linking CXX static library ../../lib/libkenlm_filter.a
[ 62%] Built target kenlm_filter
[ 63%] Building CXX object lm/CMakeFiles/kenlm.dir/vocab.cc.o
[ 65%] Building CXX object lm/CMakeFiles/kenlm.dir/common/model_buffer.cc.o
In file included from /mnt/data/asr-finetuning/kenlm/lm/vocab.cc:11:
/mnt/data/asr-finetuning/kenlm/lm/../util/joint_sort.hh:104:68: warning: template<class _Arg1, class _Arg2, class _Result> struct std::binary_function is deprecated [-Wdeprecated-declarations]
  104 | template <class Proxy, class Less> class LessWrapper : public std::binary_function<const typename Proxy::value_type &, const typename Proxy::value_type &, bool> {
      |                                                                    ^~~~~~~~~~~~~~~
In file included from /usr/include/c++/13/string:49,
                 from /usr/include/c++/13/bits/locale_classes.h:40,
                 from /usr/include/c++/13/bits/ios_base.h:41,
                 from /usr/include/c++/13/ios:44,
                 from /usr/include/c++/13/ostream:40,
                 from /mnt/data/asr-finetuning/kenlm/lm/../util/string_piece.hh:55,
                 from /mnt/data/asr-finetuning/kenlm/lm/enumerate_vocab.hh:5,
                 from /mnt/data/asr-finetuning/kenlm/lm/vocab.hh:4,
                 from /mnt/data/asr-finetuning/kenlm/lm/vocab.cc:1:
/usr/include/c++/13/bits/stl_function.h:131:12: note: declared here
  131 |     struct binary_function
      |            ^~~~~~~~~~~~~~~
[ 66%] Building CXX object lm/CMakeFiles/kenlm.dir/common/print.cc.o
[ 67%] Building CXX object lm/CMakeFiles/kenlm.dir/common/renumber.cc.o
[ 68%] Building CXX object lm/CMakeFiles/kenlm.dir/common/size_option.cc.o
In file included from /mnt/data/asr-finetuning/kenlm/lm/common/model_buffer.cc:3:
/mnt/data/asr-finetuning/kenlm/lm/common/compare.hh:15:55: warning: template<class _Arg1, class _Arg2, class _Result> struct std::binary_function is deprecated [-Wdeprecated-declarations]
   15 | template <class Child> class Comparator : public std::binary_function<const void *, const void *, bool> {
      |                                                       ^~~~~~~~~~~~~~~
In file included from /usr/include/c++/13/string:49,
                 from /usr/include/c++/13/bits/locale_classes.h:40,
                 from /usr/include/c++/13/bits/ios_base.h:41,
                 from /usr/include/c++/13/ios:44,
                 from /usr/include/c++/13/ostream:40,
                 from /mnt/data/asr-finetuning/kenlm/lm/common/../../util/string_piece.hh:55,
                 from /mnt/data/asr-finetuning/kenlm/lm/common/../../util/fake_ostream.hh:6,
                 from /mnt/data/asr-finetuning/kenlm/lm/common/../../util/string_stream.hh:4,
                 from /mnt/data/asr-finetuning/kenlm/lm/common/../../util/exception.hh:4,
                 from /mnt/data/asr-finetuning/kenlm/lm/common/../../util/file.hh:4,
                 from /mnt/data/asr-finetuning/kenlm/lm/common/model_buffer.hh:8,
                 from /mnt/data/asr-finetuning/kenlm/lm/common/model_buffer.cc:1:
/usr/include/c++/13/bits/stl_function.h:131:12: note: declared here
  131 |     struct binary_function
      |            ^~~~~~~~~~~~~~~
/mnt/data/asr-finetuning/kenlm/lm/common/compare.hh:173:69: warning: template<class _Arg1, class _Arg2, class _Result> struct std::binary_function is deprecated [-Wdeprecated-declarations]
  173 | template <class Range> struct SuffixLexicographicLess : public std::binary_function<const Range, const Range, bool> {
      |                                                                     ^~~~~~~~~~~~~~~
/usr/include/c++/13/bits/stl_function.h:131:12: note: declared here
  131 |     struct binary_function
      |            ^~~~~~~~~~~~~~~
[ 70%] Linking CXX static library ../lib/libkenlm.a
[ 70%] Built target kenlm
[ 71%] Building CXX object lm/CMakeFiles/query.dir/query_main.cc.o
[ 72%] Building CXX object lm/CMakeFiles/build_binary.dir/build_binary_main.cc.o
[ 73%] Building CXX object lm/filter/CMakeFiles/filter.dir/filter_main.cc.o
[ 75%] Building CXX object lm/CMakeFiles/kenlm_benchmark.dir/kenlm_benchmark_main.cc.o
[ 77%] Building CXX object lm/CMakeFiles/fragment.dir/fragment_main.cc.o
[ 77%] Building CXX object lm/builder/CMakeFiles/kenlm_builder.dir/adjust_counts.cc.o
[ 78%] Building CXX object lm/filter/CMakeFiles/phrase_table_vocab.dir/phrase_table_vocab_main.cc.o
[ 80%] Linking CXX executable ../bin/probing_hash_table_benchmark
In file included from /mnt/data/asr-finetuning/kenlm/lm/fragment_main.cc:4:
/mnt/data/asr-finetuning/kenlm/lm/../util/tokenize_piece.hh:99:77: warning: template<class _Category, class _Tp, class _Distance, class _Pointer, class _Reference> struct std::iterator is deprecated [-Wdeprecated-declarations]
   99 | template <class Find, bool SkipEmpty = false> class TokenIter : public std::iterator<std::forward_iterator_tag, const StringPiece, std::ptrdiff_t, const StringPiece *, const StringPiece &> {
      |                                                                             ^~~~~~~~
In file included from /usr/include/c++/13/bits/stl_iterator_base_funcs.h:66,
                 from /usr/include/c++/13/string:47,
                 from /usr/include/c++/13/bits/locale_classes.h:40,
                 from /usr/include/c++/13/bits/ios_base.h:41,
                 from /usr/include/c++/13/ios:44,
                 from /usr/include/c++/13/ostream:40,
                 from /mnt/data/asr-finetuning/kenlm/lm/../util/string_piece.hh:55,
                 from /mnt/data/asr-finetuning/kenlm/lm/../util/fake_ostream.hh:6,
                 from /mnt/data/asr-finetuning/kenlm/lm/../util/string_stream.hh:4,
                 from /mnt/data/asr-finetuning/kenlm/lm/../util/exception.hh:4,
                 from /mnt/data/asr-finetuning/kenlm/lm/lm_exception.hh:6,
                 from /mnt/data/asr-finetuning/kenlm/lm/config.hh:4,
                 from /mnt/data/asr-finetuning/kenlm/lm/binary_format.hh:4,
                 from /mnt/data/asr-finetuning/kenlm/lm/fragment_main.cc:1:
/usr/include/c++/13/bits/stl_iterator_base_types.h:127:34: note: declared here
  127 |     struct _GLIBCXX17_DEPRECATED iterator
      |                                  ^~~~~~~~
[ 80%] Built target probing_hash_table_benchmark
[ 81%] Building CXX object lm/builder/CMakeFiles/kenlm_builder.dir/corpus_count.cc.o
In file included from /mnt/data/asr-finetuning/kenlm/lm/filter/phrase_table_vocab_main.cc:6:
/mnt/data/asr-finetuning/kenlm/lm/filter/../../util/string_piece_hash.hh:23:48: warning: template<class _Arg, class _Result> struct std::unary_function is deprecated [-Wdeprecated-declarations]
   23 | struct StringPieceCompatibleHash : public std::unary_function<const StringPiece &, size_t> {
      |                                                ^~~~~~~~~~~~~~
In file included from /usr/include/c++/13/string:49,
                 from /usr/include/c++/13/bits/locale_classes.h:40,
                 from /usr/include/c++/13/bits/ios_base.h:41,
                 from /usr/include/c++/13/ios:44,
                 from /usr/include/c++/13/ostream:40,
                 from /mnt/data/asr-finetuning/kenlm/lm/filter/../../util/string_piece.hh:55,
                 from /mnt/data/asr-finetuning/kenlm/lm/filter/../../util/fake_ostream.hh:6,
                 from /mnt/data/asr-finetuning/kenlm/lm/filter/../../util/file_stream.hh:7,
                 from /mnt/data/asr-finetuning/kenlm/lm/filter/phrase_table_vocab_main.cc:1:
/usr/include/c++/13/bits/stl_function.h:117:12: note: declared here
  117 |     struct unary_function
      |            ^~~~~~~~~~~~~~
/mnt/data/asr-finetuning/kenlm/lm/filter/../../util/string_piece_hash.hh:29:50: warning: template<class _Arg1, class _Arg2, class _Result> struct std::binary_function is deprecated [-Wdeprecated-declarations]
   29 | struct StringPieceCompatibleEquals : public std::binary_function<const StringPiece &, const std::string &, bool> {
      |                                                  ^~~~~~~~~~~~~~~
/usr/include/c++/13/bits/stl_function.h:131:12: note: declared here
  131 |     struct binary_function
      |            ^~~~~~~~~~~~~~~
In file included from /mnt/data/asr-finetuning/kenlm/lm/filter/phrase_table_vocab_main.cc:7:
/mnt/data/asr-finetuning/kenlm/lm/filter/../../util/tokenize_piece.hh:99:77: warning: template<class _Category, class _Tp, class _Distance, class _Pointer, class _Reference> struct std::iterator is deprecated [-Wdeprecated-declarations]
   99 | template <class Find, bool SkipEmpty = false> class TokenIter : public std::iterator<std::forward_iterator_tag, const StringPiece, std::ptrdiff_t, const StringPiece *, const StringPiece &> {
      |                                                                             ^~~~~~~~
In file included from /usr/include/c++/13/bits/stl_iterator_base_funcs.h:66,
                 from /usr/include/c++/13/string:47:
/usr/include/c++/13/bits/stl_iterator_base_types.h:127:34: note: declared here
  127 |     struct _GLIBCXX17_DEPRECATED iterator
      |                                  ^~~~~~~~
[ 82%] Linking CXX executable ../bin/fragment
[ 83%] Linking CXX executable ../bin/build_binary
[ 83%] Built target fragment
[ 85%] Building CXX object lm/builder/CMakeFiles/kenlm_builder.dir/initial_probabilities.cc.o
[ 85%] Built target build_binary
[ 86%] Building CXX object lm/builder/CMakeFiles/kenlm_builder.dir/interpolate.cc.o
In file included from /mnt/data/asr-finetuning/kenlm/lm/filter/arpa_io.hh:9,
                 from /mnt/data/asr-finetuning/kenlm/lm/filter/filter_main.cc:1:
/mnt/data/asr-finetuning/kenlm/lm/filter/../../util/tokenize_piece.hh:99:77: warning: template<class _Category, class _Tp, class _Distance, class _Pointer, class _Reference> struct std::iterator is deprecated [-Wdeprecated-declarations]
   99 | template <class Find, bool SkipEmpty = false> class TokenIter : public std::iterator<std::forward_iterator_tag, const StringPiece, std::ptrdiff_t, const StringPiece *, const StringPiece &> {
      |                                                                             ^~~~~~~~
In file included from /usr/include/c++/13/bits/stl_iterator_base_funcs.h:66,
                 from /usr/include/c++/13/string:47,
                 from /usr/include/c++/13/bits/locale_classes.h:40,
                 from /usr/include/c++/13/bits/ios_base.h:41,
                 from /usr/include/c++/13/ios:44,
                 from /usr/include/c++/13/ostream:40,
                 from /mnt/data/asr-finetuning/kenlm/lm/filter/../../util/string_piece.hh:55,
                 from /mnt/data/asr-finetuning/kenlm/lm/filter/../../util/fake_ostream.hh:6,
                 from /mnt/data/asr-finetuning/kenlm/lm/filter/../../util/string_stream.hh:4,
                 from /mnt/data/asr-finetuning/kenlm/lm/filter/../../util/exception.hh:4,
                 from /mnt/data/asr-finetuning/kenlm/lm/filter/../lm_exception.hh:6,
                 from /mnt/data/asr-finetuning/kenlm/lm/filter/../read_arpa.hh:4,
                 from /mnt/data/asr-finetuning/kenlm/lm/filter/arpa_io.hh:5:
/usr/include/c++/13/bits/stl_iterator_base_types.h:127:34: note: declared here
  127 |     struct _GLIBCXX17_DEPRECATED iterator
      |                                  ^~~~~~~~
[ 87%] Linking CXX executable ../bin/query
[ 87%] Built target query
[ 88%] Building CXX object lm/builder/CMakeFiles/kenlm_builder.dir/output.cc.o
[ 90%] Linking CXX executable ../../bin/phrase_table_vocab
[ 90%] Built target phrase_table_vocab
[ 91%] Building CXX object lm/builder/CMakeFiles/kenlm_builder.dir/pipeline.cc.o
In file included from /mnt/data/asr-finetuning/kenlm/lm/builder/corpus_count.cc:15:
/mnt/data/asr-finetuning/kenlm/lm/builder/../../util/tokenize_piece.hh:99:77: warning: template<class _Category, class _Tp, class _Distance, class _Pointer, class _Reference> struct std::iterator is deprecated [-Wdeprecated-declarations]
   99 | template <class Find, bool SkipEmpty = false> class TokenIter : public std::iterator<std::forward_iterator_tag, const StringPiece, std::ptrdiff_t, const StringPiece *, const StringPiece &> {
      |                                                                             ^~~~~~~~
In file included from /usr/include/c++/13/bits/stl_iterator_base_funcs.h:66,
                 from /usr/include/c++/13/string:47,
                 from /usr/include/c++/13/bits/locale_classes.h:40,
                 from /usr/include/c++/13/bits/ios_base.h:41,
                 from /usr/include/c++/13/ios:44,
                 from /usr/include/c++/13/ostream:40,
                 from /mnt/data/asr-finetuning/kenlm/lm/builder/../../util/string_piece.hh:55,
                 from /mnt/data/asr-finetuning/kenlm/lm/builder/../../util/fake_ostream.hh:6,
                 from /mnt/data/asr-finetuning/kenlm/lm/builder/../../util/string_stream.hh:4,
                 from /mnt/data/asr-finetuning/kenlm/lm/builder/../../util/exception.hh:4,
                 from /mnt/data/asr-finetuning/kenlm/lm/builder/../lm_exception.hh:6,
                 from /mnt/data/asr-finetuning/kenlm/lm/builder/corpus_count.hh:4,
                 from /mnt/data/asr-finetuning/kenlm/lm/builder/corpus_count.cc:1:
/usr/include/c++/13/bits/stl_iterator_base_types.h:127:34: note: declared here
  127 |     struct _GLIBCXX17_DEPRECATED iterator
      |                                  ^~~~~~~~
/mnt/data/asr-finetuning/kenlm/lm/builder/corpus_count.cc:25:32: warning: template<class _Arg, class _Result> struct std::unary_function is deprecated [-Wdeprecated-declarations]
   25 | class DedupeHash : public std::unary_function<const WordIndex *, bool> {
      |                                ^~~~~~~~~~~~~~
In file included from /usr/include/c++/13/string:49:
/usr/include/c++/13/bits/stl_function.h:117:12: note: declared here
  117 |     struct unary_function
      |            ^~~~~~~~~~~~~~
/mnt/data/asr-finetuning/kenlm/lm/builder/corpus_count.cc:37:34: warning: template<class _Arg1, class _Arg2, class _Result> struct std::binary_function is deprecated [-Wdeprecated-declarations]
   37 | class DedupeEquals : public std::binary_function<const WordIndex *, const WordIndex *, bool> {
      |                                  ^~~~~~~~~~~~~~~
/usr/include/c++/13/bits/stl_function.h:131:12: note: declared here
  131 |     struct binary_function
      |            ^~~~~~~~~~~~~~~
In file included from /mnt/data/asr-finetuning/kenlm/lm/builder/interpolate.cc:5:
/mnt/data/asr-finetuning/kenlm/lm/builder/../common/compare.hh:15:55: warning: template<class _Arg1, class _Arg2, class _Result> struct std::binary_function is deprecated [-Wdeprecated-declarations]
   15 | template <class Child> class Comparator : public std::binary_function<const void *, const void *, bool> {
      |                                                       ^~~~~~~~~~~~~~~
In file included from /usr/include/c++/13/string:49,
                 from /usr/include/c++/13/bits/locale_classes.h:40,
                 from /usr/include/c++/13/bits/ios_base.h:41,
                 from /usr/include/c++/13/ios:44,
                 from /usr/include/c++/13/ostream:40,
                 from /mnt/data/asr-finetuning/kenlm/lm/builder/../../util/stream/../string_piece.hh:55,
                 from /mnt/data/asr-finetuning/kenlm/lm/builder/../../util/stream/../fake_ostream.hh:6,
                 from /mnt/data/asr-finetuning/kenlm/lm/builder/../../util/stream/../string_stream.hh:4,
                 from /mnt/data/asr-finetuning/kenlm/lm/builder/../../util/stream/../exception.hh:4,
                 from /mnt/data/asr-finetuning/kenlm/lm/builder/../../util/stream/../scoped.hh:5,
                 from /mnt/data/asr-finetuning/kenlm/lm/builder/../../util/stream/../fixed_array.hh:4,
                 from /mnt/data/asr-finetuning/kenlm/lm/builder/../../util/stream/multi_stream.hh:4,
                 from /mnt/data/asr-finetuning/kenlm/lm/builder/interpolate.hh:6,
                 from /mnt/data/asr-finetuning/kenlm/lm/builder/interpolate.cc:1:
/usr/include/c++/13/bits/stl_function.h:131:12: note: declared here
  131 |     struct binary_function
      |            ^~~~~~~~~~~~~~~
/mnt/data/asr-finetuning/kenlm/lm/builder/../common/compare.hh:173:69: warning: template<class _Arg1, class _Arg2, class _Result> struct std::binary_function is deprecated [-Wdeprecated-declarations]
  173 | template <class Range> struct SuffixLexicographicLess : public std::binary_function<const Range, const Range, bool> {
      |                                                                     ^~~~~~~~~~~~~~~
/usr/include/c++/13/bits/stl_function.h:131:12: note: declared here
  131 |     struct binary_function
      |            ^~~~~~~~~~~~~~~
In file included from /mnt/data/asr-finetuning/kenlm/lm/filter/vocab.hh:6,
                 from /mnt/data/asr-finetuning/kenlm/lm/filter/filter_main.cc:7:
/mnt/data/asr-finetuning/kenlm/lm/filter/../../util/multi_intersection.hh:14:61: warning: template<class _Arg1, class _Arg2, class _Result> struct std::binary_function is deprecated [-Wdeprecated-declarations]
   14 | template <class Range> struct RangeLessBySize : public std::binary_function<const Range &, const Range &, bool> {
      |                                                             ^~~~~~~~~~~~~~~
In file included from /usr/include/c++/13/string:49:
/usr/include/c++/13/bits/stl_function.h:131:12: note: declared here
  131 |     struct binary_function
      |            ^~~~~~~~~~~~~~~
In file included from /mnt/data/asr-finetuning/kenlm/lm/filter/vocab.hh:8:
/mnt/data/asr-finetuning/kenlm/lm/filter/../../util/string_piece_hash.hh:23:48: warning: template<class _Arg, class _Result> struct std::unary_function is deprecated [-Wdeprecated-declarations]
   23 | struct StringPieceCompatibleHash : public std::unary_function<const StringPiece &, size_t> {
      |                                                ^~~~~~~~~~~~~~
/usr/include/c++/13/bits/stl_function.h:117:12: note: declared here
  117 |     struct unary_function
      |            ^~~~~~~~~~~~~~
/mnt/data/asr-finetuning/kenlm/lm/filter/../../util/string_piece_hash.hh:29:50: warning: template<class _Arg1, class _Arg2, class _Result> struct std::binary_function is deprecated [-Wdeprecated-declarations]
   29 | struct StringPieceCompatibleEquals : public std::binary_function<const StringPiece &, const std::string &, bool> {
      |                                                  ^~~~~~~~~~~~~~~
/usr/include/c++/13/bits/stl_function.h:131:12: note: declared here
  131 |     struct binary_function
      |            ^~~~~~~~~~~~~~~
In file included from /mnt/data/asr-finetuning/kenlm/lm/builder/combine_counts.hh:6,
                 from /mnt/data/asr-finetuning/kenlm/lm/builder/pipeline.cc:4:
/mnt/data/asr-finetuning/kenlm/lm/builder/../common/compare.hh:15:55: warning: template<class _Arg1, class _Arg2, class _Result> struct std::binary_function is deprecated [-Wdeprecated-declarations]
   15 | template <class Child> class Comparator : public std::binary_function<const void *, const void *, bool> {
      |                                                       ^~~~~~~~~~~~~~~
In file included from /usr/include/c++/13/string:49,
                 from /usr/include/c++/13/bits/locale_classes.h:40,
                 from /usr/include/c++/13/bits/ios_base.h:41,
                 from /usr/include/c++/13/ios:44,
                 from /usr/include/c++/13/ostream:40,
                 from /mnt/data/asr-finetuning/kenlm/lm/builder/../../util/string_piece.hh:55,
                 from /mnt/data/asr-finetuning/kenlm/lm/builder/../../util/fake_ostream.hh:6,
                 from /mnt/data/asr-finetuning/kenlm/lm/builder/../../util/string_stream.hh:4,
                 from /mnt/data/asr-finetuning/kenlm/lm/builder/../../util/exception.hh:4,
                 from /mnt/data/asr-finetuning/kenlm/lm/builder/../lm_exception.hh:6,
                 from /mnt/data/asr-finetuning/kenlm/lm/builder/adjust_counts.hh:5,
                 from /mnt/data/asr-finetuning/kenlm/lm/builder/pipeline.hh:4,
                 from /mnt/data/asr-finetuning/kenlm/lm/builder/pipeline.cc:1:
/usr/include/c++/13/bits/stl_function.h:131:12: note: declared here
  131 |     struct binary_function
      |            ^~~~~~~~~~~~~~~
/mnt/data/asr-finetuning/kenlm/lm/builder/../common/compare.hh:173:69: warning: template<class _Arg1, class _Arg2, class _Result> struct std::binary_function is deprecated [-Wdeprecated-declarations]
  173 | template <class Range> struct SuffixLexicographicLess : public std::binary_function<const Range, const Range, bool> {
      |                                                                     ^~~~~~~~~~~~~~~
/usr/include/c++/13/bits/stl_function.h:131:12: note: declared here
  131 |     struct binary_function
      |            ^~~~~~~~~~~~~~~
In file included from /mnt/data/asr-finetuning/kenlm/lm/builder/../../util/stream/sort.hh:29,
                 from /mnt/data/asr-finetuning/kenlm/lm/builder/combine_counts.hh:8:
/mnt/data/asr-finetuning/kenlm/lm/builder/../../util/stream/../sized_iterator.hh:130:86: warning: template<class _Arg1, class _Arg2, class _Result> struct std::binary_function is deprecated [-Wdeprecated-declarations]
  130 | template <class Delegate, class Proxy = SizedProxy> class SizedCompare : public std::binary_function<const Proxy &, const Proxy &, bool> {
      |                                                                                      ^~~~~~~~~~~~~~~
/usr/include/c++/13/bits/stl_function.h:131:12: note: declared here
  131 |     struct binary_function
      |            ^~~~~~~~~~~~~~~
/mnt/data/asr-finetuning/kenlm/lm/builder/../../util/stream/../sized_iterator.hh:157:71: warning: template<class _Arg1, class _Arg2, class _Result> struct std::binary_function is deprecated [-Wdeprecated-declarations]
  157 | template <class Delegate, unsigned Size> class JustPODDelegate : std::binary_function<const JustPOD<Size> &, const JustPOD<Size> &, bool> {
      |                                                                       ^~~~~~~~~~~~~~~
/usr/include/c++/13/bits/stl_function.h:131:12: note: declared here
  131 |     struct binary_function
      |            ^~~~~~~~~~~~~~~
/mnt/data/asr-finetuning/kenlm/lm/builder/../../util/stream/sort.hh:203:33: warning: template<class _Arg1, class _Arg2, class _Result> struct std::binary_function is deprecated [-Wdeprecated-declarations]
  203 |     class Greater : public std::binary_function<const Entry &, const Entry &, bool> {
      |                                 ^~~~~~~~~~~~~~~
/usr/include/c++/13/bits/stl_function.h:131:12: note: declared here
  131 |     struct binary_function
      |            ^~~~~~~~~~~~~~~
[ 92%] Linking CXX static library ../../lib/libkenlm_builder.a
[ 93%] Linking CXX executable ../bin/kenlm_benchmark
[ 93%] Built target kenlm_builder
[ 95%] Building CXX object lm/builder/CMakeFiles/lmplz.dir/lmplz_main.cc.o
[ 96%] Building CXX object lm/builder/CMakeFiles/count_ngrams.dir/count_ngrams_main.cc.o
[ 96%] Built target kenlm_benchmark
In file included from /mnt/data/asr-finetuning/kenlm/lm/builder/combine_counts.hh:6,
                 from /mnt/data/asr-finetuning/kenlm/lm/builder/count_ngrams_main.cc:1:
/mnt/data/asr-finetuning/kenlm/lm/builder/../common/compare.hh:15:55: warning: template<class _Arg1, class _Arg2, class _Result> struct std::binary_function is deprecated [-Wdeprecated-declarations]
   15 | template <class Child> class Comparator : public std::binary_function<const void *, const void *, bool> {
      |                                                       ^~~~~~~~~~~~~~~
In file included from /usr/include/c++/13/functional:49,
                 from /mnt/data/asr-finetuning/kenlm/lm/builder/../common/compare.hh:7:
/usr/include/c++/13/bits/stl_function.h:131:12: note: declared here
  131 |     struct binary_function
      |            ^~~~~~~~~~~~~~~
/mnt/data/asr-finetuning/kenlm/lm/builder/../common/compare.hh:173:69: warning: template<class _Arg1, class _Arg2, class _Result> struct std::binary_function is deprecated [-Wdeprecated-declarations]
  173 | template <class Range> struct SuffixLexicographicLess : public std::binary_function<const Range, const Range, bool> {
      |                                                                     ^~~~~~~~~~~~~~~
/usr/include/c++/13/bits/stl_function.h:131:12: note: declared here
  131 |     struct binary_function
      |            ^~~~~~~~~~~~~~~
[ 97%] Linking CXX executable ../../bin/filter
[ 97%] Built target filter
In file included from /mnt/data/asr-finetuning/kenlm/lm/builder/../../util/stream/sort.hh:29,
                 from /mnt/data/asr-finetuning/kenlm/lm/builder/combine_counts.hh:8:
/mnt/data/asr-finetuning/kenlm/lm/builder/../../util/stream/../sized_iterator.hh:130:86: warning: template<class _Arg1, class _Arg2, class _Result> struct std::binary_function is deprecated [-Wdeprecated-declarations]
  130 | template <class Delegate, class Proxy = SizedProxy> class SizedCompare : public std::binary_function<const Proxy &, const Proxy &, bool> {
      |                                                                                      ^~~~~~~~~~~~~~~
/usr/include/c++/13/bits/stl_function.h:131:12: note: declared here
  131 |     struct binary_function
      |            ^~~~~~~~~~~~~~~
/mnt/data/asr-finetuning/kenlm/lm/builder/../../util/stream/../sized_iterator.hh:157:71: warning: template<class _Arg1, class _Arg2, class _Result> struct std::binary_function is deprecated [-Wdeprecated-declarations]
  157 | template <class Delegate, unsigned Size> class JustPODDelegate : std::binary_function<const JustPOD<Size> &, const JustPOD<Size> &, bool> {
      |                                                                       ^~~~~~~~~~~~~~~
/usr/include/c++/13/bits/stl_function.h:131:12: note: declared here
  131 |     struct binary_function
      |            ^~~~~~~~~~~~~~~
/mnt/data/asr-finetuning/kenlm/lm/builder/../../util/stream/sort.hh:203:33: warning: template<class _Arg1, class _Arg2, class _Result> struct std::binary_function is deprecated [-Wdeprecated-declarations]
  203 |     class Greater : public std::binary_function<const Entry &, const Entry &, bool> {
      |                                 ^~~~~~~~~~~~~~~
/usr/include/c++/13/bits/stl_function.h:131:12: note: declared here
  131 |     struct binary_function
      |            ^~~~~~~~~~~~~~~
[ 98%] Linking CXX executable ../../bin/lmplz
[ 98%] Built target lmplz
[100%] Linking CXX executable ../../bin/count_ngrams
[100%] Built target count_ngrams
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning/kenlm/build# ls -lh kenlm/build/bin/lmplz
ls: cannot access 'kenlm/build/bin/lmplz': No such file or directory
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning/kenlm/build# cd ..
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning/kenlm# cd ..
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# ls -lh kenlm/build/bin/lmplz
-rwxr-x--- 1 root root 1.5M Jan 22 19:44 kenlm/build/bin/lmplz
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# # Ensure you are at project root
cd /mnt/data/asr-finetuning

python3 << 'EOF'
import json

manifest_path = "data/training/v2.1/master_manifest.json"
output_text = "data/training/v2.1/all_text.txt"

print(f" Reading: {manifest_path}")
print(f" Writing: {output_text}")

count = 0
with open(output_text, 'w', encoding='utf-8') as out_f:
    with open(manifest_path, 'r', encoding='utf-8') as in_f:
        for line in in_f:
            data = json.loads(line)
            if "text" in data and data["text"].strip():
                out_f.write(data["text"] + "\n")
                count += 1

print(f" Extracted {count} lines.")
EOF
 Reading: data/training/v2.1/master_manifest.json
 Writing: data/training/v2.1/all_text.txt
 Extracted 417021 lines.
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# head  data/training/v2.1/all_text.txt
         
        
           
        
          
              
        
         
        
        
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# kenlm/build/bin/lmplz -o 4 < data/training/v3/all_text.txt > data/training/v3/kannada_4gram.arpa
bash: data/training/v3/all_text.txt: No such file or directory
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# kenlm/build/bin/lmplz -o 4 < data/training/v2.1/all_text.txt > data/training/v2.1/kannada_4gram.arpa
=== 1/5 Counting and sorting n-grams ===
Reading /mnt/data/asr-finetuning/data/training/v2.1/all_text.txt
----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100
****************************************************************************************************
Unigram tokens 4954914 types 465571
=== 2/5 Calculating and sorting adjusted counts ===
Chain sizes: 1:5586852 2:36798664704 3:68997496832 4:110395990016
Statistics:
1 465571 D1=0.734543 D2=1.02889 D3+=1.33905
2 2657001 D1=0.849932 D2=1.15652 D3+=1.33757
3 3883089 D1=0.928588 D2=1.31391 D3+=1.45948
4 4042387 D1=0.905509 D2=1.57727 D3+=1.87156
Memory estimate for binary LM:
type     MB
probing 230 assuming -p 1.5
probing 269 assuming -r models -p 1.5
trie    115 without quantization
trie     68 assuming -q 8 -b 8 quantization 
trie    104 assuming -a 22 array pointer compression
trie     56 assuming -a 22 -q 8 -b 8 array pointer compression and quantization
=== 3/5 Calculating and sorting initial probabilities ===
Chain sizes: 1:5586852 2:42512016 3:77661780 4:97017288
----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100
####################################################################################################
=== 4/5 Calculating and writing order-interpolated probabilities ===
Chain sizes: 1:5586852 2:42512016 3:77661780 4:97017288
----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100
####################################################################################################
=== 5/5 Writing ARPA model ===
----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100
****************************************************************************************************
Name:lmplz	VmPeak:211295336 kB	VmRSS:17508 kB	RSSMax:42351908 kB	user:11.3402	sys:33.8506	CPU:45.1909	real:42.2675
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# nano evaluation/benchmarking/run/run_benchmark_kenlm.py
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# ls training/models
kathbath_hybrid_h200_phase1_final.nemo       kathbath_hybrid_h200_phase2_final.nemo  kathbath_hybrid_h200_scaleup_p3_phase3_final.nemo  kathbath_v1_init_final.nemo
kathbath_hybrid_h200_phase1_safe_final.nemo  kathbath_hybrid_h200_phase3_final.nemo  kathbath_hybrid_h200_scaleup_phase2_final.nemo     kathbath_v2_unfrozen_final.nemo
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# python evaluation/benchmarking/run/run_benchmark_kenlm.py \
  --model_path "training/models/kathbath_hybrid_h200_scaleup_p3_phase3_final.nemo" \
  --manifest "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/test_manifest.json" \
  --kenlm_model_path "data/training/v3/kannada_4gram.arpa"
fused_indices_to_multihot has reached end of life. Please migrate to a non-experimental function.
OneLogger: Setting error_handling_strategy to DISABLE_QUIETLY_AND_REPORT_METRIC_ERROR for rank (rank=0) with OneLogger disabled. To override: explicitly set error_handling_strategy parameter.
No exporters were provided. This means that no telemetry data will be collected.
usage: run_benchmark_kenlm.py [-h] --model MODEL --manifest MANIFEST --output_dir OUTPUT_DIR [--batch_size BATCH_SIZE]
run_benchmark_kenlm.py: error: the following arguments are required: --model, --output_dir
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# rm evaluation/benchmarking/run/run_benchmark_kenlm.py
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# nano evaluation/benchmarking/run/run_benchmark_kenlm.py
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# python evaluation/benchmarking/run/run_benchmark_kenlm.py   --model_path "training/models/kathbath_hybrid_h200_scaleup_p3_phase3_final.nemo"   --manifest "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/test_manifest.json"   --kenlm_model_path "data/training/v3/kannada_4gram.arpa"
Traceback (most recent call last):
  File "/mnt/data/asr-finetuning/evaluation/benchmarking/run/run_benchmark_kenlm.py", line 1, in <module>
    cat << 'EOF' > evaluation/benchmarking/run/run_benchmark_kenlm.py
    ^^^
NameError: name 'cat' is not defined
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# nano evaluation/benchmarking/run/run_benchmark_kenlm.py
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# python evaluation/benchmarking/run/run_benchmark_kenlm.py   --model_path "training/models/kathbath_hybrid_h200_scaleup_p3_phase3_final.nemo"   --manifest "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/test_manifest.json"   --kenlm_model_path "data/training/v3/kannada_4gram.arpa"
fused_indices_to_multihot has reached end of life. Please migrate to a non-experimental function.
OneLogger: Setting error_handling_strategy to DISABLE_QUIETLY_AND_REPORT_METRIC_ERROR for rank (rank=0) with OneLogger disabled. To override: explicitly set error_handling_strategy parameter.
No exporters were provided. This means that no telemetry data will be collected.
Traceback (most recent call last):
  File "/mnt/data/asr-finetuning/evaluation/benchmarking/run/run_benchmark_kenlm.py", line 10, in <module>
    from nemo.collections.asr.modules import CTCBeamDecoding
ImportError: cannot import name 'CTCBeamDecoding' from 'nemo.collections.asr.modules' (/mnt/data/asr-env/lib/python3.12/site-packages/nemo/collections/asr/modules/__init__.py)
timed out waiting for input: auto-logout-finetuning# 
timed out waiting for input: auto-logout
Connection to 10.0.0.147 closed.
timed out waiting for input: auto-logout
Connection to 47.29.24.119 closed.
chaitanyakartik@Chaitanyas-MacBook-Air:~ $ ssh ubuntu@47.29.24.119
Authorized uses only. All activity may be monitored and reported.
Welcome to Ubuntu 22.04.5 LTS (GNU/Linux 5.15.0-144-generic x86_64)

 * Documentation:  https://help.ubuntu.com
 * Management:     https://landscape.canonical.com
 * Support:        https://ubuntu.com/pro

 System information as of Thu Jan 22 09:39:43 PM IST 2026

  System load:    0.04              Processes:               265
  Usage of /home: 43.4% of 4.99GB   Users logged in:         0
  Memory usage:   4%                IPv4 address for enp3s0: 10.0.0.234
  Swap usage:     0%

 * Strictly confined Kubernetes makes edge and IoT secure. Learn how MicroK8s
   just raised the bar for easy, resilient and secure K8s cluster deployment.

   https://ubuntu.com/engage/secure-kubernetes-at-the-edge

Expanded Security Maintenance for Applications is not enabled.

97 updates can be applied immediately.
75 of these updates are standard security updates.
To see these additional updates run: apt list --upgradable

Enable ESM Apps to receive additional future security updates.
See https://ubuntu.com/esm or run: sudo pro status


The list of available updates is more than a week old.
To check for new updates run: sudo apt update
New release '24.04.3 LTS' available.
Run 'do-release-upgrade' to upgrade to it.


Authorized uses only. All activity may be monitored and reported.
Last login: Thu Jan 22 19:22:52 2026 from 103.83.29.160
ubuntu@bh-01:~$ NeuroDX@25112025
WARNING:root:could not open file '/etc/apt/sources.list'

NeuroDX@25112025: command not found
ubuntu@bh-01:~$ ssh neurodx@10.0.0.147
Authorized uses only. All activity may be monitored and reported.
neurodx@10.0.0.147's password: 
Welcome to Ubuntu 24.04.2 LTS (GNU/Linux 6.8.0-56-generic x86_64)

 * Documentation:  https://help.ubuntu.com
 * Management:     https://landscape.canonical.com
 * Support:        https://ubuntu.com/pro

 System information as of Thu Jan 22 09:40:53 PM IST 2026

  System load:    0.8               Processes:               882
  Usage of /home: 55.9% of 4.94GB   Users logged in:         1
  Memory usage:   4%                IPv4 address for enp3s0: 10.0.0.147
  Swap usage:     0%

  => /var/log/audit is using 100.0% of 4.94GB


Expanded Security Maintenance for Applications is not enabled.

232 updates can be applied immediately.
139 of these updates are standard security updates.
To see these additional updates run: apt list --upgradable

13 additional security updates can be applied with ESM Apps.
Learn more about enabling ESM Apps service at https://ubuntu.com/esm


Last login: Thu Jan 22 19:22:59 2026 from 10.0.0.234

(base) neurodx@h200-nvl-2x:~$ 
(base) neurodx@h200-nvl-2x:~$ sudo su
root@h200-nvl-2x:/home/neurodx# cd /mnt/data
source asr-env/bin/activate 
cd asr-finetuning
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# python3 << 'EOF'
import os
import nemo
import pkgutil
import inspect

print("="*60)
print(f" EXPLORING NEMO INSTALLATION FOR BEAM SEARCH")
print("="*60)

# 1. Locate the package on disk
nemo_path = os.path.dirname(nemo.__file__)
print(f" Base NeMo Path: {nemo_path}")
print(f"  NeMo Version: {nemo.__version__}")

print("\n1  SEARCHING FILESYSTEM (Scaning for '*beam*' files)...")
found_modules = []

for root, dirs, files in os.walk(nemo_path):
    for file in files:
        if "beam" in file.lower() and file.endswith(".py"):
            full_path = os.path.join(root, file)
            # Convert file path to python import path
            rel_path = os.path.relpath(full_path, nemo_path)
            import_path = "nemo." + rel_path.replace("/", ".")[:-3] # remove .py
            
            print(f"    Found File: {rel_path}")
            found_modules.append(import_path)

print("\n2  TESTING IMPORTS (Checking classes inside found files)...")

for mod_name in found_modules:
    try:
        print(f"    Importing: {mod_name} ... ", end="")
        module = __import__(mod_name, fromlist=[''])
        print(" SUCCESS")
        
        # List likely classes
        has_classes = False
        for name, obj in inspect.getmembers(module):
            if inspect.isclass(obj) and ("Beam" in name or "Decod" in name):
                print(f"        Found Class: {name}")
                has_classes = True
        
        if not has_classes:
            print("       (No obvious BeamSearch classes found inside)")
            
    except Exception as e:
        print(f" FAILED ({str(e)})")

print("="*60)
EOF
============================================================
 EXPLORING NEMO INSTALLATION FOR BEAM SEARCH
============================================================
 Base NeMo Path: /mnt/data/asr-env/lib/python3.12/site-packages/nemo
  NeMo Version: 2.7.0rc0

1  SEARCHING FILESYSTEM (Scaning for '*beam*' files)...
    Found File: collections/asr/parts/utils/batched_beam_decoding_utils.py
    Found File: collections/asr/parts/submodules/multitask_beam_decoding.py
    Found File: collections/asr/parts/submodules/tdt_beam_decoding.py
    Found File: collections/asr/parts/submodules/ctc_batched_beam_decoding.py
    Found File: collections/asr/parts/submodules/rnnt_beam_decoding.py
    Found File: collections/asr/parts/submodules/ctc_beam_decoding.py
    Found File: collections/asr/modules/beam_search_decoder.py

2  TESTING IMPORTS (Checking classes inside found files)...
fused_indices_to_multihot has reached end of life. Please migrate to a non-experimental function.
OneLogger: Setting error_handling_strategy to DISABLE_QUIETLY_AND_REPORT_METRIC_ERROR for rank (rank=0) with OneLogger disabled. To override: explicitly set error_handling_strategy parameter.
No exporters were provided. This means that no telemetry data will be collected.
    Importing: nemo.collections.asr.parts.utils.batched_beam_decoding_utils ...  SUCCESS
        Found Class: BatchedBeamHyps
    Importing: nemo.collections.asr.parts.submodules.multitask_beam_decoding ...  SUCCESS
        Found Class: AEDBeamInfer
        Found Class: AEDBeamInferConfig
        Found Class: BeamSearchSequenceGenerator
        Found Class: BeamSearchSequenceGeneratorWithFusionModels
        Found Class: TransformerAEDBeamInfer
    Importing: nemo.collections.asr.parts.submodules.tdt_beam_decoding ...  SUCCESS
        Found Class: BeamBatchedTDTInfer
        Found Class: BeamTDTInfer
    Importing: nemo.collections.asr.parts.submodules.ctc_batched_beam_decoding ...  SUCCESS
        Found Class: BacthedBeamCTCState
        Found Class: BatchedBeamCTCComputer
        Found Class: BatchedBeamHyps
        Found Class: SeparateGraphsBatchedBeamCTC
    Importing: nemo.collections.asr.parts.submodules.rnnt_beam_decoding ...  SUCCESS
        Found Class: BeamBatchedRNNTInfer
        Found Class: BeamRNNTInfer
        Found Class: BeamRNNTInferConfig
    Importing: nemo.collections.asr.parts.submodules.ctc_beam_decoding ...  SUCCESS
        Found Class: AbstractBeamCTCInfer
        Found Class: BatchedBeamCTCComputer
        Found Class: BeamBatchedCTCInfer
        Found Class: BeamCTCInfer
        Found Class: BeamCTCInferConfig
        Found Class: PyCTCDecodeConfig
        Found Class: RivaDecoderConfig
    Importing: nemo.collections.asr.modules.beam_search_decoder ...  SUCCESS
        Found Class: BeamSearchDecoderWithLM
============================================================
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# cat << 'EOF' > evaluation/benchmarking/run/run_benchmark_kenlm.py
import argparse
import json
import torch
import os
import jiwer
from tqdm import tqdm
import librosa
import numpy as np
from nemo.collections.asr.models import EncDecHybridRNNTCTCBPEModel

# --- DYNAMIC IMPORT BASED ON YOUR SCAN ---
try:
    # This is the file you found in the scan
    from nemo.collections.asr.modules.beam_search_decoder import BeamSearchDecoderWithLM
except ImportError:
    print("  Could not import BeamSearchDecoderWithLM directly.")
    print("   Attempting fallback to internal parts...")
    try:
        from nemo.collections.asr.parts.submodules.ctc_beam_decoding import BeamCTCInfer
        # Create a wrapper to make BeamCTCInfer look like BeamSearchDecoderWithLM
        class BeamSearchDecoderWithLM(BeamCTCInfer):
            def __init__(self, vocab, kenlm_path, beam_width, alpha, beta, **kwargs):
                super().__init__(
                    decoding_cfg={
                        "beam_width": beam_width,
                        "kenlm_path": kenlm_path,
                        "alpha": alpha, 
                        "beta": beta
                    },
                    vocabulary=vocab
                )
    except ImportError:
        print(" CRITICAL: Could not find any Beam Search decoder class.")
        exit(1)

def parse_args():
    parser = argparse.ArgumentParser(description="KenLM Beam Search Benchmark")
    parser.add_argument("--model", type=str, required=True, help="Path to .nemo model")
    parser.add_argument("--manifest", type=str, required=True, help="Path to manifest.json")
    parser.add_argument("--kenlm_model_path", type=str, required=True, help="Path to .arpa file")
    parser.add_argument("--output_dir", type=str, required=True, help="Dir to save results")
    parser.add_argument("--batch_size", type=int, default=16)
    parser.add_argument("--beam_width", type=int, default=128)
    parser.add_argument("--alpha", type=float, default=0.5, help="LM Weight")
    parser.add_argument("--beta", type=float, default=1.0, help="Word Count Weight")
    return parser.parse_args()

def load_audio(path, target_sr=16000):
    try:
        audio, _ = librosa.load(path, sr=target_sr)
        return torch.tensor(audio, dtype=torch.float32), len(audio)
    except Exception as e:
        return None, 0

def run_eval(args):
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f" Device: {device}")

    # 1. Load Model
EOF run_eval(parse_args())r:.2f} | CER: {cer:.2f}").txt"), "w") as f:) dtype=torch.long)
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# cat << 'EOF' > evaluation/benchmarking/run/run_benchmark_kenlm.py
import argparse                                      python3 << 'EOF'                                                 
import os                                            python evaluation/benchmarking/run/run_benchmark_kenlm.py   --model_path "training/models/kathbath_hybrid_h200_scaleup_p3_phase3_final.nemo"   --manifest "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/test_manifest.json"   --kenlm_model_path "data/training/v3/kannada_4gram.arpa"
fused_indices_to_multihot has reached end of life. Please migrate to a non-experimental function.
OneLogger: Setting error_handling_strategy to DISABLE_QUIETLY_AND_REPORT_METRIC_ERROR for rank (rank=0) with OneLogger disabled. To override: explicitly set error_handling_strategy parameter.
No exporters were provided. This means that no telemetry data will be collected.
usage: run_benchmark_kenlm.py [-h] --model MODEL --manifest MANIFEST --kenlm_model_path KENLM_MODEL_PATH --output_dir OUTPUT_DIR [--batch_size BATCH_SIZE] [--beam_width BEAM_WIDTH] [--alpha ALPHA]
                              [--beta BETA]
run_benchmark_kenlm.py: error: the following arguments are required: --model, --output_dir
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# python evaluation/benchmarking/run/run_benchmark_kenlm.py \
  --model "training/models/kathbath_hybrid_h200_scaleup_p3_phase3_final.nemo" \
  --manifest "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/test_manifest.json" \
  --kenlm_model_path "data/training/v3/kannada_4gram.arpa" \
  --output_dir "models/results_kenlm_v1"
fused_indices_to_multihot has reached end of life. Please migrate to a non-experimental function.
OneLogger: Setting error_handling_strategy to DISABLE_QUIETLY_AND_REPORT_METRIC_ERROR for rank (rank=0) with OneLogger disabled. To override: explicitly set error_handling_strategy parameter.
No exporters were provided. This means that no telemetry data will be collected.
 Device: cuda
 Loading Model: training/models/kathbath_hybrid_h200_scaleup_p3_phase3_final.nemo
[NeMo I 2026-01-22 21:49:52 mixins:208] _setup_tokenizer: detected an aggregate tokenizer
[NeMo I 2026-01-22 21:49:52 mixins:347] Tokenizer SentencePieceTokenizer initialized with 1024 tokens
[NeMo I 2026-01-22 21:49:52 mixins:347] Tokenizer SentencePieceTokenizer initialized with 3000 tokens
[NeMo I 2026-01-22 21:49:52 aggregate_tokenizer:73] Aggregate vocab size: 4024
[NeMo W 2026-01-22 21:49:56 modelPT:188] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.
    Train config : 
    manifest_filepath: data/training/v2/master_manifest.json
    sample_rate: 16000
    batch_size: 32
    shuffle: true
    num_workers: 16
    pin_memory: true
    use_start_end_token: false
    min_duration: 1.5
    max_duration: 40.0
    prefetch_factor: 4
    
[NeMo W 2026-01-22 21:49:56 modelPT:195] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). 
    Validation config : 
    manifest_filepath:
    - /mnt/data/asr-finetuning/evaluation/benchmarking/data/v1/en_clean_read.json
    - /mnt/data/asr-finetuning/evaluation/benchmarking/data/v1/kn_clean_read.json
    sample_rate: 16000
    batch_size: 32
    shuffle: false
    num_workers: 16
    
[NeMo W 2026-01-22 21:49:56 modelPT:202] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).
    Test config : 
    manifest_filepath: null
    sample_rate: 16000
    batch_size: 16
    shuffle: false
    num_workers: 8
    pin_memory: true
    use_start_end_token: false
    
[NeMo I 2026-01-22 21:49:58 rnnt_models:226] Using RNNT Loss : warprnnt_numba
    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}
[NeMo I 2026-01-22 21:49:58 rnnt_models:226] Using RNNT Loss : warprnnt_numba
    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}
[NeMo W 2026-01-22 21:49:58 label_looping_base:123] No conditional node support for Cuda.
    Cuda graphs with while loops are disabled, decoding speed will be slower
    Reason: Driver supports cuda toolkit version 12.4, but the driver needs to support at least 12,6. Please update your cuda driver.
[NeMo I 2026-01-22 21:49:59 rnnt_models:226] Using RNNT Loss : warprnnt_numba
    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}
[NeMo W 2026-01-22 21:49:59 label_looping_base:123] No conditional node support for Cuda.
    Cuda graphs with while loops are disabled, decoding speed will be slower
    Reason: Driver supports cuda toolkit version 12.4, but the driver needs to support at least 12,6. Please update your cuda driver.
[NeMo I 2026-01-22 21:50:00 save_restore_connector:285] Model EncDecHybridRNNTCTCBPEModel was successfully restored from /mnt/data/asr-finetuning/training/models/kathbath_hybrid_h200_scaleup_p3_phase3_final.nemo.
 Loading KenLM: data/training/v3/kannada_4gram.arpa
Traceback (most recent call last):
  File "/mnt/data/asr-finetuning/evaluation/benchmarking/run/run_benchmark_kenlm.py", line 171, in <module>
    run_eval(parse_args())
  File "/mnt/data/asr-finetuning/evaluation/benchmarking/run/run_benchmark_kenlm.py", line 68, in run_eval
    vocab = model.decoder.vocabulary
            ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/data/asr-env/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1931, in __getattr__
    raise AttributeError(
AttributeError: 'RNNTDecoder' object has no attribute 'vocabulary'
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# cat << 'EOF' > evaluation/benchmarking/run/run_benchmark_kenlm.py
import argparse
import json
import torch
import os
import jiwer
from tqdm import tqdm
import librosa
import numpy as np
from nemo.collections.asr.models import EncDecHybridRNNTCTCBPEModel

# --- 1. DYNAMIC IMPORT (Version Safe) ---
try:
    from nemo.collections.asr.modules.beam_search_decoder import BeamSearchDecoderWithLM
except ImportError:
    try:
        from nemo.collections.asr.parts.submodules.ctc_beam_decoding import BeamCTCInfer as BeamSearchDecoderWithLM
    except ImportError:
        print(" CRITICAL: Could not find BeamSearchDecoderWithLM. Ensure 'pyctcdecode' is installed.")
        exit(1)

# --- 2. VOCABULARY EXTRACTOR (The Fix) ---
def get_vocab(model):
    """Safely extracts vocabulary from any NeMo ASR model (BPE or Char)"""
    # Case A: BPE Models (Has Tokenizer)
    if hasattr(model, 'tokenizer'):
        # For SentencePiece/BPE, we reconstruct the vocab list manually
        # to ensure it matches the decoder's output indices.
        vocab_size = model.tokenizer.vocab_size
        vocab = []
        for i in range(vocab_size):
            # We treat the token as its string representation
            # Note: id_to_piece is safer than ids_to_text for raw subwords
            if hasattr(model.tokenizer, 'tokenizer') and hasattr(model.tokenizer.tokenizer, 'id_to_piece'):
                vocab.append(model.tokenizer.tokenizer.id_to_piece(i))
            else:
                # Fallback: simple decode
                vocab.append(model.tokenizer.ids_to_text([i]))
        return vocab
    
    # Case B: Char Models (Has Decoder Vocabulary)
    elif hasattr(model.decoder, 'vocabulary'):
        return model.decoder.vocabulary
    
    # Case C: Deep Fallback
    elif hasattr(model, 'cfg') and 'labels' in model.cfg:
        return model.cfg.labels
        
    raise AttributeError("Could not find vocabulary in model. Checked tokenizer and decoder.")

def parse_args():
    parser = argparse.ArgumentParser(description="KenLM Beam Search Benchmark")
    parser.add_argument("--model", type=str, required=True, help="Path to .nemo model")
    parser.add_argument("--manifest", type=str, required=True, help="Path to manifest.json")
    parser.add_argument("--kenlm_model_path", type=str, required=True, help="Path to .arpa file")
    parser.add_argument("--output_dir", type=str, required=True, help="Dir to save results")
    parser.add_argument("--batch_size", type=int, default=16)
    parser.add_argument("--beam_width", type=int, default=128)
    parser.add_argument("--alpha", type=float, default=0.5, help="LM Weight")
    parser.add_argument("--beta", type=float, default=1.0, help="Word Count Weight")
EOF run_eval(parse_args())r:.2f} | CER: {cer:.2f}").txt"), "w") as f:, dtype=torch.long)
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# python evaluation/benchmarking/run/run_benchmark_kenlm.py \
  --model "training/models/kathbath_hybrid_h200_scaleup_p3_phase3_final.nemo" \
  --manifest "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/test_manifest.json" \
  --kenlm_model_path "data/training/v3/kannada_4gram.arpa" \
  --output_dir "models/results_kenlm_v1"
fused_indices_to_multihot has reached end of life. Please migrate to a non-experimental function.
OneLogger: Setting error_handling_strategy to DISABLE_QUIETLY_AND_REPORT_METRIC_ERROR for rank (rank=0) with OneLogger disabled. To override: explicitly set error_handling_strategy parameter.
No exporters were provided. This means that no telemetry data will be collected.
 Device: cuda
 Loading Model: training/models/kathbath_hybrid_h200_scaleup_p3_phase3_final.nemo
[NeMo I 2026-01-22 21:52:10 mixins:208] _setup_tokenizer: detected an aggregate tokenizer
[NeMo I 2026-01-22 21:52:10 mixins:347] Tokenizer SentencePieceTokenizer initialized with 1024 tokens
[NeMo I 2026-01-22 21:52:10 mixins:347] Tokenizer SentencePieceTokenizer initialized with 3000 tokens
[NeMo I 2026-01-22 21:52:10 aggregate_tokenizer:73] Aggregate vocab size: 4024
[NeMo W 2026-01-22 21:52:14 modelPT:188] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.
    Train config : 
    manifest_filepath: data/training/v2/master_manifest.json
    sample_rate: 16000
    batch_size: 32
    shuffle: true
    num_workers: 16
    pin_memory: true
    use_start_end_token: false
    min_duration: 1.5
    max_duration: 40.0
    prefetch_factor: 4
    
[NeMo W 2026-01-22 21:52:14 modelPT:195] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). 
    Validation config : 
    manifest_filepath:
    - /mnt/data/asr-finetuning/evaluation/benchmarking/data/v1/en_clean_read.json
    - /mnt/data/asr-finetuning/evaluation/benchmarking/data/v1/kn_clean_read.json
    sample_rate: 16000
    batch_size: 32
    shuffle: false
    num_workers: 16
    
[NeMo W 2026-01-22 21:52:14 modelPT:202] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).
    Test config : 
    manifest_filepath: null
    sample_rate: 16000
    batch_size: 16
    shuffle: false
    num_workers: 8
    pin_memory: true
    use_start_end_token: false
    
[NeMo I 2026-01-22 21:52:16 rnnt_models:226] Using RNNT Loss : warprnnt_numba
    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}
[NeMo I 2026-01-22 21:52:16 rnnt_models:226] Using RNNT Loss : warprnnt_numba
    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}
[NeMo W 2026-01-22 21:52:16 label_looping_base:123] No conditional node support for Cuda.
    Cuda graphs with while loops are disabled, decoding speed will be slower
    Reason: Driver supports cuda toolkit version 12.4, but the driver needs to support at least 12,6. Please update your cuda driver.
[NeMo I 2026-01-22 21:52:16 rnnt_models:226] Using RNNT Loss : warprnnt_numba
    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}
[NeMo W 2026-01-22 21:52:16 label_looping_base:123] No conditional node support for Cuda.
    Cuda graphs with while loops are disabled, decoding speed will be slower
    Reason: Driver supports cuda toolkit version 12.4, but the driver needs to support at least 12,6. Please update your cuda driver.
[NeMo I 2026-01-22 21:52:18 save_restore_connector:285] Model EncDecHybridRNNTCTCBPEModel was successfully restored from /mnt/data/asr-finetuning/training/models/kathbath_hybrid_h200_scaleup_p3_phase3_final.nemo.
 Loading KenLM: data/training/v3/kannada_4gram.arpa
    Extracted Vocabulary Size: 4024
Traceback (most recent call last):
  File "/mnt/data/asr-finetuning/evaluation/benchmarking/run/run_benchmark_kenlm.py", line 187, in <module>
    run_eval(parse_args())
  File "/mnt/data/asr-finetuning/evaluation/benchmarking/run/run_benchmark_kenlm.py", line 87, in run_eval
    beam_search_lm = BeamSearchDecoderWithLM(
                     ^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: BeamSearchDecoderWithLM.__init__() got an unexpected keyword argument 'kenlm_path'
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# cat << 'EOF' > evaluation/benchmarking/run/run_benchmark_kenlm.py
import argparse
import json
import torch
import os
import jiwer
from tqdm import tqdm
import librosa
import numpy as np
from nemo.collections.asr.models import EncDecHybridRNNTCTCBPEModel

# --- 1. DYNAMIC IMPORT ---
try:
    from nemo.collections.asr.modules.beam_search_decoder import BeamSearchDecoderWithLM
except ImportError:
    from nemo.collections.asr.parts.submodules.ctc_beam_decoding import BeamCTCInfer as BeamSearchDecoderWithLM

# --- 2. VOCABULARY EXTRACTOR ---
def get_vocab(model):
    """Safely extracts vocabulary from BPE/Char models"""
    if hasattr(model, 'tokenizer'):
        vocab_size = model.tokenizer.vocab_size
        vocab = []
        for i in range(vocab_size):
            if hasattr(model.tokenizer, 'tokenizer') and hasattr(model.tokenizer.tokenizer, 'id_to_piece'):
                vocab.append(model.tokenizer.tokenizer.id_to_piece(i))
            else:
                vocab.append(model.tokenizer.ids_to_text([i]))
        return vocab
    elif hasattr(model.decoder, 'vocabulary'):
        return model.decoder.vocabulary
    elif hasattr(model, 'cfg') and 'labels' in model.cfg:
        return model.cfg.labels
    raise AttributeError("Could not find vocabulary in model. Checked tokenizer and decoder.")

def parse_args():
    parser = argparse.ArgumentParser(description="KenLM Beam Search Benchmark")
    parser.add_argument("--model", type=str, required=True, help="Path to .nemo model")
    parser.add_argument("--manifest", type=str, required=True, help="Path to manifest.json")
    parser.add_argument("--kenlm_model_path", type=str, required=True, help="Path to .arpa file")
    parser.add_argument("--output_dir", type=str, required=True, help="Dir to save results")
    parser.add_argument("--batch_size", type=int, default=16)
    parser.add_argument("--beam_width", type=int, default=128)
    parser.add_argument("--alpha", type=float, default=0.5, help="LM Weight")
    parser.add_argument("--beta", type=float, default=1.0, help="Word Count Weight")
    return parser.parse_args()

def load_audio(path, target_sr=16000):
    try:
        audio, _ = librosa.load(path, sr=target_sr)
        return torch.tensor(audio, dtype=torch.float32), len(audio)
    except Exception as e:
        return None, 0

def run_eval(args):
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f" Device: {device}")

    print(f" Loading Model: {args.model}")
    model = EncDecHybridRNNTCTCBPEModel.restore_from(args.model)
EOF run_eval(parse_args())r:.2f} | CER: {cer:.2f}").txt"), "w") as f:, dtype=torch.long)
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# cat << 'EOF' > evaluation/benchmarking/run/run_benchmark_kenlm.py
import argparse                                      python evaluation/benchmarking/run/run_benchmark_kenlm.py   --model "training/models/kathbath_hybrid_h200_scaleup_p3_phase3_final.nemo"   --manifest "/mnt/data/asr-finetuning/evaluation/benchmarking/curatiocat << 'EOF' > evaluation/benchmarking/run/run_benchmark_kenlm.py
import argparse                                      
                                                     ^C
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# python evaluation/benchmarking/run/run_benchmark_kenlm.py \
  --model "training/models/kathbath_hybrid_h200_scaleup_p3_phase3_final.nemo" \
  --manifest "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/test_manifest.json" \
  --kenlm_model_path "data/training/v3/kannada_4gram.arpa" \
  --output_dir "models/results_kenlm_v1"
fused_indices_to_multihot has reached end of life. Please migrate to a non-experimental function.
OneLogger: Setting error_handling_strategy to DISABLE_QUIETLY_AND_REPORT_METRIC_ERROR for rank (rank=0) with OneLogger disabled. To override: explicitly set error_handling_strategy parameter.
No exporters were provided. This means that no telemetry data will be collected.
 Device: cuda
 Loading Model: training/models/kathbath_hybrid_h200_scaleup_p3_phase3_final.nemo
[NeMo I 2026-01-22 21:54:09 mixins:208] _setup_tokenizer: detected an aggregate tokenizer
[NeMo I 2026-01-22 21:54:09 mixins:347] Tokenizer SentencePieceTokenizer initialized with 1024 tokens
[NeMo I 2026-01-22 21:54:09 mixins:347] Tokenizer SentencePieceTokenizer initialized with 3000 tokens
[NeMo I 2026-01-22 21:54:09 aggregate_tokenizer:73] Aggregate vocab size: 4024
[NeMo W 2026-01-22 21:54:13 modelPT:188] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.
    Train config : 
    manifest_filepath: data/training/v2/master_manifest.json
    sample_rate: 16000
    batch_size: 32
    shuffle: true
    num_workers: 16
    pin_memory: true
    use_start_end_token: false
    min_duration: 1.5
    max_duration: 40.0
    prefetch_factor: 4
    
[NeMo W 2026-01-22 21:54:13 modelPT:195] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). 
    Validation config : 
    manifest_filepath:
    - /mnt/data/asr-finetuning/evaluation/benchmarking/data/v1/en_clean_read.json
    - /mnt/data/asr-finetuning/evaluation/benchmarking/data/v1/kn_clean_read.json
    sample_rate: 16000
    batch_size: 32
    shuffle: false
    num_workers: 16
    
[NeMo W 2026-01-22 21:54:13 modelPT:202] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).
    Test config : 
    manifest_filepath: null
    sample_rate: 16000
    batch_size: 16
    shuffle: false
    num_workers: 8
    pin_memory: true
    use_start_end_token: false
    
[NeMo I 2026-01-22 21:54:15 rnnt_models:226] Using RNNT Loss : warprnnt_numba
    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}
[NeMo I 2026-01-22 21:54:15 rnnt_models:226] Using RNNT Loss : warprnnt_numba
    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}
[NeMo W 2026-01-22 21:54:15 label_looping_base:123] No conditional node support for Cuda.
    Cuda graphs with while loops are disabled, decoding speed will be slower
    Reason: Driver supports cuda toolkit version 12.4, but the driver needs to support at least 12,6. Please update your cuda driver.
[NeMo I 2026-01-22 21:54:16 rnnt_models:226] Using RNNT Loss : warprnnt_numba
    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}
[NeMo W 2026-01-22 21:54:16 label_looping_base:123] No conditional node support for Cuda.
    Cuda graphs with while loops are disabled, decoding speed will be slower
    Reason: Driver supports cuda toolkit version 12.4, but the driver needs to support at least 12,6. Please update your cuda driver.
[NeMo I 2026-01-22 21:54:17 save_restore_connector:285] Model EncDecHybridRNNTCTCBPEModel was successfully restored from /mnt/data/asr-finetuning/training/models/kathbath_hybrid_h200_scaleup_p3_phase3_final.nemo.
 Loading KenLM: data/training/v3/kannada_4gram.arpa
    Extracted Vocabulary Size: 4024
Traceback (most recent call last):
  File "/mnt/data/asr-env/lib/python3.12/site-packages/nemo/collections/asr/modules/beam_search_decoder.py", line 64, in __init__
    from ctc_decoders import Scorer, ctc_beam_search_decoder_batch
ModuleNotFoundError: No module named 'ctc_decoders'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/mnt/data/asr-finetuning/evaluation/benchmarking/run/run_benchmark_kenlm.py", line 160, in <module>
    run_eval(parse_args())
  File "/mnt/data/asr-finetuning/evaluation/benchmarking/run/run_benchmark_kenlm.py", line 69, in run_eval
    beam_search_lm = BeamSearchDecoderWithLM(
                     ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/data/asr-env/lib/python3.12/site-packages/nemo/collections/asr/modules/beam_search_decoder.py", line 66, in __init__
    raise ModuleNotFoundError(
ModuleNotFoundError: BeamSearchDecoderWithLM requires the installation of ctc_decoders from scripts/asr_language_modeling/ngram_lm/install_beamsearch_decoders.sh
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# pip install pyctcdecode
Collecting pyctcdecode
  Downloading pyctcdecode-0.5.0-py2.py3-none-any.whl.metadata (20 kB)
Requirement already satisfied: numpy<2.0.0,>=1.15.0 in /mnt/data/asr-env/lib/python3.12/site-packages (from pyctcdecode) (1.26.4)
Collecting pygtrie<3.0,>=2.1 (from pyctcdecode)
  Downloading pygtrie-2.5.0-py3-none-any.whl.metadata (7.5 kB)
Collecting hypothesis<7,>=6.14 (from pyctcdecode)
  Downloading hypothesis-6.150.2-py3-none-any.whl.metadata (5.6 kB)
Requirement already satisfied: sortedcontainers<3.0.0,>=2.1.0 in /mnt/data/asr-env/lib/python3.12/site-packages (from hypothesis<7,>=6.14->pyctcdecode) (2.4.0)
Downloading pyctcdecode-0.5.0-py2.py3-none-any.whl (39 kB)
Downloading hypothesis-6.150.2-py3-none-any.whl (542 kB)
    542.7/542.7 kB 12.6 MB/s eta 0:00:00
Downloading pygtrie-2.5.0-py3-none-any.whl (25 kB)
Installing collected packages: pygtrie, hypothesis, pyctcdecode
Successfully installed hypothesis-6.150.2 pyctcdecode-0.5.0 pygtrie-2.5.0
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# cat << 'EOF' > evaluation/benchmarking/run/run_benchmark_kenlm.py
import argparse
import json
import torch
import os
import jiwer
from tqdm import tqdm
import librosa
import numpy as np
from nemo.collections.asr.models import EncDecHybridRNNTCTCBPEModel

# --- 1. IMPORT MODERN DECODER ---
try:
    from pyctcdecode import build_ctcdecoder
except ImportError:
    print(" Error: pyctcdecode not found. Run: pip install pyctcdecode")
    exit(1)

# --- 2. VOCABULARY EXTRACTOR ---
def get_vocab(model):
    """Safely extracts vocabulary from BPE/Char models"""
    if hasattr(model, 'tokenizer'):
        vocab_size = model.tokenizer.vocab_size
        vocab = []
        for i in range(vocab_size):
            if hasattr(model.tokenizer, 'tokenizer') and hasattr(model.tokenizer.tokenizer, 'id_to_piece'):
                vocab.append(model.tokenizer.tokenizer.id_to_piece(i))
            else:
                vocab.append(model.tokenizer.ids_to_text([i]))
        return vocab
    elif hasattr(model.decoder, 'vocabulary'):
        return model.decoder.vocabulary
    elif hasattr(model, 'cfg') and 'labels' in model.cfg:
        return model.cfg.labels
    raise AttributeError("Could not find vocabulary.")

def parse_args():
    parser = argparse.ArgumentParser(description="KenLM Beam Search Benchmark")
    parser.add_argument("--model", type=str, required=True)
    parser.add_argument("--manifest", type=str, required=True)
    parser.add_argument("--kenlm_model_path", type=str, required=True)
    parser.add_argument("--output_dir", type=str, required=True)
    parser.add_argument("--batch_size", type=int, default=16)
    parser.add_argument("--beam_width", type=int, default=128)
    parser.add_argument("--alpha", type=float, default=0.5)
    parser.add_argument("--beta", type=float, default=1.0)
    return parser.parse_args()

def load_audio(path, target_sr=16000):
    try:
        audio, _ = librosa.load(path, sr=target_sr)
        return torch.tensor(audio, dtype=torch.float32), len(audio)
    except:
        return None, 0

def run_eval(args):
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f" Device: {device}")

    # 1. Load NeMo Model
EOF run_eval(parse_args())r:.2f} | CER: {cer:.2f}").txt"), "w") as f:, dtype=torch.long)
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# python evaluation/benchmarking/run/run_benchmark_kenlm.py \
  --model "training/models/kathbath_hybrid_h200_scaleup_p3_phase3_final.nemo" \
  --manifest "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/test_manifest.json" \
  --kenlm_model_path "data/training/v3/kannada_4gram.arpa" \
  --output_dir "models/results_kenlm_v1"
fused_indices_to_multihot has reached end of life. Please migrate to a non-experimental function.
OneLogger: Setting error_handling_strategy to DISABLE_QUIETLY_AND_REPORT_METRIC_ERROR for rank (rank=0) with OneLogger disabled. To override: explicitly set error_handling_strategy parameter.
No exporters were provided. This means that no telemetry data will be collected.
 Device: cuda
 Loading Model: training/models/kathbath_hybrid_h200_scaleup_p3_phase3_final.nemo
[NeMo I 2026-01-22 21:56:16 mixins:208] _setup_tokenizer: detected an aggregate tokenizer
[NeMo I 2026-01-22 21:56:16 mixins:347] Tokenizer SentencePieceTokenizer initialized with 1024 tokens
[NeMo I 2026-01-22 21:56:16 mixins:347] Tokenizer SentencePieceTokenizer initialized with 3000 tokens
[NeMo I 2026-01-22 21:56:16 aggregate_tokenizer:73] Aggregate vocab size: 4024
[NeMo W 2026-01-22 21:56:22 modelPT:188] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.
    Train config : 
    manifest_filepath: data/training/v2/master_manifest.json
    sample_rate: 16000
    batch_size: 32
    shuffle: true
    num_workers: 16
    pin_memory: true
    use_start_end_token: false
    min_duration: 1.5
    max_duration: 40.0
    prefetch_factor: 4
    
[NeMo W 2026-01-22 21:56:22 modelPT:195] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). 
    Validation config : 
    manifest_filepath:
    - /mnt/data/asr-finetuning/evaluation/benchmarking/data/v1/en_clean_read.json
    - /mnt/data/asr-finetuning/evaluation/benchmarking/data/v1/kn_clean_read.json
    sample_rate: 16000
    batch_size: 32
    shuffle: false
    num_workers: 16
    
[NeMo W 2026-01-22 21:56:22 modelPT:202] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).
    Test config : 
    manifest_filepath: null
    sample_rate: 16000
    batch_size: 16
    shuffle: false
    num_workers: 8
    pin_memory: true
    use_start_end_token: false
    
[NeMo I 2026-01-22 21:56:24 rnnt_models:226] Using RNNT Loss : warprnnt_numba
    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}
[NeMo I 2026-01-22 21:56:24 rnnt_models:226] Using RNNT Loss : warprnnt_numba
    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}
[NeMo W 2026-01-22 21:56:24 label_looping_base:123] No conditional node support for Cuda.
    Cuda graphs with while loops are disabled, decoding speed will be slower
    Reason: Driver supports cuda toolkit version 12.4, but the driver needs to support at least 12,6. Please update your cuda driver.
[NeMo I 2026-01-22 21:56:25 rnnt_models:226] Using RNNT Loss : warprnnt_numba
    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}
[NeMo W 2026-01-22 21:56:25 label_looping_base:123] No conditional node support for Cuda.
    Cuda graphs with while loops are disabled, decoding speed will be slower
    Reason: Driver supports cuda toolkit version 12.4, but the driver needs to support at least 12,6. Please update your cuda driver.
[NeMo I 2026-01-22 21:56:27 save_restore_connector:285] Model EncDecHybridRNNTCTCBPEModel was successfully restored from /mnt/data/asr-finetuning/training/models/kathbath_hybrid_h200_scaleup_p3_phase3_final.nemo.
 Loading KenLM: data/training/v3/kannada_4gram.arpa
Traceback (most recent call last):
  File "kenlm.pyx", line 139, in kenlm.Model.__init__
RuntimeError: util/file.cc:76 in int util::OpenReadOrThrow(const char*) threw ErrnoException because `-1 == (ret = open(name, 00))'.
No such file or directory while opening /mnt/data/asr-finetuning/data/training/v3/kannada_4gram.arpa

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/mnt/data/asr-finetuning/evaluation/benchmarking/run/run_benchmark_kenlm.py", line 163, in <module>
    run_eval(parse_args())
  File "/mnt/data/asr-finetuning/evaluation/benchmarking/run/run_benchmark_kenlm.py", line 74, in run_eval
    decoder = build_ctcdecoder(
              ^^^^^^^^^^^^^^^^^
  File "/mnt/data/asr-env/lib/python3.12/site-packages/pyctcdecode/decoder.py", line 907, in build_ctcdecoder
    kenlm_model = None if kenlm_model_path is None else kenlm.Model(kenlm_model_path)
                                                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "kenlm.pyx", line 142, in kenlm.Model.__init__
OSError: Cannot read model 'data/training/v3/kannada_4gram.arpa' (util/file.cc:76 in int util::OpenReadOrThrow(const char*) threw ErrnoException because `-1 == (ret = open(name, 00))'. No such file or directory while opening /mnt/data/asr-finetuning/data/training/v3/kannada_4gram.arpa)
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# # 1. Ensure you are in the project root
cd /mnt/data/asr-finetuning

# 2. Verify we have the source text (Should show file size)
ls -lh data/training/v3/all_text.txt

# 3. GENERATE THE ARPA FILE (This is the missing step)
# This uses the tool you built to read the text and write the model.
kenlm/build/bin/lmplz -o 4 < data/training/v3/all_text.txt > data/training/v3/kannada_4gram.arpa

# 4. Verify it was created (Should be ~100MB - 500MB)
ls -lh data/training/v3/kannada_4gram.arpa
ls: cannot access 'data/training/v3/all_text.txt': No such file or directory
bash: data/training/v3/all_text.txt: No such file or directory
ls: cannot access 'data/training/v3/kannada_4gram.arpa': No such file or directory
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# ls -lh data/training/v3/all_text.txt
ls: cannot access 'data/training/v3/all_text.txt': No such file or directory
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# # --- STEP 1: Extract Text from JSON Manifest ---
python3 << 'EOF'
import json
import os

manifest_file = "data/training/v3/master_manifest.json"
text_file = "data/training/v3/all_text.txt"

print(f" Reading: {manifest_file}")
count = 0

with open(text_file, 'w', encoding='utf-8') as out_f:
    with open(manifest_file, 'r', encoding='utf-8') as in_f:
        for line in in_f:
            data = json.loads(line)
            # Only extract if text exists and is valid
            if "text" in data and isinstance(data["text"], str) and data["text"].strip():
                out_f.write(data["text"].strip() + "\n")
                count += 1

print(f" Extracted {count} sentences to: {text_file}")
EOF

# --- STEP 2: Build the KenLM Model ---
print("  Building KenLM ARPA file...")
kenlm/build/bin/lmplz -o 4 < data/training/v3/all_text.txt > data/training/v3/kannada_4gram.arpa

# --- STEP 3: Run the Benchmark ---
print(" Running Benchmark...")
python evaluation/benchmarking/run/run_benchmark_kenlm.py \
  --model "training/models/kathbath_hybrid_h200_scaleup_p3_phase3_final.nemo" \
  --manifest "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/test_manifest.json" \
  --kenlm_model_path "data/training/v3/kannada_4gram.arpa" \
  --output_dir "models/results_kenlm_v1"
 Reading: data/training/v3/master_manifest.json
Traceback (most recent call last):
  File "<stdin>", line 10, in <module>
FileNotFoundError: [Errno 2] No such file or directory: 'data/training/v3/all_text.txt'
bash: syntax error near unexpected token `"  Building KenLM ARPA file..."'
bash: data/training/v3/all_text.txt: No such file or directory
bash: syntax error near unexpected token `" Running Benchmark..."'
fused_indices_to_multihot has reached end of life. Please migrate to a non-experimental function.
^CTraceback (most recent call last):
  File "/mnt/data/asr-finetuning/evaluation/benchmarking/run/run_benchmark_kenlm.py", line 9, in <module>
    from nemo.collections.asr.models import EncDecHybridRNNTCTCBPEModel
  File "/mnt/data/asr-env/lib/python3.12/site-packages/nemo/collections/asr/__init__.py", line 15, in <module>
    from nemo.collections.asr import data, losses, models, modules
  File "/mnt/data/asr-env/lib/python3.12/site-packages/nemo/collections/asr/losses/__init__.py", line 15, in <module>
    from nemo.collections.asr.losses.angularloss import AngularSoftmaxLoss
  File "/mnt/data/asr-env/lib/python3.12/site-packages/nemo/collections/asr/losses/angularloss.py", line 18, in <module>
    from nemo.core.classes import Loss, Typing, typecheck
  File "/mnt/data/asr-env/lib/python3.12/site-packages/nemo/core/__init__.py", line 16, in <module>
    from nemo.core.classes import *
  File "/mnt/data/asr-env/lib/python3.12/site-packages/nemo/core/classes/__init__.py", line 30, in <module>
    from nemo.core.classes.exportable import Exportable, ExportFormat
  File "/mnt/data/asr-env/lib/python3.12/site-packages/nemo/core/classes/exportable.py", line 24, in <module>
    from nemo.utils.export_utils import (
  File "/mnt/data/asr-env/lib/python3.12/site-packages/nemo/utils/export_utils.py", line 28, in <module>
    from nemo.utils.megatron_utils import ApexGuardDefaults
  File "/mnt/data/asr-env/lib/python3.12/site-packages/nemo/utils/megatron_utils.py", line 37, in <module>
    from megatron.core import parallel_state
  File "/mnt/data/asr-env/lib/python3.12/site-packages/megatron/core/__init__.py", line 22, in <module>
    from megatron.core.timers import Timers
  File "/mnt/data/asr-env/lib/python3.12/site-packages/megatron/core/timers.py", line 12, in <module>
    import wandb
  File "/mnt/data/asr-env/lib/python3.12/site-packages/wandb/__init__.py", line 22, in <module>
    from wandb.sdk.lib import wb_logging as _wb_logging
  File "/mnt/data/asr-env/lib/python3.12/site-packages/wandb/sdk/__init__.py", line 24, in <module>
    from . import wandb_helper as helper
  File "/mnt/data/asr-env/lib/python3.12/site-packages/wandb/sdk/wandb_helper.py", line 6, in <module>
    from .lib import config_util
  File "/mnt/data/asr-env/lib/python3.12/site-packages/wandb/sdk/lib/config_util.py", line 8, in <module>
    from wandb.util import load_yaml
  File "/mnt/data/asr-env/lib/python3.12/site-packages/wandb/util.py", line 59, in <module>
Traceback (most recent call last):
  File "/mnt/data/asr-env/lib/python3.12/site-packages/torch/_inductor/compile_worker/__main__.py", line 7, in <module>
    from wandb.sdk.lib import filesystem, runid
  File "/mnt/data/asr-env/lib/python3.12/site-packages/wandb/sdk/lib/filesystem.py", line 18, in <module>
    from torch._inductor.async_compile import pre_fork_setup
  File "/mnt/data/asr-env/lib/python3.12/site-packages/torch/__init__.py", line 2016, in <module>
    from torch import _VF as _VF, functional as functional  # usort: skip
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/data/asr-env/lib/python3.12/site-packages/torch/functional.py", line 7, in <module>
    import torch.nn.functional as F
  File "/mnt/data/asr-env/lib/python3.12/site-packages/torch/nn/__init__.py", line 9, in <module>
    from wandb.sdk.wandb_settings import Settings
  File "/mnt/data/asr-env/lib/python3.12/site-packages/wandb/sdk/wandb_settings.py", line 27, in <module>
    from wandb._pydantic import (
  File "/mnt/data/asr-env/lib/python3.12/site-packages/wandb/_pydantic/__init__.py", line 27, in <module>
    from torch.nn import (
  File "/mnt/data/asr-env/lib/python3.12/site-packages/torch/nn/parallel/__init__.py", line 4, in <module>
    from .base import CompatBaseModel, GQLBase, GQLInput, GQLResult, JsonableModel
  File "/mnt/data/asr-env/lib/python3.12/site-packages/wandb/_pydantic/base.py", line 52, in <module>
    class CompatBaseModel(PydanticCompatMixin, BaseModel):
  File "/mnt/data/asr-env/lib/python3.12/site-packages/pydantic/_internal/_model_construction.py", line 255, in __new__
    complete_model_class(
  File "/mnt/data/asr-env/lib/python3.12/site-packages/pydantic/_internal/_model_construction.py", line 671, in complete_model_class
    from torch.nn.parallel.data_parallel import data_parallel, DataParallel
  File "/mnt/data/asr-env/lib/python3.12/site-packages/torch/nn/parallel/data_parallel.py", line 17, in <module>
    cls.__pydantic_validator__ = create_schema_validator(
    from torch.nn.parallel.scatter_gather import gather, scatter_kwargs
                                 ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/data/asr-env/lib/python3.12/site-packages/pydantic/plugin/_schema_validator.py", line 39, in create_schema_validator
  File "/mnt/data/asr-env/lib/python3.12/site-packages/torch/nn/parallel/scatter_gather.py", line 6, in <module>
    from torch.nn.parallel._functions import Gather, Scatter
    plugins = get_plugins()
  File "<frozen importlib._bootstrap>", line 1357, in _find_and_load
              ^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 418, in __enter__
  File "/mnt/data/asr-env/lib/python3.12/site-packages/pydantic/plugin/_loader.py", line 40, in get_plugins
  File "<frozen importlib._bootstrap>", line 311, in acquire
  File "<frozen importlib._bootstrap>", line 170, in __enter__
  File "<frozen importlib._bootstrap>", line 132, in setdefault
  File "<frozen importlib._bootstrap>", line 74, in __new__
KeyboardInterrupt
    for entry_point in dist.entry_points:
                       ^^^^^^^^^^^^^^^^^
  File "/mnt/data/asr-env/lib/python3.12/site-packages/importlib_metadata/__init__.py", line 567, in entry_points
    return EntryPoints._from_text_for(self.read_text('entry_points.txt'), self)
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/data/asr-env/lib/python3.12/site-packages/importlib_metadata/__init__.py", line 1014, in read_text
    return self._path.joinpath(filename).read_text(encoding='utf-8')
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/pathlib.py", line 1029, in read_text
    with self.open(mode='r', encoding=encoding, errors=errors) as f:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/pathlib.py", line 1015, in open
    return io.open(self, mode, buffering, encoding, errors, newline)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen codecs>", line 309, in __init__
KeyboardInterrupt
^C
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# c
c: command not found
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# # --- STEP 1: Extract Text from JSON Manifest ---
python3 << 'EOF'
import json
import os

manifest_file = "data/training/v3/master_manifest.json"
text_file = "data/training/v3/all_text.txt"

print(f" Reading: {manifest_file}")
count = 0

with open(text_file, 'w', encoding='utf-8') as out_f:
    with open(manifest_file, 'r', encoding='utf-8') as in_f:
        for line in in_f:
            data = json.loads(line)
            # Only extract if text exists and is valid
            if "text" in data and isinstance(data["text"], str) and data["text"].strip():
                out_f.write(data["text"].strip() + "\n")
                count += 1

print(f" Extracted {count} sentences to: {text_file}")
EOF

# --- STEP 2: Build the KenLM Model ---
print("  Building KenLM ARPA file...")
kenlm/build/bin/lmplz -o 4 < data/training/v3/all_text.txt > data/training/v3/kannada_4gram.arpa

# --- STEP 3: Run the Benchmark ---
print(" Running Benchmark...")
python evaluation/benchmarking/run/run_benchmark_kenlm.py \
  --model "training/models/kathbath_hybrid_h200_scaleup_p3_phase3_final.nemo" \
  --manifest "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/test_manifest.json" \
  --kenlm_model_path "data/training/v3/kannada_4gram.arpa" \
  --output_dir "models/results_kenlm_v1"
 Reading: data/training/v3/master_manifest.json
Traceback (most recent call last):
  File "<stdin>", line 10, in <module>
FileNotFoundError: [Errno 2] No such file or directory: 'data/training/v3/all_text.txt'
bash: syntax error near unexpected token `"  Building KenLM ARPA file..."'
bash: data/training/v3/all_text.txt: No such file or directory
bash: syntax error near unexpected token `" Running Benchmark..."'
fused_indices_to_multihot has reached end of life. Please migrate to a non-experimental function.
OneLogger: Setting error_handling_strategy to DISABLE_QUIETLY_AND_REPORT_METRIC_ERROR for rank (rank=0) with OneLogger disabled. To override: explicitly set error_handling_strategy parameter.
No exporters were provided. This means that no telemetry data will be collected.
 Device: cuda
 Loading Model: training/models/kathbath_hybrid_h200_scaleup_p3_phase3_final.nemo
[NeMo I 2026-01-22 22:00:14 mixins:208] _setup_tokenizer: detected an aggregate tokenizer
[NeMo I 2026-01-22 22:00:14 mixins:347] Tokenizer SentencePieceTokenizer initialized with 1024 tokens
[NeMo I 2026-01-22 22:00:14 mixins:347] Tokenizer SentencePieceTokenizer initialized with 3000 tokens
[NeMo I 2026-01-22 22:00:14 aggregate_tokenizer:73] Aggregate vocab size: 4024
[NeMo W 2026-01-22 22:00:18 modelPT:188] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.
    Train config : 
    manifest_filepath: data/training/v2/master_manifest.json
    sample_rate: 16000
    batch_size: 32
    shuffle: true
    num_workers: 16
    pin_memory: true
    use_start_end_token: false
    min_duration: 1.5
    max_duration: 40.0
    prefetch_factor: 4
    
[NeMo W 2026-01-22 22:00:18 modelPT:195] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). 
    Validation config : 
    manifest_filepath:
    - /mnt/data/asr-finetuning/evaluation/benchmarking/data/v1/en_clean_read.json
    - /mnt/data/asr-finetuning/evaluation/benchmarking/data/v1/kn_clean_read.json
    sample_rate: 16000
    batch_size: 32
    shuffle: false
    num_workers: 16
    
[NeMo W 2026-01-22 22:00:18 modelPT:202] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).
    Test config : 
    manifest_filepath: null
    sample_rate: 16000
    batch_size: 16
    shuffle: false
    num_workers: 8
    pin_memory: true
    use_start_end_token: false
    
[NeMo I 2026-01-22 22:00:20 rnnt_models:226] Using RNNT Loss : warprnnt_numba
    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}
[NeMo I 2026-01-22 22:00:20 rnnt_models:226] Using RNNT Loss : warprnnt_numba
    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}
[NeMo W 2026-01-22 22:00:20 label_looping_base:123] No conditional node support for Cuda.
    Cuda graphs with while loops are disabled, decoding speed will be slower
    Reason: Driver supports cuda toolkit version 12.4, but the driver needs to support at least 12,6. Please update your cuda driver.
[NeMo I 2026-01-22 22:00:20 rnnt_models:226] Using RNNT Loss : warprnnt_numba
    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}
[NeMo W 2026-01-22 22:00:20 label_looping_base:123] No conditional node support for Cuda.
    Cuda graphs with while loops are disabled, decoding speed will be slower
    Reason: Driver supports cuda toolkit version 12.4, but the driver needs to support at least 12,6. Please update your cuda driver.
[NeMo I 2026-01-22 22:00:22 save_restore_connector:285] Model EncDecHybridRNNTCTCBPEModel was successfully restored from /mnt/data/asr-finetuning/training/models/kathbath_hybrid_h200_scaleup_p3_phase3_final.nemo.
 Loading KenLM: data/training/v3/kannada_4gram.arpa
Traceback (most recent call last):
  File "kenlm.pyx", line 139, in kenlm.Model.__init__
RuntimeError: util/file.cc:76 in int util::OpenReadOrThrow(const char*) threw ErrnoException because `-1 == (ret = open(name, 00))'.
No such file or directory while opening /mnt/data/asr-finetuning/data/training/v3/kannada_4gram.arpa

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/mnt/data/asr-finetuning/evaluation/benchmarking/run/run_benchmark_kenlm.py", line 163, in <module>
    run_eval(parse_args())
  File "/mnt/data/asr-finetuning/evaluation/benchmarking/run/run_benchmark_kenlm.py", line 74, in run_eval
    decoder = build_ctcdecoder(
              ^^^^^^^^^^^^^^^^^
  File "/mnt/data/asr-env/lib/python3.12/site-packages/pyctcdecode/decoder.py", line 907, in build_ctcdecoder
    kenlm_model = None if kenlm_model_path is None else kenlm.Model(kenlm_model_path)
                                                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "kenlm.pyx", line 142, in kenlm.Model.__init__
OSError: Cannot read model 'data/training/v3/kannada_4gram.arpa' (util/file.cc:76 in int util::OpenReadOrThrow(const char*) threw ErrnoException because `-1 == (ret = open(name, 00))'. No such file or directory while opening /mnt/data/asr-finetuning/data/training/v3/kannada_4gram.arpa)
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# ls training/data/v2.1
ls: cannot access 'training/data/v2.1': No such file or directory
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# ls training/data
ls: cannot access 'training/data': No such file or directory
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# ls training
build_tokenizer_4k.py  create_vocab_txt.py  experiments                   fix_validation_manifests.py  logs    tokenizers  train.py
build_tokenizer.py     data_prep            extract_english_tokenizer.py  generate_vocab.py            models  training
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# ls training/training
tokenizers
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# ls training/data_prep
IISC_Mile.py  shrutilipi.py  vaani.py  verify_dataset.py
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# find /mnt/data/asr-finetuning -name "master_manifest.json"
/mnt/data/asr-finetuning/data/training/v1/master_manifest.json
/mnt/data/asr-finetuning/data/training/v2.1/master_manifest.json
/mnt/data/asr-finetuning/data/training/v2/master_manifest.json
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# # Stop if any command fails
set -e

# --- CONFIGURATION ---
MANIFEST="data/training/v2.1/master_manifest.json"
TEXT_FILE="data/training/v2.1/all_text.txt"
ARPA_FILE="data/training/v2.1/kannada_4gram.arpa"

echo " Found Manifest: $MANIFEST"

# 1. Extract Text (if missing)
if [ ! -f "$TEXT_FILE" ]; then
    echo " Extracting text from manifest..."
    python3 -c "
import json
with open('$TEXT_FILE', 'w', encoding='utf-8') as out_f:
    with open('$MANIFEST', 'r', encoding='utf-8') as in_f:
        for line in in_f:
            try:
                data = json.loads(line)
                if 'text' in data and data['text'].strip():
                    out_f.write(data['text'].strip() + '\n')
            except: pass
"
    echo " Text extracted to $TEXT_FILE"
else
    echo " Text file already exists."
fi

# 2. Train KenLM (if missing)
if [ ! -f "$ARPA_FILE" ]; then
    echo "  Building KenLM ARPA file (this takes ~30s)..."
    kenlm/build/bin/lmplz -o 4 < "$TEXT_FILE" > "$ARPA_FILE"
    echo " ARPA file created at $ARPA_FILE"
else
    echo " ARPA file already exists."
fi

# 3. Run Benchmark
echo " Running Benchmark with KenLM..."
python evaluation/benchmarking/run/run_benchmark_kenlm.py \
  --model "training/models/kathbath_hybrid_h200_scaleup_p3_phase3_final.nemo" \
  --manifest "evaluation/benchmarking/curation/test_data/Kathbath/test_manifest.json" \
  --kenlm_model_path "$ARPA_FILE" \
  --output_dir "models/results_kenlm_v1"

# Turn off strict mode
set +e
 Found Manifest: data/training/v2.1/master_manifest.json
 Text file already exists.
 ARPA file already exists.
 Running Benchmark with KenLM...
fused_indices_to_multihot has reached end of life. Please migrate to a non-experimental function.
OneLogger: Setting error_handling_strategy to DISABLE_QUIETLY_AND_REPORT_METRIC_ERROR for rank (rank=0) with OneLogger disabled. To override: explicitly set error_handling_strategy parameter.
No exporters were provided. This means that no telemetry data will be collected.
^Z
[1]+  Stopped                 python evaluation/benchmarking/run/run_benchmark_kenlm.py --model "training/models/kathbath_hybrid_h200_scaleup_p3_phase3_final.nemo" --manifest "evaluation/benchmarking/curation/test_data/Kathbath/test_manifest.json" --kenlm_model_path "$ARPA_FILE" --output_dir "models/results_kenlm_v1"
(base) neurodx@h200-nvl-2x:~$ python evaluation/benchmarking/run/run_benchmark_kenlm.py \
  --model "training/models/kathbath_hybrid_h200_scaleup_p3_phase3_final.nemo" \
  --manifest "evaluation/benchmarking/curation/test_data/Kathbath/test_manifest.json" \
  --kenlm_model_path "data/training/v2.1/kannada_4gram.arpa" \
  --output_dir "models/results_kenlm_v1"
python: can't open file '/home/neurodx/evaluation/benchmarking/run/run_benchmark_kenlm.py': [Errno 2] No such file or directory
(base) neurodx@h200-nvl-2x:~$ sudo su
root@h200-nvl-2x:/home/neurodx# cd /mnt/data
source asr-env/bin/activate 
cd asr-finetuning
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# python evaluation/benchmarking/run/run_benchmark_kenlm.py \
  --model "training/models/kathbath_hybrid_h200_scaleup_p3_phase3_final.nemo" \
  --manifest "evaluation/benchmarking/curation/test_data/Kathbath/test_manifest.json" \
  --kenlm_model_path "data/training/v2.1/kannada_4gram.arpa" \
  --output_dir "models/results_kenlm_v1"
fused_indices_to_multihot has reached end of life. Please migrate to a non-experimental function.
OneLogger: Setting error_handling_strategy to DISABLE_QUIETLY_AND_REPORT_METRIC_ERROR for rank (rank=0) with OneLogger disabled. To override: explicitly set error_handling_strategy parameter.
No exporters were provided. This means that no telemetry data will be collected.
 Device: cuda
 Loading Model: training/models/kathbath_hybrid_h200_scaleup_p3_phase3_final.nemo
[NeMo I 2026-01-22 22:07:03 mixins:208] _setup_tokenizer: detected an aggregate tokenizer
[NeMo I 2026-01-22 22:07:03 mixins:347] Tokenizer SentencePieceTokenizer initialized with 1024 tokens
[NeMo I 2026-01-22 22:07:03 mixins:347] Tokenizer SentencePieceTokenizer initialized with 3000 tokens
[NeMo I 2026-01-22 22:07:03 aggregate_tokenizer:73] Aggregate vocab size: 4024
[NeMo W 2026-01-22 22:07:07 modelPT:188] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.
    Train config : 
    manifest_filepath: data/training/v2/master_manifest.json
    sample_rate: 16000
    batch_size: 32
    shuffle: true
    num_workers: 16
    pin_memory: true
    use_start_end_token: false
    min_duration: 1.5
    max_duration: 40.0
    prefetch_factor: 4
    
[NeMo W 2026-01-22 22:07:07 modelPT:195] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). 
    Validation config : 
    manifest_filepath:
    - /mnt/data/asr-finetuning/evaluation/benchmarking/data/v1/en_clean_read.json
    - /mnt/data/asr-finetuning/evaluation/benchmarking/data/v1/kn_clean_read.json
    sample_rate: 16000
    batch_size: 32
    shuffle: false
    num_workers: 16
    
[NeMo W 2026-01-22 22:07:07 modelPT:202] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).
    Test config : 
    manifest_filepath: null
    sample_rate: 16000
    batch_size: 16
    shuffle: false
    num_workers: 8
    pin_memory: true
    use_start_end_token: false
    
[NeMo I 2026-01-22 22:07:09 rnnt_models:226] Using RNNT Loss : warprnnt_numba
    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}
[NeMo I 2026-01-22 22:07:09 rnnt_models:226] Using RNNT Loss : warprnnt_numba
    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}
[NeMo W 2026-01-22 22:07:09 label_looping_base:123] No conditional node support for Cuda.
    Cuda graphs with while loops are disabled, decoding speed will be slower
    Reason: Driver supports cuda toolkit version 12.4, but the driver needs to support at least 12,6. Please update your cuda driver.
[NeMo I 2026-01-22 22:07:10 rnnt_models:226] Using RNNT Loss : warprnnt_numba
    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}
[NeMo W 2026-01-22 22:07:10 label_looping_base:123] No conditional node support for Cuda.
    Cuda graphs with while loops are disabled, decoding speed will be slower
    Reason: Driver supports cuda toolkit version 12.4, but the driver needs to support at least 12,6. Please update your cuda driver.
[NeMo I 2026-01-22 22:07:11 save_restore_connector:285] Model EncDecHybridRNNTCTCBPEModel was successfully restored from /mnt/data/asr-finetuning/training/models/kathbath_hybrid_h200_scaleup_p3_phase3_final.nemo.
 Loading KenLM: data/training/v2.1/kannada_4gram.arpa
Loading the LM will be faster if you build a binary file.
Reading /mnt/data/asr-finetuning/data/training/v2.1/kannada_4gram.arpa
----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100
****************************************************************************************************
Traceback (most recent call last):
  File "/mnt/data/asr-finetuning/evaluation/benchmarking/run/run_benchmark_kenlm.py", line 163, in <module>
    run_eval(parse_args())
  File "/mnt/data/asr-finetuning/evaluation/benchmarking/run/run_benchmark_kenlm.py", line 74, in run_eval
    decoder = build_ctcdecoder(
              ^^^^^^^^^^^^^^^^^
  File "/mnt/data/asr-env/lib/python3.12/site-packages/pyctcdecode/decoder.py", line 918, in build_ctcdecoder
    alphabet = Alphabet.build_alphabet(labels)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/data/asr-env/lib/python3.12/site-packages/pyctcdecode/alphabet.py", line 143, in build_alphabet
    _verify_alphabet(labels, is_bpe)
  File "/mnt/data/asr-env/lib/python3.12/site-packages/pyctcdecode/alphabet.py", line 117, in _verify_alphabet
    raise ValueError("Alphabet contains duplicate entries, this is not allowed.")
ValueError: Alphabet contains duplicate entries, this is not allowed.
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# cat << 'EOF' > evaluation/benchmarking/run/run_benchmark_kenlm.py
import argparse
import json
import torch
import os
import jiwer
from tqdm import tqdm
import librosa
import numpy as np
from nemo.collections.asr.models import EncDecHybridRNNTCTCBPEModel

# --- 1. IMPORT MODERN DECODER ---
try:
    from pyctcdecode import build_ctcdecoder
except ImportError:
    print(" Error: pyctcdecode not found. Run: pip install pyctcdecode")
    exit(1)

# --- 2. VOCABULARY EXTRACTOR (WITH DEDUPLICATION FIX) ---
def get_vocab(model):
    """Safely extracts vocabulary and renames duplicates to satisfy pyctcdecode"""
    vocab_raw = []
    
    # A. Extract raw list based on model type
    if hasattr(model, 'tokenizer'):
        vocab_size = model.tokenizer.vocab_size
        for i in range(vocab_size):
            if hasattr(model.tokenizer, 'tokenizer') and hasattr(model.tokenizer.tokenizer, 'id_to_piece'):
                vocab_raw.append(model.tokenizer.tokenizer.id_to_piece(i))
            else:
                vocab_raw.append(model.tokenizer.ids_to_text([i]))
    elif hasattr(model.decoder, 'vocabulary'):
        vocab_raw = model.decoder.vocabulary
    elif hasattr(model, 'cfg') and 'labels' in model.cfg:
        vocab_raw = model.cfg.labels
    else:
        raise AttributeError("Could not find vocabulary.")

    # B. Deduplicate (Fix for 'Alphabet contains duplicate entries' error)
    vocab_final = []
    seen_counts = {}
    
    for token in vocab_raw:
        if token in seen_counts:
            seen_counts[token] += 1
            # Rename duplicate to unique string (e.g., <unk> -> <unk>_dup1)
            new_token = f"{token}_dup{seen_counts[token]}"
            vocab_final.append(new_token)
        else:
            seen_counts[token] = 0
            vocab_final.append(token)
            
    return vocab_final

def parse_args():
    parser = argparse.ArgumentParser(description="KenLM Beam Search Benchmark")
    parser.add_argument("--model", type=str, required=True)
    parser.add_argument("--manifest", type=str, required=True)
EOF run_eval(parse_args())r:.2f} | CER: {cer:.2f}").txt"), "w") as f:dth)ype=torch.long)
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# python evaluation/benchmarking/run/run_benchmark_kenlm.py \
  --model "training/models/kathbath_hybrid_h200_scaleup_p3_phase3_final.nemo" \
  --manifest "evaluation/benchmarking/curation/test_data/Kathbath/test_manifest.json" \
  --kenlm_model_path "data/training/v2.1/kannada_4gram.arpa" \
  --output_dir "models/results_kenlm_v1"
fused_indices_to_multihot has reached end of life. Please migrate to a non-experimental function.
OneLogger: Setting error_handling_strategy to DISABLE_QUIETLY_AND_REPORT_METRIC_ERROR for rank (rank=0) with OneLogger disabled. To override: explicitly set error_handling_strategy parameter.
No exporters were provided. This means that no telemetry data will be collected.
 Device: cuda
 Loading Model: training/models/kathbath_hybrid_h200_scaleup_p3_phase3_final.nemo
[NeMo I 2026-01-22 22:08:46 mixins:208] _setup_tokenizer: detected an aggregate tokenizer
[NeMo I 2026-01-22 22:08:46 mixins:347] Tokenizer SentencePieceTokenizer initialized with 1024 tokens
[NeMo I 2026-01-22 22:08:46 mixins:347] Tokenizer SentencePieceTokenizer initialized with 3000 tokens
[NeMo I 2026-01-22 22:08:46 aggregate_tokenizer:73] Aggregate vocab size: 4024
[NeMo W 2026-01-22 22:08:51 modelPT:188] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.
    Train config : 
    manifest_filepath: data/training/v2/master_manifest.json
    sample_rate: 16000
    batch_size: 32
    shuffle: true
    num_workers: 16
    pin_memory: true
    use_start_end_token: false
    min_duration: 1.5
    max_duration: 40.0
    prefetch_factor: 4
    
[NeMo W 2026-01-22 22:08:51 modelPT:195] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). 
    Validation config : 
    manifest_filepath:
    - /mnt/data/asr-finetuning/evaluation/benchmarking/data/v1/en_clean_read.json
    - /mnt/data/asr-finetuning/evaluation/benchmarking/data/v1/kn_clean_read.json
    sample_rate: 16000
    batch_size: 32
    shuffle: false
    num_workers: 16
    
[NeMo W 2026-01-22 22:08:51 modelPT:202] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).
    Test config : 
    manifest_filepath: null
    sample_rate: 16000
    batch_size: 16
    shuffle: false
    num_workers: 8
    pin_memory: true
    use_start_end_token: false
    
[NeMo I 2026-01-22 22:08:52 rnnt_models:226] Using RNNT Loss : warprnnt_numba
    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}
[NeMo I 2026-01-22 22:08:52 rnnt_models:226] Using RNNT Loss : warprnnt_numba
    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}
[NeMo W 2026-01-22 22:08:53 label_looping_base:123] No conditional node support for Cuda.
    Cuda graphs with while loops are disabled, decoding speed will be slower
    Reason: Driver supports cuda toolkit version 12.4, but the driver needs to support at least 12,6. Please update your cuda driver.
[NeMo I 2026-01-22 22:08:53 rnnt_models:226] Using RNNT Loss : warprnnt_numba
    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}
[NeMo W 2026-01-22 22:08:53 label_looping_base:123] No conditional node support for Cuda.
    Cuda graphs with while loops are disabled, decoding speed will be slower
    Reason: Driver supports cuda toolkit version 12.4, but the driver needs to support at least 12,6. Please update your cuda driver.
[NeMo I 2026-01-22 22:08:54 save_restore_connector:285] Model EncDecHybridRNNTCTCBPEModel was successfully restored from /mnt/data/asr-finetuning/training/models/kathbath_hybrid_h200_scaleup_p3_phase3_final.nemo.
 Loading KenLM: data/training/v2.1/kannada_4gram.arpa
    Extracted Vocabulary Size: 4024 (Duplicates renamed)
Loading the LM will be faster if you build a binary file.
Reading /mnt/data/asr-finetuning/data/training/v2.1/kannada_4gram.arpa
----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100
****************************************************************************************************
Found entries of length > 1 in alphabet. This is unusual unless style is BPE, but the alphabet was not recognized as BPE type. Is this correct?
Unigrams and labels don't seem to agree.
 Processing 2062 files...
100%|| 129/129 [03:28<00:00,  1.62s/it]
========================================
 RESULTS (KenLM via PyCTCDecode)
WER: 73.63% | CER: 43.74%
========================================
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# cat << 'EOF' > evaluation/benchmarking/run/run_benchmark_kenlm.py
import argparse
import json
import torch
import os
import jiwer
from tqdm import tqdm
import librosa
import numpy as np
from nemo.collections.asr.models import EncDecHybridRNNTCTCBPEModel

# --- 1. IMPORT DECODER ---
try:
    from pyctcdecode import build_ctcdecoder
except ImportError:
    print(" Error: pyctcdecode not found. Run: pip install pyctcdecode")
    exit(1)

# --- 2. VOCABULARY SANITIZER (THE FIX) ---
def get_clean_vocab(model):
    """
    Extracts vocab and fixes the 'Alien vs Predator' mismatch.
    1. Replaces SentencePiece '_' (U+2581) with real space.
    2. Deduplicates tokens to stop pyctcdecode from crashing.
    """
    vocab_raw = []
    
    # A. Extract Raw Tokens
    if hasattr(model, 'tokenizer'):
        vocab_size = model.tokenizer.vocab_size
        for i in range(vocab_size):
            if hasattr(model.tokenizer, 'tokenizer') and hasattr(model.tokenizer.tokenizer, 'id_to_piece'):
                # Get raw piece (e.g. " hello")
                piece = model.tokenizer.tokenizer.id_to_piece(i)
                vocab_raw.append(piece)
            else:
                vocab_raw.append(model.tokenizer.ids_to_text([i]))
    elif hasattr(model.decoder, 'vocabulary'):
        vocab_raw = model.decoder.vocabulary
    else:
        raise AttributeError("Could not find vocabulary.")

    # B. Sanitize for PyCTCDecode
    vocab_final = []
    seen_tokens = set()
    
    for token in vocab_raw:
        # Fix 1: Handle SentencePiece Underscore (U+2581) -> Space
        # This tells the decoder that "_" is the start of a word
        clean_token = token.replace("\u2581", " ")
        
        # Fix 2: Handle special tokens like <unk> that might duplicate
        # If we see a duplicate, we must rename it or pyctcdecode crashes.
        if clean_token in seen_tokens:
            # If it's a duplicate, we ignore it (treat as blank/null for decoding)
            # or append a suffix if it's crucial. Usually safe to ignore duplicates in tail.
            vocab_final.append(f"<{token}>") # obscure it so it doesn't conflict
        else:
EOF run_eval(parse_args())r:.2f} | CER: {cer:.2f}").txt"), "w") as f:dth)ype=torch.long)
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# python evaluation/benchmarking/run/run_benchmark_kenlm.py \
  --model "training/models/kathbath_hybrid_h200_scaleup_p3_phase3_final.nemo" \
  --manifest "evaluation/benchmarking/curation/test_data/Kathbath/test_manifest.json" \
  --kenlm_model_path "data/training/v2.1/kannada_4gram.arpa" \
  --output_dir "models/results_kenlm_v1"
fused_indices_to_multihot has reached end of life. Please migrate to a non-experimental function.
OneLogger: Setting error_handling_strategy to DISABLE_QUIETLY_AND_REPORT_METRIC_ERROR for rank (rank=0) with OneLogger disabled. To override: explicitly set error_handling_strategy parameter.
No exporters were provided. This means that no telemetry data will be collected.
 Loading Model...
[NeMo I 2026-01-22 22:15:49 mixins:208] _setup_tokenizer: detected an aggregate tokenizer
[NeMo I 2026-01-22 22:15:49 mixins:347] Tokenizer SentencePieceTokenizer initialized with 1024 tokens
[NeMo I 2026-01-22 22:15:49 mixins:347] Tokenizer SentencePieceTokenizer initialized with 3000 tokens
[NeMo I 2026-01-22 22:15:49 aggregate_tokenizer:73] Aggregate vocab size: 4024
[NeMo W 2026-01-22 22:15:53 modelPT:188] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.
    Train config : 
    manifest_filepath: data/training/v2/master_manifest.json
    sample_rate: 16000
    batch_size: 32
    shuffle: true
    num_workers: 16
    pin_memory: true
    use_start_end_token: false
    min_duration: 1.5
    max_duration: 40.0
    prefetch_factor: 4
    
[NeMo W 2026-01-22 22:15:53 modelPT:195] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). 
    Validation config : 
    manifest_filepath:
    - /mnt/data/asr-finetuning/evaluation/benchmarking/data/v1/en_clean_read.json
    - /mnt/data/asr-finetuning/evaluation/benchmarking/data/v1/kn_clean_read.json
    sample_rate: 16000
    batch_size: 32
    shuffle: false
    num_workers: 16
    
[NeMo W 2026-01-22 22:15:53 modelPT:202] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).
    Test config : 
    manifest_filepath: null
    sample_rate: 16000
    batch_size: 16
    shuffle: false
    num_workers: 8
    pin_memory: true
    use_start_end_token: false
    
[NeMo I 2026-01-22 22:15:55 rnnt_models:226] Using RNNT Loss : warprnnt_numba
    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}
[NeMo I 2026-01-22 22:15:55 rnnt_models:226] Using RNNT Loss : warprnnt_numba
    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}
[NeMo W 2026-01-22 22:15:55 label_looping_base:123] No conditional node support for Cuda.
    Cuda graphs with while loops are disabled, decoding speed will be slower
    Reason: Driver supports cuda toolkit version 12.4, but the driver needs to support at least 12,6. Please update your cuda driver.
[NeMo I 2026-01-22 22:15:56 rnnt_models:226] Using RNNT Loss : warprnnt_numba
    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}
[NeMo W 2026-01-22 22:15:56 label_looping_base:123] No conditional node support for Cuda.
    Cuda graphs with while loops are disabled, decoding speed will be slower
    Reason: Driver supports cuda toolkit version 12.4, but the driver needs to support at least 12,6. Please update your cuda driver.
[NeMo I 2026-01-22 22:15:57 save_restore_connector:285] Model EncDecHybridRNNTCTCBPEModel was successfully restored from /mnt/data/asr-finetuning/training/models/kathbath_hybrid_h200_scaleup_p3_phase3_final.nemo.
 Loading KenLM & Cleaning Vocab...
    Vocab Size: 4024 (Sanitized)
Loading the LM will be faster if you build a binary file.
Reading /mnt/data/asr-finetuning/data/training/v2.1/kannada_4gram.arpa
----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100
****************************************************************************************************
Found entries of length > 1 in alphabet. This is unusual unless style is BPE, but the alphabet was not recognized as BPE type. Is this correct?
Unigrams and labels don't seem to agree.
 Processing 2062 files...
100%|| 129/129 [03:19<00:00,  1.54s/it]
========================================
 RESULTS (KenLM via PyCTCDecode)
WER: 73.63% | CER: 43.73%
========================================
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# cat << 'EOF' > evaluation/benchmarking/run/run_benchmark_kenlm.py
import argparse
import json
import torch
import os
import jiwer
from tqdm import tqdm
import librosa
import numpy as np
from nemo.collections.asr.models import EncDecHybridRNNTCTCBPEModel

# --- 1. IMPORT DECODER ---
try:
    from pyctcdecode import build_ctcdecoder
except ImportError:
    print(" Error: pyctcdecode not found. Run: pip install pyctcdecode")
    exit(1)

# --- 2. RAW VOCAB EXTRACTOR (PRESERVES BPE MARKERS) ---
def get_raw_vocab(model):
    """
    Extracts RAW BPE tokens (keeping the \u2581 marker).
    Renames duplicates to avoid pyctcdecode crashes.
    """
    vocab_raw = []
    
    # A. Extract Raw Pieces (CRITICAL: Must use id_to_piece to keep '_')
    if hasattr(model, 'tokenizer'):
        vocab_size = model.tokenizer.vocab_size
        for i in range(vocab_size):
            if hasattr(model.tokenizer, 'tokenizer') and hasattr(model.tokenizer.tokenizer, 'id_to_piece'):
                # This returns the raw BPE token like " k" (with U+2581)
                vocab_raw.append(model.tokenizer.tokenizer.id_to_piece(i))
            else:
                # Fallback
                vocab_raw.append(model.tokenizer.ids_to_text([i]))
    elif hasattr(model.decoder, 'vocabulary'):
        vocab_raw = model.decoder.vocabulary
    else:
        raise AttributeError("Could not find vocabulary.")

    # B. Deduplicate (Rename duplicates, don't remove them)
    vocab_final = []
    seen_counts = {}
    
    for token in vocab_raw:
        # Check for duplicates
        if token in seen_counts:
            seen_counts[token] += 1
            # Rename to something unique so pyctcdecode accepts it
            new_token = f"{token}_dup{seen_counts[token]}"
            vocab_final.append(new_token)
        else:
            seen_counts[token] = 0
            vocab_final.append(token)
            
    return vocab_final

EOF run_eval(parse_args())r:.2f} | CER: {cer:.2f}").txt"), "w") as f:, dtype=torch.long)ord completion
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# python evaluation/benchmarking/run/run_benchmark_kenlm.py \
  --model "training/models/kathbath_hybrid_h200_scaleup_p3_phase3_final.nemo" \
  --manifest "evaluation/benchmarking/curation/test_data/Kathbath/test_manifest.json" \
  --kenlm_model_path "data/training/v2.1/kannada_4gram.arpa" \
  --output_dir "models/results_kenlm_v1"
fused_indices_to_multihot has reached end of life. Please migrate to a non-experimental function.
OneLogger: Setting error_handling_strategy to DISABLE_QUIETLY_AND_REPORT_METRIC_ERROR for rank (rank=0) with OneLogger disabled. To override: explicitly set error_handling_strategy parameter.
No exporters were provided. This means that no telemetry data will be collected.
 Device: cuda
 Loading Model: training/models/kathbath_hybrid_h200_scaleup_p3_phase3_final.nemo
[NeMo I 2026-01-22 22:27:45 mixins:208] _setup_tokenizer: detected an aggregate tokenizer
[NeMo I 2026-01-22 22:27:45 mixins:347] Tokenizer SentencePieceTokenizer initialized with 1024 tokens
[NeMo I 2026-01-22 22:27:45 mixins:347] Tokenizer SentencePieceTokenizer initialized with 3000 tokens
[NeMo I 2026-01-22 22:27:45 aggregate_tokenizer:73] Aggregate vocab size: 4024
[NeMo W 2026-01-22 22:27:49 modelPT:188] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.
    Train config : 
    manifest_filepath: data/training/v2/master_manifest.json
    sample_rate: 16000
    batch_size: 32
    shuffle: true
    num_workers: 16
    pin_memory: true
    use_start_end_token: false
    min_duration: 1.5
    max_duration: 40.0
    prefetch_factor: 4
    
[NeMo W 2026-01-22 22:27:49 modelPT:195] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). 
    Validation config : 
    manifest_filepath:
    - /mnt/data/asr-finetuning/evaluation/benchmarking/data/v1/en_clean_read.json
    - /mnt/data/asr-finetuning/evaluation/benchmarking/data/v1/kn_clean_read.json
    sample_rate: 16000
    batch_size: 32
    shuffle: false
    num_workers: 16
    
[NeMo W 2026-01-22 22:27:49 modelPT:202] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).
    Test config : 
    manifest_filepath: null
    sample_rate: 16000
    batch_size: 16
    shuffle: false
    num_workers: 8
    pin_memory: true
    use_start_end_token: false
    
[NeMo I 2026-01-22 22:27:51 rnnt_models:226] Using RNNT Loss : warprnnt_numba
    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}
[NeMo I 2026-01-22 22:27:51 rnnt_models:226] Using RNNT Loss : warprnnt_numba
    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}
[NeMo W 2026-01-22 22:27:51 label_looping_base:123] No conditional node support for Cuda.
    Cuda graphs with while loops are disabled, decoding speed will be slower
    Reason: Driver supports cuda toolkit version 12.4, but the driver needs to support at least 12,6. Please update your cuda driver.
[NeMo I 2026-01-22 22:27:52 rnnt_models:226] Using RNNT Loss : warprnnt_numba
    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}
[NeMo W 2026-01-22 22:27:52 label_looping_base:123] No conditional node support for Cuda.
    Cuda graphs with while loops are disabled, decoding speed will be slower
    Reason: Driver supports cuda toolkit version 12.4, but the driver needs to support at least 12,6. Please update your cuda driver.
[NeMo I 2026-01-22 22:27:53 save_restore_connector:285] Model EncDecHybridRNNTCTCBPEModel was successfully restored from /mnt/data/asr-finetuning/training/models/kathbath_hybrid_h200_scaleup_p3_phase3_final.nemo.
 Loading KenLM: data/training/v2.1/kannada_4gram.arpa
    Raw Vocab Size: 4024 (Duplicates renamed)
Loading the LM will be faster if you build a binary file.
Reading /mnt/data/asr-finetuning/data/training/v2.1/kannada_4gram.arpa
----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100
****************************************************************************************************
Found entries of length > 1 in alphabet. This is unusual unless style is BPE, but the alphabet was not recognized as BPE type. Is this correct?
Unigrams and labels don't seem to agree.
 Processing 515 files (1/4 Subset)...
100%|| 33/33 [00:45<00:00,  1.38s/it]
========================================
 RESULTS (1/4 Data Subset)
WER: 69.96% | CER: 40.24%
========================================
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# python3 << 'EOF'
import sys
import torch
import json
from nemo.collections.asr.models import EncDecHybridRNNTCTCBPEModel

# CONFIG
MODEL_PATH = "training/models/kathbath_hybrid_h200_scaleup_p3_phase3_final.nemo"
KENLM_PATH = "data/training/v2.1/kannada_4gram.arpa"
MANIFEST_PATH = "evaluation/benchmarking/curation/test_data/Kathbath/test_manifest.json"

print("="*60)
print(" DIAGNOSTIC: EAR (Model) vs BRAIN (KenLM)")
print("="*60)

# 1. INSPECT THE ACOUSTIC MODEL (The Ear)
print("\n LOADING ACOUSTIC MODEL...")
model = EncDecHybridRNNTCTCBPEModel.restore_from(MODEL_PATH)
tokenizer = model.tokenizer.tokenizer

print(f"\n Model Vocabulary Size: {model.tokenizer.vocab_size}")
print(" First 20 Tokens in Acoustic Model:")
for i in range(20):
    try:
        piece = tokenizer.id_to_piece(i)
        # Python repr() shows hidden characters like \u2581
        print(f"   ID {i}: {repr(piece)}") 
    except:
        pass

# 2. INSPECT THE KENLM (The Brain)
print(f"\n INSPECTING KENLM FILE: {KENLM_PATH}")
print(" First 20 Lines of ARPA file:")
try:
    with open(KENLM_PATH, 'r', encoding='utf-8') as f:
        for i, line in enumerate(f):
            if i > 20: break
            print(f"   {line.strip()}")
except Exception as e:
    print(f" Error reading ARPA: {e}")

# 3. TEST ONE SINGLE AUDIO
print("\n TESTING SINGLE INFERENCE (Greedy vs KenLM)")
# Get first file from manifest
with open(MANIFEST_PATH, 'r') as f:
    first_line = json.loads(f.readline())
    audio_path = first_line['audio_filepath']
    ref_text = first_line['text']

print(f"   Audio: {audio_path}")
print(f"   Ref:   {ref_text}")

# Run Greedy (What the model naturally sees)
# Note: NeMo's transcribe uses greedy by default
try:
    greedy_text = model.transcribe([audio_path])[0]
    print(f"\n    GREEDY OUTPUT (What the model hears):")
    print(f"   '{greedy_text}'")
EOFnt("\n" + "="*60)eedy failed: {e}")
fused_indices_to_multihot has reached end of life. Please migrate to a non-experimental function.
OneLogger: Setting error_handling_strategy to DISABLE_QUIETLY_AND_REPORT_METRIC_ERROR for rank (rank=0) with OneLogger disabled. To override: explicitly set error_handling_strategy parameter.
No exporters were provided. This means that no telemetry data will be collected.
============================================================
 DIAGNOSTIC: EAR (Model) vs BRAIN (KenLM)
============================================================

 LOADING ACOUSTIC MODEL...
[NeMo I 2026-01-22 22:33:33 mixins:208] _setup_tokenizer: detected an aggregate tokenizer
[NeMo I 2026-01-22 22:33:33 mixins:347] Tokenizer SentencePieceTokenizer initialized with 1024 tokens
[NeMo I 2026-01-22 22:33:34 mixins:347] Tokenizer SentencePieceTokenizer initialized with 3000 tokens
[NeMo I 2026-01-22 22:33:34 aggregate_tokenizer:73] Aggregate vocab size: 4024
[NeMo W 2026-01-22 22:33:38 modelPT:188] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.
    Train config : 
    manifest_filepath: data/training/v2/master_manifest.json
    sample_rate: 16000
    batch_size: 32
    shuffle: true
    num_workers: 16
    pin_memory: true
    use_start_end_token: false
    min_duration: 1.5
    max_duration: 40.0
    prefetch_factor: 4
    
[NeMo W 2026-01-22 22:33:38 modelPT:195] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). 
    Validation config : 
    manifest_filepath:
    - /mnt/data/asr-finetuning/evaluation/benchmarking/data/v1/en_clean_read.json
    - /mnt/data/asr-finetuning/evaluation/benchmarking/data/v1/kn_clean_read.json
    sample_rate: 16000
    batch_size: 32
    shuffle: false
    num_workers: 16
    
[NeMo W 2026-01-22 22:33:38 modelPT:202] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).
    Test config : 
    manifest_filepath: null
    sample_rate: 16000
    batch_size: 16
    shuffle: false
    num_workers: 8
    pin_memory: true
    use_start_end_token: false
    
[NeMo I 2026-01-22 22:33:40 rnnt_models:226] Using RNNT Loss : warprnnt_numba
    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}
[NeMo I 2026-01-22 22:33:40 rnnt_models:226] Using RNNT Loss : warprnnt_numba
    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}
[NeMo W 2026-01-22 22:33:40 label_looping_base:123] No conditional node support for Cuda.
    Cuda graphs with while loops are disabled, decoding speed will be slower
    Reason: Driver supports cuda toolkit version 12.4, but the driver needs to support at least 12,6. Please update your cuda driver.
[NeMo I 2026-01-22 22:33:40 rnnt_models:226] Using RNNT Loss : warprnnt_numba
    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}
[NeMo W 2026-01-22 22:33:40 label_looping_base:123] No conditional node support for Cuda.
    Cuda graphs with while loops are disabled, decoding speed will be slower
    Reason: Driver supports cuda toolkit version 12.4, but the driver needs to support at least 12,6. Please update your cuda driver.
[NeMo I 2026-01-22 22:33:42 save_restore_connector:285] Model EncDecHybridRNNTCTCBPEModel was successfully restored from /mnt/data/asr-finetuning/training/models/kathbath_hybrid_h200_scaleup_p3_phase3_final.nemo.

 Model Vocabulary Size: 4024
 First 20 Tokens in Acoustic Model:

 INSPECTING KENLM FILE: data/training/v2.1/kannada_4gram.arpa
 First 20 Lines of ARPA file:
   \data\
   ngram 1=465571
   ngram 2=2657001
   ngram 3=3883089
   ngram 4=4042387
   
   \1-grams:
   -6.470791	<unk>	0
   0	<s>	-0.85514647
   -1.5801783	</s>	0
   -2.9552238		-0.37312075
   -3.9322467		-0.21089505
   -5.7654624		-0.07061606
   -3.1118844		-0.21528664
   -4.9686394		-0.09310714
   -6.358391		-0.07061606
   -3.2622576		-0.71413493
   -3.3757327		-0.29129073
   -5.2053413			-0.10867205
   -5.325415		-0.63143635
   -5.7654624		-0.07061606

 TESTING SINGLE INFERENCE (Greedy vs KenLM)
   Audio: /mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_0.wav
   Ref:           
[NeMo W 2026-01-22 22:33:42 dataloader:760] The following configuration keys are ignored by Lhotse dataloader: use_start_end_token
[NeMo W 2026-01-22 22:33:42 dataloader:498] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)
Transcribing: 0it [00:00, ?it/s]
    Greedy failed: Expected 'lang' to be set for AggregateTokenizer.

============================================================
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# python3 << 'EOF'
import torch
import json
import librosa
import numpy as np
from nemo.collections.asr.models import EncDecHybridRNNTCTCBPEModel

# CONFIG
MODEL_PATH = "training/models/kathbath_hybrid_h200_scaleup_p3_phase3_final.nemo"
KENLM_PATH = "data/training/v2.1/kannada_4gram.arpa"
MANIFEST_PATH = "evaluation/benchmarking/curation/test_data/Kathbath/test_manifest.json"

def run_debug():
    print("="*60)
    print(" DIAGNOSTIC: EAR (Raw Tokens) vs BRAIN (KenLM)")
    print("="*60)
    
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

    # 1. LOAD MODEL
    print("\n1  LOADING MODEL...")
    model = EncDecHybridRNNTCTCBPEModel.restore_from(MODEL_PATH)
    model.eval()
    model.freeze()
    model = model.to(device)
    
    # 2. INSPECT VOCABULARY (What the model knows)
    print("\n2  INSPECTING MODEL VOCABULARY")
    # We check the tokenizer directly to see the BPE markers
    if hasattr(model, 'tokenizer'):
        print(f"    Tokenizer found. Type: {type(model.tokenizer)}")
        print("    First 10 Token Pieces (Raw):")
        for i in range(10):
            try:
                # We use repr() to see hidden characters like \u2581
                piece = model.tokenizer.tokenizer.id_to_piece(i)
                print(f"      ID {i}: {repr(piece)}")
            except:
                print(f"      ID {i}: [Error retrieving piece]")
    else:
        print("    No tokenizer found!")

    # 3. INSPECT KENLM (What the ARPA file expects)
    print(f"\n3  INSPECTING KENLM FILE: {KENLM_PATH}")
    print("    First 10 Lines of ARPA:")
    try:
        with open(KENLM_PATH, 'r', encoding='utf-8') as f:
            for i, line in enumerate(f):
                if i > 15: break
                print(f"      {line.strip()}")
    except Exception as e:
        print(f"       Error reading ARPA: {e}")

    # 4. MANUAL INFERENCE (No .transcribe)
    print("\n4  RUNNING MANUAL INFERENCE ON 1 FILE")
    
    # Get first audio from manifest
    with open(MANIFEST_PATH, 'r') as f:
EOF run_debug()"__main__": '{clean_str}'")1", " ").strip()...")dx)n batchto(device)
fused_indices_to_multihot has reached end of life. Please migrate to a non-experimental function.
OneLogger: Setting error_handling_strategy to DISABLE_QUIETLY_AND_REPORT_METRIC_ERROR for rank (rank=0) with OneLogger disabled. To override: explicitly set error_handling_strategy parameter.
No exporters were provided. This means that no telemetry data will be collected.
============================================================
 DIAGNOSTIC: EAR (Raw Tokens) vs BRAIN (KenLM)
============================================================

1  LOADING MODEL...
[NeMo I 2026-01-22 22:35:34 mixins:208] _setup_tokenizer: detected an aggregate tokenizer
[NeMo I 2026-01-22 22:35:34 mixins:347] Tokenizer SentencePieceTokenizer initialized with 1024 tokens
[NeMo I 2026-01-22 22:35:34 mixins:347] Tokenizer SentencePieceTokenizer initialized with 3000 tokens
[NeMo I 2026-01-22 22:35:34 aggregate_tokenizer:73] Aggregate vocab size: 4024
[NeMo W 2026-01-22 22:35:39 modelPT:188] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.
    Train config : 
    manifest_filepath: data/training/v2/master_manifest.json
    sample_rate: 16000
    batch_size: 32
    shuffle: true
    num_workers: 16
    pin_memory: true
    use_start_end_token: false
    min_duration: 1.5
    max_duration: 40.0
    prefetch_factor: 4
    
[NeMo W 2026-01-22 22:35:39 modelPT:195] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). 
    Validation config : 
    manifest_filepath:
    - /mnt/data/asr-finetuning/evaluation/benchmarking/data/v1/en_clean_read.json
    - /mnt/data/asr-finetuning/evaluation/benchmarking/data/v1/kn_clean_read.json
    sample_rate: 16000
    batch_size: 32
    shuffle: false
    num_workers: 16
    
[NeMo W 2026-01-22 22:35:39 modelPT:202] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).
    Test config : 
    manifest_filepath: null
    sample_rate: 16000
    batch_size: 16
    shuffle: false
    num_workers: 8
    pin_memory: true
    use_start_end_token: false
    
[NeMo I 2026-01-22 22:35:41 rnnt_models:226] Using RNNT Loss : warprnnt_numba
    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}
[NeMo I 2026-01-22 22:35:41 rnnt_models:226] Using RNNT Loss : warprnnt_numba
    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}
[NeMo W 2026-01-22 22:35:41 label_looping_base:123] No conditional node support for Cuda.
    Cuda graphs with while loops are disabled, decoding speed will be slower
    Reason: Driver supports cuda toolkit version 12.4, but the driver needs to support at least 12,6. Please update your cuda driver.
[NeMo I 2026-01-22 22:35:42 rnnt_models:226] Using RNNT Loss : warprnnt_numba
    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}
[NeMo W 2026-01-22 22:35:42 label_looping_base:123] No conditional node support for Cuda.
    Cuda graphs with while loops are disabled, decoding speed will be slower
    Reason: Driver supports cuda toolkit version 12.4, but the driver needs to support at least 12,6. Please update your cuda driver.
[NeMo I 2026-01-22 22:35:43 save_restore_connector:285] Model EncDecHybridRNNTCTCBPEModel was successfully restored from /mnt/data/asr-finetuning/training/models/kathbath_hybrid_h200_scaleup_p3_phase3_final.nemo.

2  INSPECTING MODEL VOCABULARY
    Tokenizer found. Type: <class 'nemo.collections.common.tokenizers.aggregate_tokenizer.AggregateTokenizer'>
    First 10 Token Pieces (Raw):
      ID 0: [Error retrieving piece]
      ID 1: [Error retrieving piece]
      ID 2: [Error retrieving piece]
      ID 3: [Error retrieving piece]
      ID 4: [Error retrieving piece]
      ID 5: [Error retrieving piece]
      ID 6: [Error retrieving piece]
      ID 7: [Error retrieving piece]
      ID 8: [Error retrieving piece]
      ID 9: [Error retrieving piece]

3  INSPECTING KENLM FILE: data/training/v2.1/kannada_4gram.arpa
    First 10 Lines of ARPA:
      \data\
      ngram 1=465571
      ngram 2=2657001
      ngram 3=3883089
      ngram 4=4042387
      
      \1-grams:
      -6.470791	<unk>	0
      0	<s>	-0.85514647
      -1.5801783	</s>	0
      -2.9552238		-0.37312075
      -3.9322467		-0.21089505
      -5.7654624		-0.07061606
      -3.1118844		-0.21528664
      -4.9686394		-0.09310714
      -6.358391		-0.07061606

4  RUNNING MANUAL INFERENCE ON 1 FILE
   Audio: /mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_0.wav
   Ref:           

    RAW MODEL OUTPUT (Greedy):
   Sequence: 1287 -> 3121 -> 3087 -> 3238 -> 1335 -> 3124 -> 1655 -> 1334 -> 1288 -> 1348 -> 3954 -> 1319 -> 1867 -> 2457 -> 2446 -> 3431 -> 1934 -> 3756 -> 1484 -> 1380 ...
   Raw String: ''
   Cleaned:    ''

============================================================
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# python3 << 'EOF'
import torch
from nemo.collections.asr.models import EncDecHybridRNNTCTCBPEModel

MODEL_PATH = "training/models/kathbath_hybrid_h200_scaleup_p3_phase3_final.nemo"

print(" INSPECTING TOKENIZER INTERNALS...")
try:
    model = EncDecHybridRNNTCTCBPEModel.restore_from(MODEL_PATH, map_location="cpu")
    tokenizer_wrapper = model.tokenizer
    
    print(f"\n1. Wrapper Type: {type(tokenizer_wrapper)}")
    print(f"2. Attributes: {dir(tokenizer_wrapper)}")
    
    # Check for common SentencePiece locations
    if hasattr(tokenizer_wrapper, 'tokenizer'):
        print("\n Found '.tokenizer' attribute")
        print(f"   Type: {type(tokenizer_wrapper.tokenizer)}")
    
    if hasattr(tokenizer_wrapper, 'sp'):
        print("\n Found '.sp' attribute")
        print(f"   Type: {type(tokenizer_wrapper.sp)}")
        
    if hasattr(tokenizer_wrapper, 'model'):
        print("\n Found '.model' attribute")
        print(f"   Type: {type(tokenizer_wrapper.model)}")

except Exception as e:
    print(f" Failed to load: {e}")
EOF
fused_indices_to_multihot has reached end of life. Please migrate to a non-experimental function.
OneLogger: Setting error_handling_strategy to DISABLE_QUIETLY_AND_REPORT_METRIC_ERROR for rank (rank=0) with OneLogger disabled. To override: explicitly set error_handling_strategy parameter.
No exporters were provided. This means that no telemetry data will be collected.
 INSPECTING TOKENIZER INTERNALS...
[NeMo I 2026-01-22 22:37:21 mixins:208] _setup_tokenizer: detected an aggregate tokenizer
[NeMo I 2026-01-22 22:37:21 mixins:347] Tokenizer SentencePieceTokenizer initialized with 1024 tokens
[NeMo I 2026-01-22 22:37:21 mixins:347] Tokenizer SentencePieceTokenizer initialized with 3000 tokens
[NeMo I 2026-01-22 22:37:21 aggregate_tokenizer:73] Aggregate vocab size: 4024
[NeMo W 2026-01-22 22:37:25 modelPT:188] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.
    Train config : 
    manifest_filepath: data/training/v2/master_manifest.json
    sample_rate: 16000
    batch_size: 32
    shuffle: true
    num_workers: 16
    pin_memory: true
    use_start_end_token: false
    min_duration: 1.5
    max_duration: 40.0
    prefetch_factor: 4
    
[NeMo W 2026-01-22 22:37:25 modelPT:195] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). 
    Validation config : 
    manifest_filepath:
    - /mnt/data/asr-finetuning/evaluation/benchmarking/data/v1/en_clean_read.json
    - /mnt/data/asr-finetuning/evaluation/benchmarking/data/v1/kn_clean_read.json
    sample_rate: 16000
    batch_size: 32
    shuffle: false
    num_workers: 16
    
[NeMo W 2026-01-22 22:37:25 modelPT:202] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).
    Test config : 
    manifest_filepath: null
    sample_rate: 16000
    batch_size: 16
    shuffle: false
    num_workers: 8
    pin_memory: true
    use_start_end_token: false
    
[NeMo I 2026-01-22 22:37:27 rnnt_models:226] Using RNNT Loss : warprnnt_numba
    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}
[NeMo I 2026-01-22 22:37:27 rnnt_models:226] Using RNNT Loss : warprnnt_numba
    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}
[NeMo W 2026-01-22 22:37:27 label_looping_base:123] No conditional node support for Cuda.
    Cuda graphs with while loops are disabled, decoding speed will be slower
    Reason: Driver supports cuda toolkit version 12.4, but the driver needs to support at least 12,6. Please update your cuda driver.
[NeMo I 2026-01-22 22:37:28 rnnt_models:226] Using RNNT Loss : warprnnt_numba
    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}
[NeMo W 2026-01-22 22:37:28 label_looping_base:123] No conditional node support for Cuda.
    Cuda graphs with while loops are disabled, decoding speed will be slower
    Reason: Driver supports cuda toolkit version 12.4, but the driver needs to support at least 12,6. Please update your cuda driver.
[NeMo I 2026-01-22 22:37:28 save_restore_connector:285] Model EncDecHybridRNNTCTCBPEModel was successfully restored from /mnt/data/asr-finetuning/training/models/kathbath_hybrid_h200_scaleup_p3_phase3_final.nemo.

1. Wrapper Type: <class 'nemo.collections.common.tokenizers.aggregate_tokenizer.AggregateTokenizer'>
2. Attributes: ['__abstractmethods__', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__slots__', '__str__', '__subclasshook__', '__weakref__', '_abc_impl', '_calculate_offsets', 'add_special_tokens', 'apply_chat_template', 'bos', 'cls', 'eod', 'eos', 'get_bos', 'get_eos', 'ids_to_lang', 'ids_to_text', 'ids_to_text_and_langs', 'ids_to_tokens', 'ids_to_words_and_langs', 'langs', 'langs_by_token_id', 'mask', 'name', 'offset_token_ids_by_token_id', 'pad', 'sep', 'supported_punctuation', 'supports_capitalization', 'text_to_ids', 'text_to_tokens', 'token_id_offset', 'token_id_offset_by_tokenizer_num', 'token_to_id', 'tokenizer', 'tokenizers_by_token_id', 'tokenizers_dict', 'tokens_to_ids', 'tokens_to_text', 'unique_identifiers', 'vocab', 'vocab_size', 'vocabulary']

 Found '.tokenizer' attribute
   Type: <class 'nemo.collections.common.tokenizers.aggregate_tokenizer.DummyTokenizer'>
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# cat << 'EOF' > evaluation/benchmarking/run/run_benchmark_kenlm.py
import argparse
import json
import torch
import os
import jiwer
from tqdm import tqdm
import librosa
import numpy as np
from nemo.collections.asr.models import EncDecHybridRNNTCTCBPEModel

# --- 1. IMPORT DECODER ---
try:
    from pyctcdecode import build_ctcdecoder
except ImportError:
    print(" Error: pyctcdecode not found. Run: pip install pyctcdecode")
    exit(1)

# --- 2. AGGREGATE TOKENIZER HANDLER (The Fix) ---
def get_raw_vocab(model):
    """
    Correctly extracts Raw BPE tokens from an AggregateTokenizer.
    """
    vocab_raw = []
    
    # 1. Use 'ids_to_tokens' to get the Raw BPE pieces (with underscores)
    # This is the specific API that works on AggregateTokenizers
    if hasattr(model, 'tokenizer') and hasattr(model.tokenizer, 'ids_to_tokens'):
        vocab_size = model.tokenizer.vocab_size
        print(f"    Unpacking AggregateTokenizer (Size: {vocab_size})...")
        
        # We process in chunks to be faster, or one by one to be safe
        # AggregateTokenizer expects a list of IDs
        for i in range(vocab_size):
            try:
                # Returns a list like ["_hello"]
                tokens = model.tokenizer.ids_to_tokens([i])
                if tokens:
                    vocab_raw.append(tokens[0])
                else:
                    vocab_raw.append(str(i)) # Fallback
            except:
                vocab_raw.append(f"<unk_{i}>")
                
    elif hasattr(model.decoder, 'vocabulary'):
        vocab_raw = model.decoder.vocabulary
    else:
        raise AttributeError("Could not find vocabulary API.")

    # 2. Deduplicate (Rename duplicates so pyctcdecode doesn't crash)
    vocab_final = []
    seen_counts = {}
    
    for token in vocab_raw:
        if token in seen_counts:
            seen_counts[token] += 1
            vocab_final.append(f"{token}_dup{seen_counts[token]}")
        else:
EOF run_eval(parse_args())r:.2f} | CER: {cer:.2f}").txt"), "w") as f:dth)ype=torch.long)
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# python evaluation/benchmarking/run/run_benchmark_kenlm.py \
  --model "training/models/kathbath_hybrid_h200_scaleup_p3_phase3_final.nemo" \
  --manifest "evaluation/benchmarking/curation/test_data/Kathbath/test_manifest.json" \
  --kenlm_model_path "data/training/v2.1/kannada_4gram.arpa" \
  --output_dir "models/results_kenlm_v1"
fused_indices_to_multihot has reached end of life. Please migrate to a non-experimental function.
OneLogger: Setting error_handling_strategy to DISABLE_QUIETLY_AND_REPORT_METRIC_ERROR for rank (rank=0) with OneLogger disabled. To override: explicitly set error_handling_strategy parameter.
No exporters were provided. This means that no telemetry data will be collected.
 Device: cuda
 Loading Model: training/models/kathbath_hybrid_h200_scaleup_p3_phase3_final.nemo
[NeMo I 2026-01-22 22:41:56 mixins:208] _setup_tokenizer: detected an aggregate tokenizer
[NeMo I 2026-01-22 22:41:56 mixins:347] Tokenizer SentencePieceTokenizer initialized with 1024 tokens
[NeMo I 2026-01-22 22:41:56 mixins:347] Tokenizer SentencePieceTokenizer initialized with 3000 tokens
[NeMo I 2026-01-22 22:41:56 aggregate_tokenizer:73] Aggregate vocab size: 4024
[NeMo W 2026-01-22 22:42:00 modelPT:188] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.
    Train config : 
    manifest_filepath: data/training/v2/master_manifest.json
    sample_rate: 16000
    batch_size: 32
    shuffle: true
    num_workers: 16
    pin_memory: true
    use_start_end_token: false
    min_duration: 1.5
    max_duration: 40.0
    prefetch_factor: 4
    
[NeMo W 2026-01-22 22:42:00 modelPT:195] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). 
    Validation config : 
    manifest_filepath:
    - /mnt/data/asr-finetuning/evaluation/benchmarking/data/v1/en_clean_read.json
    - /mnt/data/asr-finetuning/evaluation/benchmarking/data/v1/kn_clean_read.json
    sample_rate: 16000
    batch_size: 32
    shuffle: false
    num_workers: 16
    
[NeMo W 2026-01-22 22:42:00 modelPT:202] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).
    Test config : 
    manifest_filepath: null
    sample_rate: 16000
    batch_size: 16
    shuffle: false
    num_workers: 8
    pin_memory: true
    use_start_end_token: false
    
[NeMo I 2026-01-22 22:42:02 rnnt_models:226] Using RNNT Loss : warprnnt_numba
    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}
[NeMo I 2026-01-22 22:42:02 rnnt_models:226] Using RNNT Loss : warprnnt_numba
    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}
[NeMo W 2026-01-22 22:42:02 label_looping_base:123] No conditional node support for Cuda.
    Cuda graphs with while loops are disabled, decoding speed will be slower
    Reason: Driver supports cuda toolkit version 12.4, but the driver needs to support at least 12,6. Please update your cuda driver.
[NeMo I 2026-01-22 22:42:03 rnnt_models:226] Using RNNT Loss : warprnnt_numba
    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}
[NeMo W 2026-01-22 22:42:03 label_looping_base:123] No conditional node support for Cuda.
    Cuda graphs with while loops are disabled, decoding speed will be slower
    Reason: Driver supports cuda toolkit version 12.4, but the driver needs to support at least 12,6. Please update your cuda driver.
[NeMo I 2026-01-22 22:42:04 save_restore_connector:285] Model EncDecHybridRNNTCTCBPEModel was successfully restored from /mnt/data/asr-finetuning/training/models/kathbath_hybrid_h200_scaleup_p3_phase3_final.nemo.
 Loading KenLM: data/training/v2.1/kannada_4gram.arpa
    Unpacking AggregateTokenizer (Size: 4024)...
    Raw Vocab Size: 4024 (Duplicates renamed)
Loading the LM will be faster if you build a binary file.
Reading /mnt/data/asr-finetuning/data/training/v2.1/kannada_4gram.arpa
----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100
****************************************************************************************************
Unigrams and labels don't seem to agree.
 Processing 515 files (1/4 Subset)...
100%|| 33/33 [00:27<00:00,  1.21it/s]
========================================
 RESULTS (1/4 Data Subset)
WER: 33.37% | CER: 15.93%
========================================
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# python3 << 'EOF'
import argparse
import json
import torch
import os
import jiwer
import numpy as np
import librosa
from nemo.collections.asr.models import EncDecHybridRNNTCTCBPEModel
from tqdm import tqdm

# --- IMPORT DECODER ---
try:
    from pyctcdecode import build_ctcdecoder
except ImportError:
    print(" Error: pyctcdecode not found. Run: pip install pyctcdecode")
    exit(1)

# --- 1. CONFIG ---
# EDIT THESE PATHS IF NEEDED
MODEL_PATH = "training/models/kathbath_hybrid_h200_scaleup_p3_phase3_final.nemo"
KENLM_PATH = "data/training/v2.1/kannada_4gram.arpa"
MANIFEST_PATH = "evaluation/benchmarking/curation/test_data/Kathbath/test_manifest.json"
SUBSET_SIZE = 128  # Small batch to run fast

# --- 2. VOCAB EXTRACTOR ---
def get_raw_vocab(model):
    vocab_raw = []
    if hasattr(model, 'tokenizer') and hasattr(model.tokenizer, 'ids_to_tokens'):
        vocab_size = model.tokenizer.vocab_size
        for i in range(vocab_size):
            try:
                tokens = model.tokenizer.ids_to_tokens([i])
                vocab_raw.append(tokens[0] if tokens else str(i))
            except:
                vocab_raw.append(f"<unk_{i}>")
    else:
        # Fallback for other tokenizer types
        for i in range(model.decoder.vocabulary):
             vocab_raw.append(model.decoder.vocabulary[i])

    # Deduplicate for pyctcdecode
    vocab_final = []
    seen_counts = {}
    for token in vocab_raw:
        if token in seen_counts:
            seen_counts[token] += 1
            vocab_final.append(f"{token}_dup{seen_counts[token]}")
        else:
            seen_counts[token] = 0
            vocab_final.append(token)
    return vocab_final

def load_audio(path):
    try:
        audio, _ = librosa.load(path, sr=16000)
        return torch.tensor(audio, dtype=torch.float32), len(audio)
    except:
EOF run_grid_search()n__":t_preds[i]}")e merging correctly:")cer:.2f}%")n)in)
fused_indices_to_multihot has reached end of life. Please migrate to a non-experimental function.
OneLogger: Setting error_handling_strategy to DISABLE_QUIETLY_AND_REPORT_METRIC_ERROR for rank (rank=0) with OneLogger disabled. To override: explicitly set error_handling_strategy parameter.
No exporters were provided. This means that no telemetry data will be collected.
 Device: cuda
 Loading Model...
[NeMo I 2026-01-22 22:45:16 mixins:208] _setup_tokenizer: detected an aggregate tokenizer
[NeMo I 2026-01-22 22:45:16 mixins:347] Tokenizer SentencePieceTokenizer initialized with 1024 tokens
[NeMo I 2026-01-22 22:45:16 mixins:347] Tokenizer SentencePieceTokenizer initialized with 3000 tokens
[NeMo I 2026-01-22 22:45:16 aggregate_tokenizer:73] Aggregate vocab size: 4024
[NeMo W 2026-01-22 22:45:22 modelPT:188] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.
    Train config : 
    manifest_filepath: data/training/v2/master_manifest.json
    sample_rate: 16000
    batch_size: 32
    shuffle: true
    num_workers: 16
    pin_memory: true
    use_start_end_token: false
    min_duration: 1.5
    max_duration: 40.0
    prefetch_factor: 4
    
[NeMo W 2026-01-22 22:45:22 modelPT:195] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). 
    Validation config : 
    manifest_filepath:
    - /mnt/data/asr-finetuning/evaluation/benchmarking/data/v1/en_clean_read.json
    - /mnt/data/asr-finetuning/evaluation/benchmarking/data/v1/kn_clean_read.json
    sample_rate: 16000
    batch_size: 32
    shuffle: false
    num_workers: 16
    
[NeMo W 2026-01-22 22:45:22 modelPT:202] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).
    Test config : 
    manifest_filepath: null
    sample_rate: 16000
    batch_size: 16
    shuffle: false
    num_workers: 8
    pin_memory: true
    use_start_end_token: false
    
[NeMo I 2026-01-22 22:45:24 rnnt_models:226] Using RNNT Loss : warprnnt_numba
    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}
[NeMo I 2026-01-22 22:45:24 rnnt_models:226] Using RNNT Loss : warprnnt_numba
    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}
[NeMo W 2026-01-22 22:45:24 label_looping_base:123] No conditional node support for Cuda.
    Cuda graphs with while loops are disabled, decoding speed will be slower
    Reason: Driver supports cuda toolkit version 12.4, but the driver needs to support at least 12,6. Please update your cuda driver.
[NeMo I 2026-01-22 22:45:25 rnnt_models:226] Using RNNT Loss : warprnnt_numba
    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}
[NeMo W 2026-01-22 22:45:25 label_looping_base:123] No conditional node support for Cuda.
    Cuda graphs with while loops are disabled, decoding speed will be slower
    Reason: Driver supports cuda toolkit version 12.4, but the driver needs to support at least 12,6. Please update your cuda driver.
[NeMo I 2026-01-22 22:45:27 save_restore_connector:285] Model EncDecHybridRNNTCTCBPEModel was successfully restored from /mnt/data/asr-finetuning/training/models/kathbath_hybrid_h200_scaleup_p3_phase3_final.nemo.
Traceback (most recent call last):
  File "<stdin>", line 166, in <module>
  File "<stdin>", line 67, in run_grid_search
AttributeError: 'NoneType' object has no attribute 'to'
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# python3 << 'EOF'
import argparse
import json
import torch
import os
import jiwer
import numpy as np
import librosa
from nemo.collections.asr.models import EncDecHybridRNNTCTCBPEModel
from tqdm import tqdm

# --- IMPORT DECODER ---
try:
    from pyctcdecode import build_ctcdecoder
except ImportError:
    print(" Error: pyctcdecode not found. Run: pip install pyctcdecode")
    exit(1)

# --- 1. CONFIG ---
MODEL_PATH = "training/models/kathbath_hybrid_h200_scaleup_p3_phase3_final.nemo"
KENLM_PATH = "data/training/v2.1/kannada_4gram.arpa"
MANIFEST_PATH = "evaluation/benchmarking/curation/test_data/Kathbath/test_manifest.json"
SUBSET_SIZE = 128

# --- 2. VOCAB EXTRACTOR ---
def get_raw_vocab(model):
    vocab_raw = []
    # Try Aggregate Tokenizer first (The likely one)
    if hasattr(model, 'tokenizer') and hasattr(model.tokenizer, 'ids_to_tokens'):
        vocab_size = model.tokenizer.vocab_size
        for i in range(vocab_size):
            try:
                tokens = model.tokenizer.ids_to_tokens([i])
                vocab_raw.append(tokens[0] if tokens else str(i))
            except:
                vocab_raw.append(f"<unk_{i}>")
    else:
        # Fallback
        try:
            vocab_size = model.tokenizer.vocab_size
            for i in range(vocab_size):
                vocab_raw.append(model.tokenizer.ids_to_text([i]))
        except:
             # Last resort (Char models)
             vocab_raw = model.decoder.vocabulary

    # Deduplicate for pyctcdecode
    vocab_final = []
    seen_counts = {}
    for token in vocab_raw:
        if token in seen_counts:
            seen_counts[token] += 1
            vocab_final.append(f"{token}_dup{seen_counts[token]}")
        else:
            seen_counts[token] = 0
            vocab_final.append(token)
    return vocab_final

EOF run_grid_search()n__":t_preds[i]}")s))):ings)")2f}%   | {cer:.2f}%")n)in)
fused_indices_to_multihot has reached end of life. Please migrate to a non-experimental function.
OneLogger: Setting error_handling_strategy to DISABLE_QUIETLY_AND_REPORT_METRIC_ERROR for rank (rank=0) with OneLogger disabled. To override: explicitly set error_handling_strategy parameter.
No exporters were provided. This means that no telemetry data will be collected.
 Device: cuda
 Loading Model...
[NeMo I 2026-01-22 22:47:08 mixins:208] _setup_tokenizer: detected an aggregate tokenizer
[NeMo I 2026-01-22 22:47:08 mixins:347] Tokenizer SentencePieceTokenizer initialized with 1024 tokens
[NeMo I 2026-01-22 22:47:08 mixins:347] Tokenizer SentencePieceTokenizer initialized with 3000 tokens
[NeMo I 2026-01-22 22:47:08 aggregate_tokenizer:73] Aggregate vocab size: 4024
[NeMo W 2026-01-22 22:47:13 modelPT:188] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.
    Train config : 
    manifest_filepath: data/training/v2/master_manifest.json
    sample_rate: 16000
    batch_size: 32
    shuffle: true
    num_workers: 16
    pin_memory: true
    use_start_end_token: false
    min_duration: 1.5
    max_duration: 40.0
    prefetch_factor: 4
    
[NeMo W 2026-01-22 22:47:13 modelPT:195] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). 
    Validation config : 
    manifest_filepath:
    - /mnt/data/asr-finetuning/evaluation/benchmarking/data/v1/en_clean_read.json
    - /mnt/data/asr-finetuning/evaluation/benchmarking/data/v1/kn_clean_read.json
    sample_rate: 16000
    batch_size: 32
    shuffle: false
    num_workers: 16
    
[NeMo W 2026-01-22 22:47:13 modelPT:202] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).
    Test config : 
    manifest_filepath: null
    sample_rate: 16000
    batch_size: 16
    shuffle: false
    num_workers: 8
    pin_memory: true
    use_start_end_token: false
    
[NeMo I 2026-01-22 22:47:15 rnnt_models:226] Using RNNT Loss : warprnnt_numba
    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}
[NeMo I 2026-01-22 22:47:15 rnnt_models:226] Using RNNT Loss : warprnnt_numba
    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}
[NeMo W 2026-01-22 22:47:15 label_looping_base:123] No conditional node support for Cuda.
    Cuda graphs with while loops are disabled, decoding speed will be slower
    Reason: Driver supports cuda toolkit version 12.4, but the driver needs to support at least 12,6. Please update your cuda driver.
[NeMo I 2026-01-22 22:47:16 rnnt_models:226] Using RNNT Loss : warprnnt_numba
    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}
[NeMo W 2026-01-22 22:47:16 label_looping_base:123] No conditional node support for Cuda.
    Cuda graphs with while loops are disabled, decoding speed will be slower
    Reason: Driver supports cuda toolkit version 12.4, but the driver needs to support at least 12,6. Please update your cuda driver.
[NeMo I 2026-01-22 22:47:17 save_restore_connector:285] Model EncDecHybridRNNTCTCBPEModel was successfully restored from /mnt/data/asr-finetuning/training/models/kathbath_hybrid_h200_scaleup_p3_phase3_final.nemo.
 Pre-computing logits for 128 files...
100%|| 128/128 [00:08<00:00, 15.82it/s]
 Loading KenLM...

==================================================
 STARTING GRID SEARCH
==================================================
Alpha    | Beta     | WER      | CER     
--------------------------------------------------
Loading the LM will be faster if you build a binary file.
Reading /mnt/data/asr-finetuning/data/training/v2.1/kannada_4gram.arpa
----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100
****************************************************************************************************
Unigrams and labels don't seem to agree.
0.1      | 0.0      | 34.23%   | 10.85%
Loading the LM will be faster if you build a binary file.
Reading /mnt/data/asr-finetuning/data/training/v2.1/kannada_4gram.arpa
----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100
****************************************************************************************************
Unigrams and labels don't seem to agree.
0.1      | 1.0      | 36.99%   | 10.38%
Loading the LM will be faster if you build a binary file.
Reading /mnt/data/asr-finetuning/data/training/v2.1/kannada_4gram.arpa
----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100
****************************************************************************************************
Unigrams and labels don't seem to agree.
0.1      | 2.0      | 41.44%   | 10.80%
Loading the LM will be faster if you build a binary file.
Reading /mnt/data/asr-finetuning/data/training/v2.1/kannada_4gram.arpa
----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100
****************************************************************************************************
Unigrams and labels don't seem to agree.
0.1      | 3.0      | 51.41%   | 12.41%
Loading the LM will be faster if you build a binary file.
Reading /mnt/data/asr-finetuning/data/training/v2.1/kannada_4gram.arpa
----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100
****************************************************************************************************
Unigrams and labels don't seem to agree.
0.5      | 0.0      | 33.52%   | 16.28%
Loading the LM will be faster if you build a binary file.
Reading /mnt/data/asr-finetuning/data/training/v2.1/kannada_4gram.arpa
----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100
****************************************************************************************************
Unigrams and labels don't seem to agree.
0.5      | 1.0      | 31.90%   | 14.36%
Loading the LM will be faster if you build a binary file.
Reading /mnt/data/asr-finetuning/data/training/v2.1/kannada_4gram.arpa
----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100
****************************************************************************************************
Unigrams and labels don't seem to agree.
0.5      | 2.0      | 32.25%   | 12.85%
Loading the LM will be faster if you build a binary file.
Reading /mnt/data/asr-finetuning/data/training/v2.1/kannada_4gram.arpa
----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100
****************************************************************************************************
Unigrams and labels don't seem to agree.
0.5      | 3.0      | 32.53%   | 11.67%
Loading the LM will be faster if you build a binary file.
Reading /mnt/data/asr-finetuning/data/training/v2.1/kannada_4gram.arpa
----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100
****************************************************************************************************
Unigrams and labels don't seem to agree.
0.8      | 0.0      | 38.83%   | 21.89%
Loading the LM will be faster if you build a binary file.
Reading /mnt/data/asr-finetuning/data/training/v2.1/kannada_4gram.arpa
----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100
****************************************************************************************************
Unigrams and labels don't seem to agree.
0.8      | 1.0      | 36.99%   | 20.22%
Loading the LM will be faster if you build a binary file.
Reading /mnt/data/asr-finetuning/data/training/v2.1/kannada_4gram.arpa
----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100
****************************************************************************************************
Unigrams and labels don't seem to agree.
0.8      | 2.0      | 35.36%   | 18.38%
Loading the LM will be faster if you build a binary file.
Reading /mnt/data/asr-finetuning/data/training/v2.1/kannada_4gram.arpa
----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100
****************************************************************************************************
Unigrams and labels don't seem to agree.
0.8      | 3.0      | 34.58%   | 16.70%
Loading the LM will be faster if you build a binary file.
Reading /mnt/data/asr-finetuning/data/training/v2.1/kannada_4gram.arpa
----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100
****************************************************************************************************
Unigrams and labels don't seem to agree.
1.0      | 0.0      | 42.72%   | 25.56%
Loading the LM will be faster if you build a binary file.
Reading /mnt/data/asr-finetuning/data/training/v2.1/kannada_4gram.arpa
----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100
****************************************************************************************************
Unigrams and labels don't seem to agree.
1.0      | 1.0      | 41.02%   | 23.95%
Loading the LM will be faster if you build a binary file.
Reading /mnt/data/asr-finetuning/data/training/v2.1/kannada_4gram.arpa
----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100
****************************************************************************************************
Unigrams and labels don't seem to agree.
1.0      | 2.0      | 39.32%   | 22.27%
Loading the LM will be faster if you build a binary file.
Reading /mnt/data/asr-finetuning/data/training/v2.1/kannada_4gram.arpa
----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100
****************************************************************************************************
Unigrams and labels don't seem to agree.
1.0      | 3.0      | 37.48%   | 20.30%
Loading the LM will be faster if you build a binary file.
Reading /mnt/data/asr-finetuning/data/training/v2.1/kannada_4gram.arpa
----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100
****************************************************************************************************
Unigrams and labels don't seem to agree.
1.5      | 0.0      | 50.92%   | 29.98%
Loading the LM will be faster if you build a binary file.
Reading /mnt/data/asr-finetuning/data/training/v2.1/kannada_4gram.arpa
----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100
****************************************************************************************************
Unigrams and labels don't seem to agree.
1.5      | 1.0      | 49.08%   | 29.45%
Loading the LM will be faster if you build a binary file.
Reading /mnt/data/asr-finetuning/data/training/v2.1/kannada_4gram.arpa
----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100
****************************************************************************************************
Unigrams and labels don't seem to agree.
1.5      | 2.0      | 48.30%   | 28.98%
Loading the LM will be faster if you build a binary file.
Reading /mnt/data/asr-finetuning/data/training/v2.1/kannada_4gram.arpa
----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100
****************************************************************************************************
Unigrams and labels don't seem to agree.
1.5      | 3.0      | 46.89%   | 27.67%
Loading the LM will be faster if you build a binary file.
Reading /mnt/data/asr-finetuning/data/training/v2.1/kannada_4gram.arpa
----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100
****************************************************************************************************
Unigrams and labels don't seem to agree.
2.0      | 0.0      | 56.29%   | 31.98%
Loading the LM will be faster if you build a binary file.
Reading /mnt/data/asr-finetuning/data/training/v2.1/kannada_4gram.arpa
----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100
****************************************************************************************************
Unigrams and labels don't seem to agree.
2.0      | 1.0      | 55.45%   | 31.71%
Loading the LM will be faster if you build a binary file.
Reading /mnt/data/asr-finetuning/data/training/v2.1/kannada_4gram.arpa
----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100
****************************************************************************************************
Unigrams and labels don't seem to agree.
2.0      | 2.0      | 54.38%   | 31.24%
Loading the LM will be faster if you build a binary file.
Reading /mnt/data/asr-finetuning/data/training/v2.1/kannada_4gram.arpa
----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100
****************************************************************************************************
Unigrams and labels don't seem to agree.
2.0      | 3.0      | 52.90%   | 30.68%
==================================================
 BEST RESULT: WER 31.90%
   Alpha: 0.5
   Beta:  1.0
==================================================

 QUALITATIVE CHECK (Best Settings)

Example 1:
Ref:          
Pred:        

Example 2:
Ref:          
Pred:        

Example 3:
Ref:               
Pred:              
^C^Z
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# # Find any text file larger than 100MB with "wiki" or "corpus" in the name
find /mnt/data -type f \( -name "*wiki*" -o -name "*corpus*" \) -size +100M -exec ls -lh {} +
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# find /mnt/data -type f \( -name "*wiki*" -o -name "*corpus*" \) -size +100M -exec ls -lh {} +
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# find /mnt/data -type f -name "*.txt" -size +100M -exec ls -lh {} +
-rw-r----- 1 root root 105M Jan 22 19:47 /mnt/data/asr-finetuning/data/training/v2.1/all_text.txt
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# find /mnt/data -type f -name "*.txt" -size +100M -ex^C ls -lh {} +
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# find /mnt/data -type f -name "*.txt" -size +10M -exec ls -lh {} +
-rw-r----- 1 root root 105M Jan 22 19:47 /mnt/data/asr-finetuning/data/training/v2.1/all_text.txt
-rw-r----- 1 root root  11M Jan 21 20:39 /mnt/data/asr-finetuning/training/experiments/kathbath_hybrid_h200_scaleup_phase2/2026-01-21_11-36-36/nemo_log_globalrank-0_localrank-0.txt
-rw-r----- 1 root root  11M Jan 21 20:39 /mnt/data/asr-finetuning/training/experiments/kathbath_hybrid_h200_scaleup_phase2/2026-01-21_11-36-36/nemo_log_globalrank-1_localrank-1.txt
-rw-r----- 1 root root  19M Jan 19 01:39 /mnt/data/asr-finetuning/training/experiments/kathbath_v1_init/2026-01-18_21-54-51/nemo_log_globalrank-0_localrank-0.txt
-rw-r----- 1 root root  15M Jan 19 09:44 /mnt/data/asr-finetuning/training/experiments/kathbath_v2_unfrozen/2026-01-19_05-18-12/nemo_log_globalrank-0_localrank-0.txt
-rw-r----- 1 root root  16M Jan 18 21:03 /mnt/data/asr-finetuning/training/tokenizers/kn_master/all_kannada_text.txt
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# nano fetch_wiki.py
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# # 1. Run the python script to get text
python fetch_wiki.py

# 2. Build the KenLM ARPA file
# --prune 0 0 1: Removes rare singleton errors to keep file size manageable
echo " Training KenLM (This may take 1-2 mins)..."
kenlm/build/bin/lmplz -o 6 --prune 0 0 1 < data/training/wiki_corpus.txt > data/training/wiki_6gram.arpa

echo " Created: data/training/wiki_6gram.arpa"
  Loading Dataset: wikipedia...
Downloading readme: 131kB [00:00, 92.2MB/s]
Downloading data: 100%|| 147M/147M [00:01<00:00, 117MB/s]
Generating train split: 100%|| 31437/31437 [00:01<00:00, 16505.59 examples/s]
 extracting and cleaning text to data/training/wiki_corpus.txt...
100%|| 31437/31437 [00:16<00:00, 1856.20it/s]
 Success! Saved 1521438 sentences to data/training/wiki_corpus.txt
 Training KenLM (This may take 1-2 mins)...
=== 1/5 Counting and sorting n-grams ===
Reading /mnt/data/asr-finetuning/data/training/wiki_corpus.txt
----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100
****************************************************************************************************
Unigram tokens 16830742 types 1380268
=== 2/5 Calculating and sorting adjusted counts ===
Chain sizes: 1:16563216 2:13303456768 3:24943982592 4:39910371328 5:58202628096 6:79820742656
Statistics:
1 1380268 D1=0.730797 D2=1.03633 D3+=1.33182
2 9814529 D1=0.857068 D2=1.16119 D3+=1.34049
3 909001/14380785 D1=0.947952 D2=1.32138 D3+=1.41395
4 448809/14297732 D1=0.98137 D2=1.53223 D3+=1.57755
5 299121/13115394 D1=0.990371 D2=1.65672 D3+=1.69682
6 230753/11767450 D1=0.966409 D2=1.74908 D3+=1.88039
Memory estimate for binary LM:
type     MB
probing 300 assuming -p 1.5
probing 371 assuming -r models -p 1.5
trie    175 without quantization
trie    110 assuming -q 8 -b 8 quantization 
trie    153 assuming -a 22 array pointer compression
trie     88 assuming -a 22 -q 8 -b 8 array pointer compression and quantization
=== 3/5 Calculating and sorting initial probabilities ===
Chain sizes: 1:16563216 2:157032464 3:18180020 4:10771416 5:8375388 6:7384096
----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100
*###################################################################################################
=== 4/5 Calculating and writing order-interpolated probabilities ===
Chain sizes: 1:16563216 2:157032464 3:18180020 4:10771416 5:8375388 6:7384096
----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100
####################################################################################################
=== 5/5 Writing ARPA model ===
----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100
****************************************************************************************************
Name:lmplz	VmPeak:211318928 kB	VmRSS:133292 kB	RSSMax:33853592 kB	user:32.4965	sys:32.9597	CPU:65.4563	real:45.7798
 Created: data/training/wiki_6gram.arpa
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# python run_grid_search.py \
  --kenlm_model_path "data/training/wiki_6gram.arpa"
python: can't open file '/mnt/data/asr-finetuning/run_grid_search.py': [Errno 2] No such file or directory
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# python3 << 'EOF'                                                          
import argparse                                      # Find any text file larger than 100MB with "wiki" or "corpus" in the name
                                                     find /mnt/data -type f \( -name "*wiki*" -o -name "*corpus*" \) -size +100M -exec ls -lh {} +^C
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# python3 << 'EOF'
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# python3 << 'EOF'
import argparse
import jsonh
import torch
import oswer
import jiwer as np
import numpy as np
import librosaections.asr.models import EncDecHybridRNNTCTCBPEModel
from nemo.collections.asr.models import EncDecHybridRNNTCTCBPEModel
from tqdm import tqdm
# --- IMPORT DECODER ---
# --- IMPORT DECODER ---
try:from pyctcdecode import build_ctcdecoder
    from pyctcdecode import build_ctcdecoder
except ImportError:: pyctcdecode not found. Run: pip install pyctcdecode")
    print(" Error: pyctcdecode not found. Run: pip install pyctcdecode")
    exit(1)
# --- 1. CONFIG ---
# --- 1. CONFIG ---ing/models/kathbath_hybrid_h200_scaleup_p3_phase3_final.nemo"
MODEL_PATH = "training/models/kathbath_hybrid_h200_scaleup_p3_phase3_final.nemo"
KENLM_PATH = "data/training/v2.1/kannada_4gram.arpa"st_data/Kathbath/test_manifest.json"
MANIFEST_PATH = "evaluation/benchmarking/curation/test_data/Kathbath/test_manifest.json"
SUBSET_SIZE = 128
# --- 2. VOCAB EXTRACTOR ---
# --- 2. VOCAB EXTRACTOR ---
def get_raw_vocab(model):
    vocab_raw = []e Tokenizer first (The likely one)
    # Try Aggregate Tokenizer first (The likely one).tokenizer, 'ids_to_tokens'):
    if hasattr(model, 'tokenizer') and hasattr(model.tokenizer, 'ids_to_tokens'):
        vocab_size = model.tokenizer.vocab_size
        for i in range(vocab_size):
            try:tokens = model.tokenizer.ids_to_tokens([i])
                tokens = model.tokenizer.ids_to_tokens([i])tr(i))
                vocab_raw.append(tokens[0] if tokens else str(i))
            except:ab_raw.append(f"<unk_{i}>")
                vocab_raw.append(f"<unk_{i}>")
    else: Fallback
        # Fallback
        try:vocab_size = model.tokenizer.vocab_size
            vocab_size = model.tokenizer.vocab_size
            for i in range(vocab_size):tokenizer.ids_to_text([i]))
                vocab_raw.append(model.tokenizer.ids_to_text([i]))
        except:Last resort (Char models)
             # Last resort (Char models)ocabulary
             vocab_raw = model.decoder.vocabulary
    # Deduplicate for pyctcdecode
    # Deduplicate for pyctcdecode
    vocab_final = []
    seen_counts = {}ab_raw:
    for token in vocab_raw:unts:
        if token in seen_counts:= 1
            seen_counts[token] += 1oken}_dup{seen_counts[token]}")
            vocab_final.append(f"{token}_dup{seen_counts[token]}")
        else:een_counts[token] = 0
            seen_counts[token] = 0en)
            vocab_final.append(token)
    return vocab_final
EOF 
EOF 
> ^C
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# python3 << 'EOF'
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# python3 << 'EOF'
import argparse
import jsonh
import torch
import oswer
import jiwer as np
import numpy as np
import librosaections.asr.models import EncDecHybridRNNTCTCBPEModel
from nemo.collections.asr.models import EncDecHybridRNNTCTCBPEModel
from tqdm import tqdm
# --- IMPORT DECODER ---
# --- IMPORT DECODER ---
try:from pyctcdecode import build_ctcdecoder
    from pyctcdecode import build_ctcdecoder
except ImportError:: pyctcdecode not found. Run: pip install pyctcdecode")
    print(" Error: pyctcdecode not found. Run: pip install pyctcdecode")
    exit(1)
# --- 1. CONFIG ---
# --- 1. CONFIG ---ing/models/kathbath_hybrid_h200_scaleup_p3_phase3_final.nemo"
MODEL_PATH = "training/models/kathbath_hybrid_h200_scaleup_p3_phase3_final.nemo"
KENLM_PATH = "data/training/v2.1/kannada_4gram.arpa"st_data/Kathbath/test_manifest.json"
MANIFEST_PATH = "evaluation/benchmarking/curation/test_data/Kathbath/test_manifest.json"
SUBSET_SIZE = 128
# --- 2. VOCAB EXTRACTOR ---
# --- 2. VOCAB EXTRACTOR ---
def get_raw_vocab(model):
    vocab_raw = []e Tokenizer first (The likely one)
    # Try Aggregate Tokenizer first (The likely one).tokenizer, 'ids_to_tokens'):
    if hasattr(model, 'tokenizer') and hasattr(model.tokenizer, 'ids_to_tokens'):
        vocab_size = model.tokenizer.vocab_size
        for i in range(vocab_size):
            try:tokens = model.tokenizer.ids_to_tokens([i])
                tokens = model.tokenizer.ids_to_tokens([i])tr(i))
                vocab_raw.append(tokens[0] if tokens else str(i))
            except:ab_raw.append(f"<unk_{i}>")
                vocab_raw.append(f"<unk_{i}>")
    else: Fallback
        # Fallback
        try:vocab_size = model.tokenizer.vocab_size
            vocab_size = model.tokenizer.vocab_size
            for i in range(vocab_size):tokenizer.ids_to_text([i]))
                vocab_raw.append(model.tokenizer.ids_to_text([i]))
        except:Last resort (Char models)
             # Last resort (Char models)ocabulary
             vocab_raw = model.decoder.vocabulary
    # Deduplicate for pyctcdecode
    # Deduplicate for pyctcdecode
    vocab_final = []
    seen_counts = {}ab_raw:
    for token in vocab_raw:unts:
        if token in seen_counts:= 1
            seen_counts[token] += 1oken}_dup{seen_counts[token]}")
            vocab_final.append(f"{token}_dup{seen_counts[token]}")
        else:een_counts[token] = 0
            seen_counts[token] = 0en)
            vocab_final.append(token)
    return vocab_final
EOF
EOF
^CTraceback (most recent call last):
  File "<stdin>", line 5, in <module>
  File "/mnt/data/asr-env/lib/python3.12/site-packages/jiwer/__init__.py", line 1, in <module>
    from .measures import *
  File "/mnt/data/asr-env/lib/python3.12/site-packages/jiwer/measures.py", line 51, in <module>
    from jiwer.process import process_words, process_characters
  File "/mnt/data/asr-env/lib/python3.12/site-packages/jiwer/process.py", line 29, in <module>
    import rapidfuzz
  File "/mnt/data/asr-env/lib/python3.12/site-packages/rapidfuzz/__init__.py", line 11, in <module>
    from rapidfuzz import distance, fuzz, process, utils
  File "/mnt/data/asr-env/lib/python3.12/site-packages/rapidfuzz/utils.py", line 58, in <module>
    from rapidfuzz.utils_cpp import (
  File "src/rapidfuzz/utils_cpp.pyx", line 14, in init rapidfuzz.utils_cpp
  File "<frozen importlib._bootstrap>", line 645, in parent
KeyboardInterrupt

(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# python3 << 'EOF'
import argparse
import json
import torch
import os
import jiwer
import numpy as np
import librosa
from nemo.collections.asr.models import EncDecHybridRNNTCTCBPEModel
from tqdm import tqdm

# --- IMPORT DECODER ---
try:
    from pyctcdecode import build_ctcdecoder
except ImportError:
    print(" Error: pyctcdecode not found. Run: pip install pyctcdecode")
    exit(1)

# --- 1. CONFIG ---
MODEL_PATH = "training/models/kathbath_hybrid_h200_scaleup_p3_phase3_final.nemo"
KENLM_PATH = "data/training/v2.1/kannada_4gram.arpa"
MANIFEST_PATH = "evaluation/benchmarking/curation/test_data/Kathbath/test_manifest.json"
SUBSET_SIZE = 128

# --- 2. VOCAB EXTRACTOR ---
def get_raw_vocab(model):
    vocab_raw = []
    # Try Aggregate Tokenizer first (The likely one)
    if hasattr(model, 'tokenizer') and hasattr(model.tokenizer, 'ids_to_tokens'):
        vocab_size = model.tokenizer.vocab_size
        for i in range(vocab_size):
            try:
                tokens = model.tokenizer.ids_to_tokens([i])
                vocab_raw.append(tokens[0] if tokens else str(i))
            except:
                vocab_raw.append(f"<unk_{i}>")
    else:
        # Fallback
        try:
            vocab_size = model.tokenizer.vocab_size
            for i in range(vocab_size):
                vocab_raw.append(model.tokenizer.ids_to_text([i]))
        except:
             # Last resort (Char models)
             vocab_raw = model.decoder.vocabulary

    # Deduplicate for pyctcdecode
    vocab_final = []
    seen_counts = {}
    for token in vocab_raw:
        if token in seen_counts:
            seen_counts[token] += 1
            vocab_final.append(f"{token}_dup{seen_counts[token]}")
        else:
            seen_counts[token] = 0
            vocab_final.append(token)
    return vocab_final

EOF
fused_indices_to_multihot has reached end of life. Please migrate to a non-experimental function.
OneLogger: Setting error_handling_strategy to DISABLE_QUIETLY_AND_REPORT_METRIC_ERROR for rank (rank=0) with OneLogger disabled. To override: explicitly set error_handling_strategy parameter.
No exporters were provided. This means that no telemetry data will be collected.
^CTraceback (most recent call last):
  File "<stdin>", line 8, in <module>
  File "/mnt/data/asr-env/lib/python3.12/site-packages/nemo/collections/asr/__init__.py", line 15, in <module>
    from nemo.collections.asr import data, losses, models, modules
  File "/mnt/data/asr-env/lib/python3.12/site-packages/nemo/collections/asr/models/__init__.py", line 15, in <module>
    from nemo.collections.asr.models.aed_multitask_models import EncDecMultiTaskModel
  File "/mnt/data/asr-env/lib/python3.12/site-packages/nemo/collections/asr/models/aed_multitask_models.py", line 32, in <module>
    from nemo.collections.asr.metrics import MultiTaskMetric
  File "/mnt/data/asr-env/lib/python3.12/site-packages/nemo/collections/asr/metrics/__init__.py", line 15, in <module>
    from nemo.collections.asr.metrics.bleu import BLEU
  File "/mnt/data/asr-env/lib/python3.12/site-packages/nemo/collections/asr/metrics/bleu.py", line 23, in <module>
    from nemo.collections.asr.parts.submodules.ctc_decoding import AbstractCTCDecoding
  File "/mnt/data/asr-env/lib/python3.12/site-packages/nemo/collections/asr/parts/submodules/ctc_decoding.py", line 25, in <module>
    from nemo.collections.asr.parts.submodules import ctc_beam_decoding, ctc_greedy_decoding
  File "/mnt/data/asr-env/lib/python3.12/site-packages/nemo/collections/asr/parts/submodules/ctc_beam_decoding.py", line 24, in <module>
    from nemo.collections.asr.parts.context_biasing import BoostingTreeModelConfig, GPUBoostingTreeModel
  File "/mnt/data/asr-env/lib/python3.12/site-packages/nemo/collections/asr/parts/context_biasing/__init__.py", line 19, in <module>
    from nemo.collections.asr.parts.context_biasing.context_biasing_utils import (
  File "/mnt/data/asr-env/lib/python3.12/site-packages/nemo/collections/asr/parts/context_biasing/context_biasing_utils.py", line 23, in <module>
    from nemo.collections.asr.parts.utils.manifest_utils import read_manifest
  File "/mnt/data/asr-env/lib/python3.12/site-packages/nemo/collections/asr/parts/utils/manifest_utils.py", line 25, in <module>
    from nemo.collections.asr.parts.utils.speaker_utils import (
  File "/mnt/data/asr-env/lib/python3.12/site-packages/nemo/collections/asr/parts/utils/speaker_utils.py", line 27, in <module>
    from pyannote.core import Annotation, Segment, Timeline
  File "/mnt/data/asr-env/lib/python3.12/site-packages/pyannote/core/__init__.py", line 48, in <module>
    from .notebook import notebook
  File "/mnt/data/asr-env/lib/python3.12/site-packages/pyannote/core/notebook.py", line 100, in <module>
    from IPython.core.pylabtools import print_figure
  File "/mnt/data/asr-env/lib/python3.12/site-packages/IPython/__init__.py", line 56, in <module>
    from .core.application import Application
  File "/mnt/data/asr-env/lib/python3.12/site-packages/IPython/core/application.py", line 26, in <module>
    from IPython.core import release, crashhandler
  File "/mnt/data/asr-env/lib/python3.12/site-packages/IPython/core/crashhandler.py", line 28, in <module>
    from IPython.core import ultratb
  File "/mnt/data/asr-env/lib/python3.12/site-packages/IPython/core/ultratb.py", line 89, in <module>
    from IPython.utils.PyColorize import Parser, Theme, TokenStream, theme_table
  File "/mnt/data/asr-env/lib/python3.12/site-packages/IPython/utils/PyColorize.py", line 112, in <module>
    nocolors_theme = Theme("nocolor", None, {})
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/data/asr-env/lib/python3.12/site-packages/IPython/utils/PyColorize.py", line 58, in __init__
    self._formatter = Terminal256Formatter(style=self.as_pygments_style())
                                                 ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/data/asr-env/lib/python3.12/site-packages/IPython/utils/PyColorize.py", line 67, in as_pygments_style
    class MyStyle(Style):
  File "/mnt/data/asr-env/lib/python3.12/site-packages/pygments/style.py", line 84, in __new__
    for token in ttype.split():
KeyboardInterrupt
^C
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# python - <<'EOF'
import argparse
import json
import torch
import os
import jiwer
import numpy as np
import librosa
from nemo.collections.asr.models import EncDecHybridRNNTCTCBPEModel
from tqdm import tqdm

# --- IMPORT DECODER ---
try:
    from pyctcdecode import build_ctcdecoder
except ImportError:
    print(" Error: pyctcdecode not found. Run: pip install pyctcdecode")
    exit(1)

# --- 1. CONFIG ---
# EDIT THESE PATHS IF NEEDED
MODEL_PATH = "training/models/kathbath_hybrid_h200_scaleup_p3_phase3_final.nemo"
KENLM_PATH = "data/training/wiki_6gram.arpa"
MANIFEST_PATH = "evaluation/benchmarking/curation/test_data/Kathbath/test_manifest.json"
SUBSET_SIZE = 128  # Small batch to run fast

# --- 2. VOCAB EXTRACTOR ---
def get_raw_vocab(model):
    vocab_raw = []
    if hasattr(model, 'tokenizer') and hasattr(model.tokenizer, 'ids_to_tokens'):
        vocab_size = model.tokenizer.vocab_size
        for i in range(vocab_size):
            try:
                tokens = model.tokenizer.ids_to_tokens([i])
                vocab_raw.append(tokens[0] if tokens else str(i))
            except:
                vocab_raw.append(f"<unk_{i}>")
    else:
        # Fallback for other tokenizer types
        for i in range(model.decoder.vocabulary):
             vocab_raw.append(model.decoder.vocabulary[i])

    # Deduplicate for pyctcdecode
    vocab_final = []
    seen_counts = {}
    for token in vocab_raw:
        if token in seen_counts:
            seen_counts[token] += 1
            vocab_final.append(f"{token}_dup{seen_counts[token]}")
        else:
            seen_counts[token] = 0
            vocab_final.append(token)
    return vocab_final

def load_audio(path):
    try:
        audio, _ = librosa.load(path, sr=16000)
        return torch.tensor(audio, dtype=torch.float32), len(audio)
    except:
EOF run_grid_search()n__":t_preds[i]}")e merging correctly:")cer:.2f}%")n)in)
fused_indices_to_multihot has reached end of life. Please migrate to a non-experimental function.
OneLogger: Setting error_handling_strategy to DISABLE_QUIETLY_AND_REPORT_METRIC_ERROR for rank (rank=0) with OneLogger disabled. To override: explicitly set error_handling_strategy parameter.
No exporters were provided. This means that no telemetry data will be collected.
 Device: cuda
 Loading Model...
[NeMo I 2026-01-22 23:12:30 mixins:208] _setup_tokenizer: detected an aggregate tokenizer
[NeMo I 2026-01-22 23:12:30 mixins:347] Tokenizer SentencePieceTokenizer initialized with 1024 tokens
[NeMo I 2026-01-22 23:12:30 mixins:347] Tokenizer SentencePieceTokenizer initialized with 3000 tokens
[NeMo I 2026-01-22 23:12:30 aggregate_tokenizer:73] Aggregate vocab size: 4024
[NeMo W 2026-01-22 23:12:35 modelPT:188] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.
    Train config : 
    manifest_filepath: data/training/v2/master_manifest.json
    sample_rate: 16000
    batch_size: 32
    shuffle: true
    num_workers: 16
    pin_memory: true
    use_start_end_token: false
    min_duration: 1.5
    max_duration: 40.0
    prefetch_factor: 4
    
[NeMo W 2026-01-22 23:12:35 modelPT:195] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). 
    Validation config : 
    manifest_filepath:
    - /mnt/data/asr-finetuning/evaluation/benchmarking/data/v1/en_clean_read.json
    - /mnt/data/asr-finetuning/evaluation/benchmarking/data/v1/kn_clean_read.json
    sample_rate: 16000
    batch_size: 32
    shuffle: false
    num_workers: 16
    
[NeMo W 2026-01-22 23:12:35 modelPT:202] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).
    Test config : 
    manifest_filepath: null
    sample_rate: 16000
    batch_size: 16
    shuffle: false
    num_workers: 8
    pin_memory: true
    use_start_end_token: false
    
[NeMo I 2026-01-22 23:12:37 rnnt_models:226] Using RNNT Loss : warprnnt_numba
    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}
[NeMo I 2026-01-22 23:12:37 rnnt_models:226] Using RNNT Loss : warprnnt_numba
    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}
[NeMo W 2026-01-22 23:12:37 label_looping_base:123] No conditional node support for Cuda.
    Cuda graphs with while loops are disabled, decoding speed will be slower
    Reason: Driver supports cuda toolkit version 12.4, but the driver needs to support at least 12,6. Please update your cuda driver.
[NeMo I 2026-01-22 23:12:37 rnnt_models:226] Using RNNT Loss : warprnnt_numba
    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}
[NeMo W 2026-01-22 23:12:37 label_looping_base:123] No conditional node support for Cuda.
    Cuda graphs with while loops are disabled, decoding speed will be slower
    Reason: Driver supports cuda toolkit version 12.4, but the driver needs to support at least 12,6. Please update your cuda driver.
[NeMo I 2026-01-22 23:12:39 save_restore_connector:285] Model EncDecHybridRNNTCTCBPEModel was successfully restored from /mnt/data/asr-finetuning/training/models/kathbath_hybrid_h200_scaleup_p3_phase3_final.nemo.
Traceback (most recent call last):
  File "<stdin>", line 166, in <module>
  File "<stdin>", line 67, in run_grid_search
AttributeError: 'NoneType' object has no attribute 'to'
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# python - <<'EOF'
import argparse
import json
import torch
import os
import jiwer
import numpy as np
import librosa
from nemo.collections.asr.models import EncDecHybridRNNTCTCBPEModel
from tqdm import tqdm

# --- IMPORT DECODER ---
try:
    from pyctcdecode import build_ctcdecoder
except ImportError:
    print(" Error: pyctcdecode not found. Run: pip install pyctcdecode")
    exit(1)

# --- 1. CONFIG DEFAULTS ---
DEFAULT_MODEL = "training/models/kathbath_hybrid_h200_scaleup_p3_phase3_final.nemo"
DEFAULT_KENLM = "data/training/wiki_6gram.arpa"  # Default to the new Wiki Brain
DEFAULT_MANIFEST = "evaluation/benchmarking/curation/test_data/Kathbath/test_manifest.json"
SUBSET_SIZE = 128

# --- 2. VOCAB EXTRACTOR (THE AGGREGATE TOKENIZER FIX) ---
def get_raw_vocab(model):
    """
    Extracts raw BPE tokens (preserving underscores) from NeMo AggregateTokenizers.
    Renames duplicates to prevent pyctcdecode crashes.
    """
    vocab_raw = []
    
    # Try Aggregate Tokenizer first (The likely one)
    if hasattr(model, 'tokenizer') and hasattr(model.tokenizer, 'ids_to_tokens'):
        vocab_size = model.tokenizer.vocab_size
        # Process in chunks if needed, but simple loop is fine for <50k vocab
        for i in range(vocab_size):
            try:
                tokens = model.tokenizer.ids_to_tokens([i])
                vocab_raw.append(tokens[0] if tokens else str(i))
            except:
                vocab_raw.append(f"<unk_{i}>")
    else:
        # Fallback 1: Standard Tokenizer
        try:
            vocab_size = model.tokenizer.vocab_size
            for i in range(vocab_size):
                vocab_raw.append(model.tokenizer.ids_to_text([i]))
        except:
             # Fallback 2: Char models
             if hasattr(model.decoder, 'vocabulary'):
                 vocab_raw = model.decoder.vocabulary
             else:
                 raise AttributeError("Could not find vocabulary!")

    # Deduplicate for pyctcdecode (Critical Step)
    vocab_final = []
    seen_counts = {}
EOF run_grid_search()n__":t_preds[i]}")s))):ings)")2f}%   | {cer:.2f}%")LMctcdecode sets it at build.")
fused_indices_to_multihot has reached end of life. Please migrate to a non-experimental function.
OneLogger: Setting error_handling_strategy to DISABLE_QUIETLY_AND_REPORT_METRIC_ERROR for rank (rank=0) with OneLogger disabled. To override: explicitly set error_handling_strategy parameter.
No exporters were provided. This means that no telemetry data will be collected.
 Device: cuda
 Model: training/models/kathbath_hybrid_h200_scaleup_p3_phase3_final.nemo
 KenLM: data/training/wiki_6gram.arpa
 Loading Model...
[NeMo I 2026-01-22 23:14:14 mixins:208] _setup_tokenizer: detected an aggregate tokenizer
[NeMo I 2026-01-22 23:14:14 mixins:347] Tokenizer SentencePieceTokenizer initialized with 1024 tokens
[NeMo I 2026-01-22 23:14:14 mixins:347] Tokenizer SentencePieceTokenizer initialized with 3000 tokens
[NeMo I 2026-01-22 23:14:14 aggregate_tokenizer:73] Aggregate vocab size: 4024
[NeMo W 2026-01-22 23:14:19 modelPT:188] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.
    Train config : 
    manifest_filepath: data/training/v2/master_manifest.json
    sample_rate: 16000
    batch_size: 32
    shuffle: true
    num_workers: 16
    pin_memory: true
    use_start_end_token: false
    min_duration: 1.5
    max_duration: 40.0
    prefetch_factor: 4
    
[NeMo W 2026-01-22 23:14:19 modelPT:195] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). 
    Validation config : 
    manifest_filepath:
    - /mnt/data/asr-finetuning/evaluation/benchmarking/data/v1/en_clean_read.json
    - /mnt/data/asr-finetuning/evaluation/benchmarking/data/v1/kn_clean_read.json
    sample_rate: 16000
    batch_size: 32
    shuffle: false
    num_workers: 16
    
[NeMo W 2026-01-22 23:14:19 modelPT:202] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).
    Test config : 
    manifest_filepath: null
    sample_rate: 16000
    batch_size: 16
    shuffle: false
    num_workers: 8
    pin_memory: true
    use_start_end_token: false
    
[NeMo I 2026-01-22 23:14:20 rnnt_models:226] Using RNNT Loss : warprnnt_numba
    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}
[NeMo I 2026-01-22 23:14:20 rnnt_models:226] Using RNNT Loss : warprnnt_numba
    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}
[NeMo W 2026-01-22 23:14:21 label_looping_base:123] No conditional node support for Cuda.
    Cuda graphs with while loops are disabled, decoding speed will be slower
    Reason: Driver supports cuda toolkit version 12.4, but the driver needs to support at least 12,6. Please update your cuda driver.
[NeMo I 2026-01-22 23:14:21 rnnt_models:226] Using RNNT Loss : warprnnt_numba
    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}
[NeMo W 2026-01-22 23:14:21 label_looping_base:123] No conditional node support for Cuda.
    Cuda graphs with while loops are disabled, decoding speed will be slower
    Reason: Driver supports cuda toolkit version 12.4, but the driver needs to support at least 12,6. Please update your cuda driver.
[NeMo I 2026-01-22 23:14:22 save_restore_connector:285] Model EncDecHybridRNNTCTCBPEModel was successfully restored from /mnt/data/asr-finetuning/training/models/kathbath_hybrid_h200_scaleup_p3_phase3_final.nemo.
 Pre-computing logits for 128 files...
100%|| 128/128 [00:07<00:00, 16.02it/s]
 Extracting Vocab & Loading KenLM...
    Vocab Size: 4024

==================================================
 STARTING GRID SEARCH
==================================================
Alpha    | Beta     | WER      | CER     
--------------------------------------------------
Loading the LM will be faster if you build a binary file.
Reading /mnt/data/asr-finetuning/data/training/wiki_6gram.arpa
----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100
****************************************************************************************************
Unigrams and labels don't seem to agree.
0.1      | 0.0      | 33.45%   | 10.41%
0.1      | 0.5      | 34.37%   | 10.43%
0.1      | 1.0      | 35.71%   | 10.19%
0.1      | 2.0      | 40.81%   | 10.42%
0.1      | 3.0      | 51.91%   | 12.09%
Loading the LM will be faster if you build a binary file.
Reading /mnt/data/asr-finetuning/data/training/wiki_6gram.arpa
----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100
****************************************************************************************************
Unigrams and labels don't seem to agree.
0.4      | 0.0      | 31.97%   | 13.86%
0.4      | 0.5      | 31.40%   | 13.16%
0.4      | 1.0      | 32.04%   | 12.43%
0.4      | 2.0      | 31.97%   | 11.56%
0.4      | 3.0      | 33.52%   | 10.85%
Loading the LM will be faster if you build a binary file.
Reading /mnt/data/asr-finetuning/data/training/wiki_6gram.arpa
----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100
****************************************************************************************************
Unigrams and labels don't seem to agree.
0.6      | 0.0      | 34.51%   | 18.08%
0.6      | 0.5      | 33.59%   | 17.10%
0.6      | 1.0      | 32.89%   | 16.05%
0.6      | 2.0      | 32.53%   | 14.39%
0.6      | 3.0      | 32.32%   | 12.71%
Loading the LM will be faster if you build a binary file.
Reading /mnt/data/asr-finetuning/data/training/wiki_6gram.arpa
----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100
****************************************************************************************************
Unigrams and labels don't seem to agree.
0.8      | 0.0      | 39.25%   | 22.31%
0.8      | 0.5      | 38.26%   | 21.56%
0.8      | 1.0      | 37.06%   | 20.15%
0.8      | 2.0      | 36.21%   | 18.23%
0.8      | 3.0      | 34.37%   | 16.01%
Loading the LM will be faster if you build a binary file.
Reading /mnt/data/asr-finetuning/data/training/wiki_6gram.arpa
----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100
****************************************************************************************************
Unigrams and labels don't seem to agree.
1.0      | 0.0      | 43.71%   | 25.60%
1.0      | 0.5      | 41.94%   | 24.53%
1.0      | 1.0      | 41.16%   | 23.82%
1.0      | 2.0      | 39.39%   | 22.40%
1.0      | 3.0      | 38.19%   | 20.49%
Loading the LM will be faster if you build a binary file.
Reading /mnt/data/asr-finetuning/data/training/wiki_6gram.arpa
----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100
****************************************************************************************************
Unigrams and labels don't seem to agree.
1.5      | 0.0      | 53.11%   | 30.98%
1.5      | 0.5      | 52.48%   | 30.75%
1.5      | 1.0      | 51.98%   | 30.45%
1.5      | 2.0      | 49.79%   | 29.16%
1.5      | 3.0      | 48.16%   | 28.33%
==================================================
 BEST RESULT: WER 31.40%
   Alpha: 0.4
   Beta:  0.5
==================================================

 QUALITATIVE CHECK (Best Settings)

Example 1:
Ref:          
Pred:        

Example 2:
Ref:          
Pred:        

Example 3:
Ref:               
Pred:              
^C
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# ^C
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# python - <<'EOF'
import sys
from nemo.collections.asr.models import EncDecHybridRNNTCTCBPEModel

# CONFIG
MODEL_PATH = "training/models/kathbath_hybrid_h200_scaleup_p3_phase3_final.nemo"
KENLM_PATH = "data/training/wiki_6gram.arpa"

def get_model_alphabet(model_path):
    print(f" Loading Model: {model_path}...")
    model = EncDecHybridRNNTCTCBPEModel.restore_from(model_path, map_location="cpu")
    
    vocab_set = set()
    
    # Extract all characters from all BPE tokens
    if hasattr(model, 'tokenizer'):
        vocab_size = model.tokenizer.vocab_size
        for i in range(vocab_size):
            try:
                # Get the raw token (e.g. " hello" or "_ka")
                if hasattr(model.tokenizer, 'ids_to_tokens'):
                    token = model.tokenizer.ids_to_tokens([i])[0]
                else:
                    token = model.tokenizer.tokenizer.id_to_piece(i)
                
                # Add every character in this token to the set
                for char in token:
                    vocab_set.add(char)
            except:
                pass
    return vocab_set

def get_kenlm_alphabet(arpa_path):
    print(f" Reading KenLM: {arpa_path}...")
    arpa_chars = set()
    
    # Scan the "1-grams" (Unigrams) section of the ARPA file
    with open(arpa_path, 'r', encoding='utf-8') as f:
        reading_unigrams = False
        for line in f:
            line = line.strip()
            if "\\1-grams:" in line:
                reading_unigrams = True
                continue
            if "\\2-grams:" in line:
                break
            
            if reading_unigrams and line:
                parts = line.split('\t')
                if len(parts) > 1:
                    word = parts[1]
                    # Add every character from the word
                    for char in word:
                        arpa_chars.add(char)
    return arpa_chars

# --- RUN FORENSICS ---
model_chars = get_model_alphabet(MODEL_PATH)
EOFnt("="*50) FATAL: Could not read characters from KenLM. Is the ARPA file valid?")or is NO)'}")
fused_indices_to_multihot has reached end of life. Please migrate to a non-experimental function.
OneLogger: Setting error_handling_strategy to DISABLE_QUIETLY_AND_REPORT_METRIC_ERROR for rank (rank=0) with OneLogger disabled. To override: explicitly set error_handling_strategy parameter.
No exporters were provided. This means that no telemetry data will be collected.
 Loading Model: training/models/kathbath_hybrid_h200_scaleup_p3_phase3_final.nemo...
[NeMo I 2026-01-22 23:23:32 mixins:208] _setup_tokenizer: detected an aggregate tokenizer
[NeMo I 2026-01-22 23:23:32 mixins:347] Tokenizer SentencePieceTokenizer initialized with 1024 tokens
[NeMo I 2026-01-22 23:23:32 mixins:347] Tokenizer SentencePieceTokenizer initialized with 3000 tokens
[NeMo I 2026-01-22 23:23:32 aggregate_tokenizer:73] Aggregate vocab size: 4024
[NeMo W 2026-01-22 23:23:37 modelPT:188] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.
    Train config : 
    manifest_filepath: data/training/v2/master_manifest.json
    sample_rate: 16000
    batch_size: 32
    shuffle: true
    num_workers: 16
    pin_memory: true
    use_start_end_token: false
    min_duration: 1.5
    max_duration: 40.0
    prefetch_factor: 4
    
[NeMo W 2026-01-22 23:23:37 modelPT:195] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). 
    Validation config : 
    manifest_filepath:
    - /mnt/data/asr-finetuning/evaluation/benchmarking/data/v1/en_clean_read.json
    - /mnt/data/asr-finetuning/evaluation/benchmarking/data/v1/kn_clean_read.json
    sample_rate: 16000
    batch_size: 32
    shuffle: false
    num_workers: 16
    
[NeMo W 2026-01-22 23:23:37 modelPT:202] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).
    Test config : 
    manifest_filepath: null
    sample_rate: 16000
    batch_size: 16
    shuffle: false
    num_workers: 8
    pin_memory: true
    use_start_end_token: false
    
[NeMo I 2026-01-22 23:23:39 rnnt_models:226] Using RNNT Loss : warprnnt_numba
    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}
[NeMo I 2026-01-22 23:23:39 rnnt_models:226] Using RNNT Loss : warprnnt_numba
    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}
[NeMo W 2026-01-22 23:23:39 label_looping_base:123] No conditional node support for Cuda.
    Cuda graphs with while loops are disabled, decoding speed will be slower
    Reason: Driver supports cuda toolkit version 12.4, but the driver needs to support at least 12,6. Please update your cuda driver.
[NeMo I 2026-01-22 23:23:39 rnnt_models:226] Using RNNT Loss : warprnnt_numba
    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}
[NeMo W 2026-01-22 23:23:39 label_looping_base:123] No conditional node support for Cuda.
    Cuda graphs with while loops are disabled, decoding speed will be slower
    Reason: Driver supports cuda toolkit version 12.4, but the driver needs to support at least 12,6. Please update your cuda driver.
[NeMo I 2026-01-22 23:23:40 save_restore_connector:285] Model EncDecHybridRNNTCTCBPEModel was successfully restored from /mnt/data/asr-finetuning/training/models/kathbath_hybrid_h200_scaleup_p3_phase3_final.nemo.
 Reading KenLM: data/training/wiki_6gram.arpa...

==================================================
 ALPHABET FORENSICS REPORT
==================================================
Checking for SentencePiece Underscore (U+2581)...
   In Model?   YES
   In KenLM?   NO (Expected behavior is NO)
Checking for Standard Space (U+0020)...
   In Model?   NO
   In KenLM?   NO

Comparing Kannada Characters...
 Kannada character coverage looks good (Model  KenLM).
==================================================
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# python - <<'EOF'
import argparse
import json
import torch
import os
import jiwer
import numpy as np
import librosa
from nemo.collections.asr.models import EncDecHybridRNNTCTCBPEModel
from tqdm import tqdm

try:
    from pyctcdecode import build_ctcdecoder
except ImportError:
    print(" Error: pyctcdecode not found. Run: pip install pyctcdecode")
    exit(1)

# --- CONFIG ---
DEFAULT_MODEL = "training/models/kathbath_hybrid_h200_scaleup_p3_phase3_final.nemo"
DEFAULT_KENLM = "data/training/wiki_6gram.arpa"
DEFAULT_MANIFEST = "evaluation/benchmarking/curation/test_data/Kathbath/test_manifest.json"
SUBSET_SIZE = 128

# --- THE FIX: VOCABULARY TRANSLATION ---
def get_translated_vocab(model):
    """
    Extracts vocabulary and TRANSLATES SentencePiece '_' to Space ' '.
    This aligns the Model's alphabet with KenLM's alphabet.
    """
    vocab_raw = []
    
    # 1. Extract Raw Tokens (with underscores)
    if hasattr(model, 'tokenizer') and hasattr(model.tokenizer, 'ids_to_tokens'):
        vocab_size = model.tokenizer.vocab_size
        for i in range(vocab_size):
            try:
                tokens = model.tokenizer.ids_to_tokens([i])
                vocab_raw.append(tokens[0] if tokens else str(i))
            except:
                vocab_raw.append(f"<unk_{i}>")
    else:
        # Fallback for other tokenizer types
        vocab_size = model.tokenizer.vocab_size
        for i in range(vocab_size):
            vocab_raw.append(model.tokenizer.ids_to_text([i]))

    # 2. Translate & Deduplicate
    vocab_final = []
    seen_counts = {}
    
    print("     Translating Vocab: U+2581 (_) -> U+0020 (Space)...")
    
    for token in vocab_raw:
        # --- THE TRANSLATION STEP ---
        # Replace SentencePiece underscore (U+2581) with standard space
        clean_token = token.replace("\u2581", " ")
        
        # Deduplicate (renaming duplicates to keep list size identical)
EOF run_grid_search()n__":t_preds[i]}")s))):f}%"):.2f}%")64).numpy())_len)in))
fused_indices_to_multihot has reached end of life. Please migrate to a non-experimental function.
OneLogger: Setting error_handling_strategy to DISABLE_QUIETLY_AND_REPORT_METRIC_ERROR for rank (rank=0) with OneLogger disabled. To override: explicitly set error_handling_strategy parameter.
No exporters were provided. This means that no telemetry data will be collected.
 Device: cuda
 Loading Model...
[NeMo I 2026-01-22 23:26:01 mixins:208] _setup_tokenizer: detected an aggregate tokenizer
[NeMo I 2026-01-22 23:26:01 mixins:347] Tokenizer SentencePieceTokenizer initialized with 1024 tokens
[NeMo I 2026-01-22 23:26:01 mixins:347] Tokenizer SentencePieceTokenizer initialized with 3000 tokens
[NeMo I 2026-01-22 23:26:01 aggregate_tokenizer:73] Aggregate vocab size: 4024
[NeMo W 2026-01-22 23:26:05 modelPT:188] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.
    Train config : 
    manifest_filepath: data/training/v2/master_manifest.json
    sample_rate: 16000
    batch_size: 32
    shuffle: true
    num_workers: 16
    pin_memory: true
    use_start_end_token: false
    min_duration: 1.5
    max_duration: 40.0
    prefetch_factor: 4
    
[NeMo W 2026-01-22 23:26:05 modelPT:195] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). 
    Validation config : 
    manifest_filepath:
    - /mnt/data/asr-finetuning/evaluation/benchmarking/data/v1/en_clean_read.json
    - /mnt/data/asr-finetuning/evaluation/benchmarking/data/v1/kn_clean_read.json
    sample_rate: 16000
    batch_size: 32
    shuffle: false
    num_workers: 16
    
[NeMo W 2026-01-22 23:26:05 modelPT:202] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).
    Test config : 
    manifest_filepath: null
    sample_rate: 16000
    batch_size: 16
    shuffle: false
    num_workers: 8
    pin_memory: true
    use_start_end_token: false
    
[NeMo I 2026-01-22 23:26:07 rnnt_models:226] Using RNNT Loss : warprnnt_numba
    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}
[NeMo I 2026-01-22 23:26:07 rnnt_models:226] Using RNNT Loss : warprnnt_numba
    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}
[NeMo W 2026-01-22 23:26:07 label_looping_base:123] No conditional node support for Cuda.
    Cuda graphs with while loops are disabled, decoding speed will be slower
    Reason: Driver supports cuda toolkit version 12.4, but the driver needs to support at least 12,6. Please update your cuda driver.
[NeMo I 2026-01-22 23:26:08 rnnt_models:226] Using RNNT Loss : warprnnt_numba
    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}
[NeMo W 2026-01-22 23:26:08 label_looping_base:123] No conditional node support for Cuda.
    Cuda graphs with while loops are disabled, decoding speed will be slower
    Reason: Driver supports cuda toolkit version 12.4, but the driver needs to support at least 12,6. Please update your cuda driver.
[NeMo I 2026-01-22 23:26:09 save_restore_connector:285] Model EncDecHybridRNNTCTCBPEModel was successfully restored from /mnt/data/asr-finetuning/training/models/kathbath_hybrid_h200_scaleup_p3_phase3_final.nemo.
 Pre-computing logits for 128 files...
100%|| 128/128 [00:08<00:00, 15.62it/s]
 Loading KenLM & Translating Vocab...
     Translating Vocab: U+2581 (_) -> U+0020 (Space)...
    Vocab Size: 4024

==================================================
 STARTING GRID SEARCH (TRANSLATED VOCAB)
==================================================
Alpha    | Beta     | WER     
--------------------------------------------------
Loading the LM will be faster if you build a binary file.
Reading /mnt/data/asr-finetuning/data/training/wiki_6gram.arpa
----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100
****************************************************************************************************
Found entries of length > 1 in alphabet. This is unusual unless style is BPE, but the alphabet was not recognized as BPE type. Is this correct?
Unigrams and labels don't seem to agree.
0.1      | 0.0      | 71.36%
0.1      | 1.0      | 71.36%
0.1      | 2.0      | 71.36%
0.1      | 3.0      | 71.36%
Loading the LM will be faster if you build a binary file.
Reading /mnt/data/asr-finetuning/data/training/wiki_6gram.arpa
----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100
****************************************************************************************************
Found entries of length > 1 in alphabet. This is unusual unless style is BPE, but the alphabet was not recognized as BPE type. Is this correct?
Unigrams and labels don't seem to agree.
0.5      | 0.0      | 71.36%
0.5      | 1.0      | 71.36%
0.5      | 2.0      | 71.36%
0.5      | 3.0      | 71.36%
Loading the LM will be faster if you build a binary file.
Reading /mnt/data/asr-finetuning/data/training/wiki_6gram.arpa
----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100
****************************************************************************************************
Found entries of length > 1 in alphabet. This is unusual unless style is BPE, but the alphabet was not recognized as BPE type. Is this correct?
Unigrams and labels don't seem to agree.
0.8      | 0.0      | 71.36%
^CTraceback (most recent call last):
  File "<stdin>", line 185, in <module>
  File "<stdin>", line 158, in run_grid_search
  File "/mnt/data/asr-env/lib/python3.12/site-packages/pyctcdecode/decoder.py", line 716, in decode
    decoded_beams = self.decode_beams(
                    ^^^^^^^^^^^^^^^^^^
  File "/mnt/data/asr-env/lib/python3.12/site-packages/pyctcdecode/decoder.py", line 596, in decode_beams
    decoded_beams = self._decode_logits(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/mnt/data/asr-env/lib/python3.12/site-packages/pyctcdecode/decoder.py", line 512, in _decode_logits
    scored_beams = self._get_lm_beams(
                   ^^^^^^^^^^^^^^^^^^^
  File "/mnt/data/asr-env/lib/python3.12/site-packages/pyctcdecode/decoder.py", line 370, in _get_lm_beams
    cached_partial_token_scores[word_part] = language_model.score_partial_token(
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/data/asr-env/lib/python3.12/site-packages/pyctcdecode/language_model.py", line 301, in score_partial_token
    is_oov = int(self._char_trie.has_node(partial_token) == 0)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt
^Z
[1]+  Stopped                 python - <<'EOF'
import argparse
import json
import torch
import os
import jiwer
import numpy as np
import librosa
from nemo.collections.asr.models import EncDecHybridRNNTCTCBPEModel
from tqdm import tqdm

try:
    from pyctcdecode import build_ctcdecoder
except ImportError:
    print(" Error: pyctcdecode not found. Run: pip install pyctcdecode")
    exit(1)

# --- CONFIG ---
DEFAULT_MODEL = "training/models/kathbath_hybrid_h200_scaleup_p3_phase3_final.nemo"
DEFAULT_KENLM = "data/training/wiki_6gram.arpa"
DEFAULT_MANIFEST = "evaluation/benchmarking/curation/test_data/Kathbath/test_manifest.json"
SUBSET_SIZE = 128

# --- THE FIX: VOCABULARY TRANSLATION ---
def get_translated_vocab(model):
    """
    Extracts vocabulary and TRANSLATES SentencePiece '_' to Space ' '.
    This aligns the Model's alphabet with KenLM's alphabet.
    """
    vocab_raw = []
    
    # 1. Extract Raw Tokens (with underscores)
    if hasattr(model, 'tokenizer') and hasattr(model.tokenizer, 'ids_to_tokens'):
        vocab_size = model.tokenizer.vocab_size
        for i in range(vocab_size):
            try:
                tokens = model.tokenizer.ids_to_tokens([i])
                vocab_raw.append(tokens[0] if tokens else str(i))
            except:
                vocab_raw.append(f"<unk_{i}>")
    else:
        # Fallback for other tokenizer types
        vocab_size = model.tokenizer.vocab_size
        for i in range(vocab_size):
            vocab_raw.append(model.tokenizer.ids_to_text([i]))

    # 2. Translate & Deduplicate
    vocab_final = []
    seen_counts = {}
    
    print("     Translating Vocab: U+2581 (_) -> U+0020 (Space)...")
    
    for token in vocab_raw:
        # --- THE TRANSLATION STEP ---
        # Replace SentencePiece underscore (U+2581) with standard space
        clean_token = token.replace("\u2581", " ")
        
        # Deduplicate (renaming duplicates to keep list size identical)
        if clean_token in seen_counts:
            seen_counts[clean_token] += 1
            vocab_final.append(f"{clean_token}_dup{seen_counts[clean_token]}")
        else:
            seen_counts[clean_token] = 0
            vocab_final.append(clean_token)
            
    return vocab_final

def load_audio(path):
    try:
        audio, _ = librosa.load(path, sr=16000)
        return torch.tensor(audio, dtype=torch.float32), len(audio)
    except:
        return None, 0

def parse_args():
    parser = argparse.ArgumentParser()
    parser.add_argument("--model", type=str, default=DEFAULT_MODEL)
    parser.add_argument("--kenlm", type=str, default=DEFAULT_KENLM)
    parser.add_argument("--manifest", type=str, default=DEFAULT_MANIFEST)
    parser.add_argument("--subset", type=int, default=SUBSET_SIZE)
    return parser.parse_args()

def run_grid_search():
    args = parse_args()
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f" Device: {device}")

    # 1. Load Model
    print(f" Loading Model...")
    model = EncDecHybridRNNTCTCBPEModel.restore_from(args.model)
    model.eval()
    model.freeze()
    model = model.to(device)

    # 2. Get Logits
    print(f" Pre-computing logits for {args.subset} files...")
    filepaths, references = [], []
    with open(args.manifest, 'r', encoding='utf-8') as f:
        for line in f:
            if len(filepaths) >= args.subset: break
            item = json.loads(line)
            filepaths.append(item['audio_filepath'])
            references.append(item.get('text', ''))

    all_logits = []
    with torch.no_grad():
        for path in tqdm(filepaths):
            tensor, length = load_audio(path)
            if tensor is None: 
                all_logits.append(None)
                continue
            t_in = tensor.unsqueeze(0).to(device)
            l_in = torch.tensor([length], device=device)
            p_sig, p_len = model.preprocessor(input_signal=t_in, length=l_in)
            enc, enc_len = model.encoder(audio_signal=p_sig, length=p_len)
            log_probs = model.ctc_decoder(encoder_output=enc)
            valid_len = int(enc_len[0].item())
            all_logits.append(log_probs[0][:valid_len].cpu().numpy())

    # 3. Setup Decoder (Translated)
    print(f" Loading KenLM & Translating Vocab...")
    vocab = get_translated_vocab(model)
    print(f"    Vocab Size: {len(vocab)}")
    
    # 4. GRID SEARCH
    alphas = [0.1, 0.5, 0.8, 1.0, 1.5, 2.0]
    betas = [0.0, 1.0, 2.0, 3.0]
    
    print("\n" + "="*50)
    print(" STARTING GRID SEARCH (TRANSLATED VOCAB)")
    print("="*50)
    print(f"{'Alpha':<8} | {'Beta':<8} | {'WER':<8}")
    print("-" * 50)

    best_wer = 100.0
    best_params = (0, 0)
    best_preds = []

    for alpha in alphas:
        # Rebuild decoder occasionally to ensure clean state
        try:
            decoder = build_ctcdecoder(
                labels=vocab,
                kenlm_model_path=args.kenlm,
                alpha=alpha,
                beta=0.0
            )
        except Exception as e:
            print(f"Build Failed: {e}")
            continue

        for beta in betas:
            decoder.reset_params(alpha=alpha, beta=beta)
            preds = []
            valid_refs = []
            
            for i, logits in enumerate(all_logits):
                if logits is None: continue
                text = decoder.decode(logits, beam_width=64)
                preds.append(text)
                valid_refs.append(references[i])

            if not preds: continue
            wer = jiwer.wer(valid_refs, preds) * 100
            
            print(f"{alpha:<8} | {beta:<8} | {wer:.2f}%")
            
            if wer < best_wer:
                best_wer = wer
                best_params = (alpha, beta)
                best_preds = preds

    print("="*50)
    print(f" BEST RESULT: WER {best_wer:.2f}%")
    print(f"   Alpha: {best_params[0]}")
    print(f"   Beta:  {best_params[1]}")
    print("="*50)

    print("\n QUALITATIVE CHECK")
    for i in range(min(3, len(best_preds))):
        print(f"\nExample {i+1}:")
        print(f"Ref:  {valid_refs[i]}")
        print(f"Pred: {best_preds[i]}")

if __name__ == "__main__":
    run_grid_search()
EOF

(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# python - <<'EOF'
import sys
import unicodedata
from nemo.collections.asr.models import EncDecHybridRNNTCTCBPEModel

# CONFIG
MODEL_PATH = "training/models/kathbath_hybrid_h200_scaleup_p3_phase3_final.nemo"
KENLM_PATH = "data/training/wiki_6gram.arpa"

def normalize_char(c):
    """Returns the name of the character for debugging"""
    return unicodedata.name(c, "UNKNOWN")

def get_model_chars(model_path):
    print(f" Extracting chars from Model...")
    model = EncDecHybridRNNTCTCBPEModel.restore_from(model_path, map_location="cpu")
    chars = set()
    
    # robustly get raw tokens
    if hasattr(model, 'tokenizer') and hasattr(model.tokenizer, 'ids_to_tokens'):
        vocab_size = model.tokenizer.vocab_size
        for i in range(vocab_size):
            try:
                # Get raw token (e.g. "\u2581hello")
                token = model.tokenizer.ids_to_tokens([i])[0]
                # Add every unique character
                for c in token:
                    chars.add(c)
            except: pass
    else:
        print(" Could not read model tokenizer.")
    return chars

def get_kenlm_chars(arpa_path):
    print(f" Extracting chars from KenLM (Unigrams)...")
    chars = set()
    with open(arpa_path, 'r', encoding='utf-8') as f:
        read_uni = False
        for line in f:
            line = line.strip()
            if "\\1-grams:" in line: read_uni = True; continue
            if "\\2-grams:" in line: break
            if not read_uni or not line: continue
            
            # Format: probability <tab> word <tab> backoff
            parts = line.split('\t')
            if len(parts) > 1:
                word = parts[1]
                if word == "<unk>" or word == "<s>" or word == "</s>": continue
                for c in word:
                    chars.add(c)
    return chars

# --- EXECUTE ---
model_set = get_model_chars(MODEL_PATH)
kenlm_set = get_kenlm_chars(KENLM_PATH)

# Exclude the BPE marker from the comparison (we know it's missing)
EOFnt("="*60) No Kannada chars found in model??")else 'Not Normalized'}"))
fused_indices_to_multihot has reached end of life. Please migrate to a non-experimental function.
OneLogger: Setting error_handling_strategy to DISABLE_QUIETLY_AND_REPORT_METRIC_ERROR for rank (rank=0) with OneLogger disabled. To override: explicitly set error_handling_strategy parameter.
No exporters were provided. This means that no telemetry data will be collected.
 Extracting chars from Model...
[NeMo I 2026-01-22 23:30:21 mixins:208] _setup_tokenizer: detected an aggregate tokenizer
[NeMo I 2026-01-22 23:30:21 mixins:347] Tokenizer SentencePieceTokenizer initialized with 1024 tokens
[NeMo I 2026-01-22 23:30:21 mixins:347] Tokenizer SentencePieceTokenizer initialized with 3000 tokens
[NeMo I 2026-01-22 23:30:21 aggregate_tokenizer:73] Aggregate vocab size: 4024
[NeMo W 2026-01-22 23:30:26 modelPT:188] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.
    Train config : 
    manifest_filepath: data/training/v2/master_manifest.json
    sample_rate: 16000
    batch_size: 32
    shuffle: true
    num_workers: 16
    pin_memory: true
    use_start_end_token: false
    min_duration: 1.5
    max_duration: 40.0
    prefetch_factor: 4
    
[NeMo W 2026-01-22 23:30:26 modelPT:195] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). 
    Validation config : 
    manifest_filepath:
    - /mnt/data/asr-finetuning/evaluation/benchmarking/data/v1/en_clean_read.json
    - /mnt/data/asr-finetuning/evaluation/benchmarking/data/v1/kn_clean_read.json
    sample_rate: 16000
    batch_size: 32
    shuffle: false
    num_workers: 16
    
[NeMo W 2026-01-22 23:30:26 modelPT:202] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).
    Test config : 
    manifest_filepath: null
    sample_rate: 16000
    batch_size: 16
    shuffle: false
    num_workers: 8
    pin_memory: true
    use_start_end_token: false
    
[NeMo I 2026-01-22 23:30:28 rnnt_models:226] Using RNNT Loss : warprnnt_numba
    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}
[NeMo I 2026-01-22 23:30:28 rnnt_models:226] Using RNNT Loss : warprnnt_numba
    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}
[NeMo W 2026-01-22 23:30:28 label_looping_base:123] No conditional node support for Cuda.
    Cuda graphs with while loops are disabled, decoding speed will be slower
    Reason: Driver supports cuda toolkit version 12.4, but the driver needs to support at least 12,6. Please update your cuda driver.
[NeMo I 2026-01-22 23:30:29 rnnt_models:226] Using RNNT Loss : warprnnt_numba
    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}
[NeMo W 2026-01-22 23:30:29 label_looping_base:123] No conditional node support for Cuda.
    Cuda graphs with while loops are disabled, decoding speed will be slower
    Reason: Driver supports cuda toolkit version 12.4, but the driver needs to support at least 12,6. Please update your cuda driver.
[NeMo I 2026-01-22 23:30:29 save_restore_connector:285] Model EncDecHybridRNNTCTCBPEModel was successfully restored from /mnt/data/asr-finetuning/training/models/kathbath_hybrid_h200_scaleup_p3_phase3_final.nemo.
 Extracting chars from KenLM (Unigrams)...

============================================================
 THE MISMATCH REPORT
============================================================

 FOUND 37 'INTRUDER' CHARACTERS
These are produced by the Model but are INVISIBLE to KenLM.
----------------------------------------
   '''  (U+0027) : APOSTROPHE
   ','  (U+002C) : COMMA
   '/'  (U+002F) : SOLIDUS
   '<'  (U+003C) : LESS-THAN SIGN
   '>'  (U+003E) : GREATER-THAN SIGN
   'A'  (U+0041) : LATIN CAPITAL LETTER A
   'B'  (U+0042) : LATIN CAPITAL LETTER B
   'C'  (U+0043) : LATIN CAPITAL LETTER C
   'D'  (U+0044) : LATIN CAPITAL LETTER D
   'E'  (U+0045) : LATIN CAPITAL LETTER E
   'F'  (U+0046) : LATIN CAPITAL LETTER F
   'a'  (U+0061) : LATIN SMALL LETTER A
   'b'  (U+0062) : LATIN SMALL LETTER B
   'c'  (U+0063) : LATIN SMALL LETTER C
   'd'  (U+0064) : LATIN SMALL LETTER D
   'e'  (U+0065) : LATIN SMALL LETTER E
   'f'  (U+0066) : LATIN SMALL LETTER F
   'g'  (U+0067) : LATIN SMALL LETTER G
   'h'  (U+0068) : LATIN SMALL LETTER H
   'i'  (U+0069) : LATIN SMALL LETTER I
   'j'  (U+006A) : LATIN SMALL LETTER J
   'k'  (U+006B) : LATIN SMALL LETTER K
   'l'  (U+006C) : LATIN SMALL LETTER L
   'm'  (U+006D) : LATIN SMALL LETTER M
   'n'  (U+006E) : LATIN SMALL LETTER N
   'o'  (U+006F) : LATIN SMALL LETTER O
   'p'  (U+0070) : LATIN SMALL LETTER P
   'q'  (U+0071) : LATIN SMALL LETTER Q
   'r'  (U+0072) : LATIN SMALL LETTER R
   's'  (U+0073) : LATIN SMALL LETTER S
   't'  (U+0074) : LATIN SMALL LETTER T
   'u'  (U+0075) : LATIN SMALL LETTER U
   'v'  (U+0076) : LATIN SMALL LETTER V
   'w'  (U+0077) : LATIN SMALL LETTER W
   'x'  (U+0078) : LATIN SMALL LETTER X
   'y'  (U+0079) : LATIN SMALL LETTER Y
   'z'  (U+007A) : LATIN SMALL LETTER Z
----------------------------------------
 DIAGNOSIS: The decoder fails because it sees these ghosts.

 CHECKING KANNADA NORMALIZATION...
Traceback (most recent call last):
  File "<stdin>", line 83, in <module>
AttributeError: module 'unicodedata' has no attribute 'normalization_form'
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# nano fetch_wiki.py
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# rm fetch_wiki.py
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# nano fetch_wiki.py
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# # 1. Generate the text
python fetch_wiki_v2.py

# 2. Build KenLM (using the new file)
echo " Training Bilingual KenLM..."
kenlm/build/bin/lmplz -o 6 --prune 0 0 1 < data/training/wiki_corpus_multilingual.txt > data/training/wiki_mixed_6gram.arpa

echo " Created: data/training/wiki_mixed_6gram.arpa"
python: can't open file '/mnt/data/asr-finetuning/fetch_wiki_v2.py': [Errno 2] No such file or directory
 Training Bilingual KenLM...
bash: data/training/wiki_corpus_multilingual.txt: No such file or directory
 Created: data/training/wiki_mixed_6gram.arpa
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# python fetch_wiki.py
  Loading Dataset: wikipedia...
Downloading readme: 131kB [00:00, 76.8MB/s]
 Extracting Mixed Text (Kannada + English) to data/training/wiki_corpus_multilingual.txt...
100%|| 31437/31437 [00:16<00:00, 1921.44it/s]
 Success! Saved 1554678 sentences.
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# echo " Training Bilingual KenLM..."
kenlm/build/bin/lmplz -o 6 --prune 0 0 1 < data/training/wiki_corpus_multilingual.txt > data/training/wiki_mixed_6gram.arpa
 Training Bilingual KenLM...
=== 1/5 Counting and sorting n-grams ===
Reading /mnt/data/asr-finetuning/data/training/wiki_corpus_multilingual.txt
----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100
****************************************************************************************************
Unigram tokens 17138453 types 1730403
=== 2/5 Calculating and sorting adjusted counts ===
Chain sizes: 1:20764836 2:13303197696 3:24943497216 4:39909593088 5:58201493504 6:79819186176
Statistics:
1 1730403 D1=0.747622 D2=1.03691 D3+=1.3078
2 10395478 D1=0.866236 D2=1.16099 D3+=1.33111
3 887516/14748363 D1=0.951041 D2=1.32966 D3+=1.40218
4 443839/14570733 D1=0.982229 D2=1.53377 D3+=1.59601
5 298461/13346819 D1=0.990618 D2=1.65715 D3+=1.69266
6 230609/11968683 D1=0.967094 D2=1.74519 D3+=1.84074
Memory estimate for binary LM:
type     MB
probing 322 assuming -p 1.5
probing 397 assuming -r models -p 1.5
trie    189 without quantization
trie    121 assuming -q 8 -b 8 quantization 
trie    166 assuming -a 22 array pointer compression
trie     98 assuming -a 22 -q 8 -b 8 array pointer compression and quantization
=== 3/5 Calculating and sorting initial probabilities ===
Chain sizes: 1:20764836 2:166327648 3:17750320 4:10652136 5:8356908 6:7379488
----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100
*###################################################################################################
=== 4/5 Calculating and writing order-interpolated probabilities ===
Chain sizes: 1:20764836 2:166327648 3:17750320 4:10652136 5:8356908 6:7379488
----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100
####################################################################################################
=== 5/5 Writing ARPA model ===
----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100
****************************************************************************************************
Name:lmplz	VmPeak:211318924 kB	VmRSS:140320 kB	RSSMax:33864744 kB	user:34.2171	sys:33.7989	CPU:68.016	real:47.9602
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# nano run_grid_search.py
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# python run_grid_search.py \
  --kenlm "data/training/wiki_mixed_6gram.arpa"
fused_indices_to_multihot has reached end of life. Please migrate to a non-experimental function.
OneLogger: Setting error_handling_strategy to DISABLE_QUIETLY_AND_REPORT_METRIC_ERROR for rank (rank=0) with OneLogger disabled. To override: explicitly set error_handling_strategy parameter.
No exporters were provided. This means that no telemetry data will be collected.
 Device: cuda
 Loading Model...
[NeMo I 2026-01-22 23:35:29 mixins:208] _setup_tokenizer: detected an aggregate tokenizer
[NeMo I 2026-01-22 23:35:29 mixins:347] Tokenizer SentencePieceTokenizer initialized with 1024 tokens
[NeMo I 2026-01-22 23:35:29 mixins:347] Tokenizer SentencePieceTokenizer initialized with 3000 tokens
[NeMo I 2026-01-22 23:35:29 aggregate_tokenizer:73] Aggregate vocab size: 4024
[NeMo W 2026-01-22 23:35:33 modelPT:188] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.
    Train config : 
    manifest_filepath: data/training/v2/master_manifest.json
    sample_rate: 16000
    batch_size: 32
    shuffle: true
    num_workers: 16
    pin_memory: true
    use_start_end_token: false
    min_duration: 1.5
    max_duration: 40.0
    prefetch_factor: 4
    
[NeMo W 2026-01-22 23:35:33 modelPT:195] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). 
    Validation config : 
    manifest_filepath:
    - /mnt/data/asr-finetuning/evaluation/benchmarking/data/v1/en_clean_read.json
    - /mnt/data/asr-finetuning/evaluation/benchmarking/data/v1/kn_clean_read.json
    sample_rate: 16000
    batch_size: 32
    shuffle: false
    num_workers: 16
    
[NeMo W 2026-01-22 23:35:33 modelPT:202] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).
    Test config : 
    manifest_filepath: null
    sample_rate: 16000
    batch_size: 16
    shuffle: false
    num_workers: 8
    pin_memory: true
    use_start_end_token: false
    
[NeMo I 2026-01-22 23:35:35 rnnt_models:226] Using RNNT Loss : warprnnt_numba
    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}
[NeMo I 2026-01-22 23:35:35 rnnt_models:226] Using RNNT Loss : warprnnt_numba
    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}
[NeMo W 2026-01-22 23:35:35 label_looping_base:123] No conditional node support for Cuda.
    Cuda graphs with while loops are disabled, decoding speed will be slower
    Reason: Driver supports cuda toolkit version 12.4, but the driver needs to support at least 12,6. Please update your cuda driver.
[NeMo I 2026-01-22 23:35:36 rnnt_models:226] Using RNNT Loss : warprnnt_numba
    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}
[NeMo W 2026-01-22 23:35:36 label_looping_base:123] No conditional node support for Cuda.
    Cuda graphs with while loops are disabled, decoding speed will be slower
    Reason: Driver supports cuda toolkit version 12.4, but the driver needs to support at least 12,6. Please update your cuda driver.
[NeMo I 2026-01-22 23:35:37 save_restore_connector:285] Model EncDecHybridRNNTCTCBPEModel was successfully restored from /mnt/data/asr-finetuning/training/models/kathbath_hybrid_h200_scaleup_p3_phase3_final.nemo.
 Pre-computing logits for 128 files...
100%|| 128/128 [00:07<00:00, 16.19it/s]
 Loading KenLM & Translating Vocab...
     Translating Vocab: U+2581 (_) -> U+0020 (Space)...
    Vocab Size: 4024

==================================================
 STARTING GRID SEARCH (TRANSLATED VOCAB)
==================================================
Alpha    | Beta     | WER     
--------------------------------------------------
Loading the LM will be faster if you build a binary file.
Reading /mnt/data/asr-finetuning/data/training/wiki_mixed_6gram.arpa
----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100
****************************************************************************************************
Found entries of length > 1 in alphabet. This is unusual unless style is BPE, but the alphabet was not recognized as BPE type. Is this correct?
Unigrams and labels don't seem to agree.
0.1      | 0.0      | 71.36%
0.1      | 1.0      | 71.36%
0.1      | 2.0      | 71.36%
0.1      | 3.0      | 71.36%
Loading the LM will be faster if you build a binary file.
Reading /mnt/data/asr-finetuning/data/training/wiki_mixed_6gram.arpa
----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100
****************************************************************************************************
Found entries of length > 1 in alphabet. This is unusual unless style is BPE, but the alphabet was not recognized as BPE type. Is this correct?
Unigrams and labels don't seem to agree.
^C^Z
[2]+  Stopped                 python run_grid_search.py --kenlm "data/training/wiki_mixed_6gram.arpa"
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# nano run_grid_search.py
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# rm run_grid_search.py
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# nano run_grid_search.py
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# python run_grid_search_final.py --kenlm "data/training/wiki_mixed_6gram.arpa"
python: can't open file '/mnt/data/asr-finetuning/run_grid_search_final.py': [Errno 2] No such file or directory
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# python run_grid_search.py --kenlm "data/training/wiki_mixed_6gram.arpa"
fused_indices_to_multihot has reached end of life. Please migrate to a non-experimental function.
OneLogger: Setting error_handling_strategy to DISABLE_QUIETLY_AND_REPORT_METRIC_ERROR for rank (rank=0) with OneLogger disabled. To override: explicitly set error_handling_strategy parameter.
No exporters were provided. This means that no telemetry data will be collected.
 Device: cuda
 KenLM: data/training/wiki_mixed_6gram.arpa
 Loading Model...
[NeMo I 2026-01-22 23:38:41 mixins:208] _setup_tokenizer: detected an aggregate tokenizer
[NeMo I 2026-01-22 23:38:41 mixins:347] Tokenizer SentencePieceTokenizer initialized with 1024 tokens
[NeMo I 2026-01-22 23:38:41 mixins:347] Tokenizer SentencePieceTokenizer initialized with 3000 tokens
[NeMo I 2026-01-22 23:38:41 aggregate_tokenizer:73] Aggregate vocab size: 4024
[NeMo W 2026-01-22 23:38:45 modelPT:188] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.
    Train config : 
    manifest_filepath: data/training/v2/master_manifest.json
    sample_rate: 16000
    batch_size: 32
    shuffle: true
    num_workers: 16
    pin_memory: true
    use_start_end_token: false
    min_duration: 1.5
    max_duration: 40.0
    prefetch_factor: 4
    
[NeMo W 2026-01-22 23:38:45 modelPT:195] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). 
    Validation config : 
    manifest_filepath:
    - /mnt/data/asr-finetuning/evaluation/benchmarking/data/v1/en_clean_read.json
    - /mnt/data/asr-finetuning/evaluation/benchmarking/data/v1/kn_clean_read.json
    sample_rate: 16000
    batch_size: 32
    shuffle: false
    num_workers: 16
    
[NeMo W 2026-01-22 23:38:45 modelPT:202] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).
    Test config : 
    manifest_filepath: null
    sample_rate: 16000
    batch_size: 16
    shuffle: false
    num_workers: 8
    pin_memory: true
    use_start_end_token: false
    
[NeMo I 2026-01-22 23:38:47 rnnt_models:226] Using RNNT Loss : warprnnt_numba
    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}
[NeMo I 2026-01-22 23:38:47 rnnt_models:226] Using RNNT Loss : warprnnt_numba
    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}
[NeMo W 2026-01-22 23:38:47 label_looping_base:123] No conditional node support for Cuda.
    Cuda graphs with while loops are disabled, decoding speed will be slower
    Reason: Driver supports cuda toolkit version 12.4, but the driver needs to support at least 12,6. Please update your cuda driver.
[NeMo I 2026-01-22 23:38:48 rnnt_models:226] Using RNNT Loss : warprnnt_numba
    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}
[NeMo W 2026-01-22 23:38:48 label_looping_base:123] No conditional node support for Cuda.
    Cuda graphs with while loops are disabled, decoding speed will be slower
    Reason: Driver supports cuda toolkit version 12.4, but the driver needs to support at least 12,6. Please update your cuda driver.
[NeMo I 2026-01-22 23:38:49 save_restore_connector:285] Model EncDecHybridRNNTCTCBPEModel was successfully restored from /mnt/data/asr-finetuning/training/models/kathbath_hybrid_h200_scaleup_p3_phase3_final.nemo.
 Pre-computing logits for 128 files...
100%|| 128/128 [00:07<00:00, 16.34it/s]
 Loading KenLM & Using RAW Vocab...
    Vocab Size: 4024

==================================================
 STARTING GRID SEARCH
==================================================
Alpha    | Beta     | WER     
--------------------------------------------------
Loading the LM will be faster if you build a binary file.
Reading /mnt/data/asr-finetuning/data/training/wiki_mixed_6gram.arpa
----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100
****************************************************************************************************
Unigrams and labels don't seem to agree.
0.3      | 0.5      | 31.40%
0.3      | 1.0      | 31.75%
0.3      | 2.0      | 32.89%
0.3      | 4.0      | 41.73%
Loading the LM will be faster if you build a binary file.
Reading /mnt/data/asr-finetuning/data/training/wiki_mixed_6gram.arpa
----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100
****************************************************************************************************
Unigrams and labels don't seem to agree.
0.5      | 0.5      | 33.17%
0.5      | 1.0      | 32.74%
0.5      | 2.0      | 32.25%
0.5      | 4.0      | 35.22%
Loading the LM will be faster if you build a binary file.
Reading /mnt/data/asr-finetuning/data/training/wiki_mixed_6gram.arpa
----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100
****************************************************************************************************
Unigrams and labels don't seem to agree.
0.7      | 0.5      | 35.79%
0.7      | 1.0      | 35.01%
0.7      | 2.0      | 34.16%
0.7      | 4.0      | 33.45%
Loading the LM will be faster if you build a binary file.
Reading /mnt/data/asr-finetuning/data/training/wiki_mixed_6gram.arpa
----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100
****************************************************************************************************
Unigrams and labels don't seem to agree.
1.0      | 0.5      | 42.57%
1.0      | 1.0      | 41.37%
1.0      | 2.0      | 39.39%
1.0      | 4.0      | 36.56%
Loading the LM will be faster if you build a binary file.
Reading /mnt/data/asr-finetuning/data/training/wiki_mixed_6gram.arpa
----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100
****************************************************************************************************
Unigrams and labels don't seem to agree.
1.5      | 0.5      | 52.90%
1.5      | 1.0      | 52.26%
1.5      | 2.0      | 50.42%
1.5      | 4.0      | 46.53%
Loading the LM will be faster if you build a binary file.
Reading /mnt/data/asr-finetuning/data/training/wiki_mixed_6gram.arpa
----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100
****************************************************************************************************
Unigrams and labels don't seem to agree.
2.0      | 0.5      | 57.28%
2.0      | 1.0      | 56.72%
2.0      | 2.0      | 56.08%
2.0      | 4.0      | 54.38%
==================================================
 BEST RESULT: WER 31.40%
   Alpha: 0.3
   Beta:  0.5
==================================================

 QUALITATIVE CHECK

Example 1:
Ref:          
Pred:         

Example 2:
Ref:          
Pred:        

Example 3:
Ref:               
Pred:              
python - <<'EOF'
import torch
from nemo.collections.asr.models import EncDecHybridRNNTCTCBPEModel
from tqdm import tqdm
import os

# CONFIG
MODEL_PATH = "training/models/kathbath_hybrid_h200_scaleup_p3_phase3_final.nemo"
INPUT_TEXT = "data/training/wiki_corpus_multilingual.txt"
OUTPUT_TOKENIZED = "data/training/wiki_tokenized.txt"

def tokenize_corpus():
    print(f" Loading Model Tokenizer from {MODEL_PATH}...")
    try:
        # Load model on CPU to save memory
        model = EncDecHybridRNNTCTCBPEModel.restore_from(MODEL_PATH, map_location="cpu")
        tokenizer = model.tokenizer
    except Exception as e:
        print(f" Failed to load model: {e}")
        return

    print(f" Reading {INPUT_TEXT}...")
    if not os.path.exists(INPUT_TEXT):
        print(" Input text file not found! Run fetch_wiki_v2.py first.")
        return

    print(f"  Tokenizing and writing to {OUTPUT_TOKENIZED}...")
    
    with open(INPUT_TEXT, 'r', encoding='utf-8') as fin, \
         open(OUTPUT_TOKENIZED, 'w', encoding='utf-8') as fout:
        
        # Process line by line
        for line in tqdm(fin):
            line = line.strip()
            if not line: continue
            
            # 1. Tokenize (Text -> IDs)
            ids = tokenizer.text_to_ids(line)
            
            # 2. Convert IDs back to BPE Tokens (IDs -> ["_he", "llo"])
            # We use the low-level API to ensure we get the raw pieces
            tokens = []
            if hasattr(tokenizer, 'ids_to_tokens'):
                tokens = tokenizer.ids_to_tokens(ids)
            elif hasattr(tokenizer, 'tokenizer') and hasattr(tokenizer.tokenizer, 'id_to_piece'):
                tokens = [tokenizer.tokenizer.id_to_piece(i) for i in ids]
            
            if tokens:
                # Join with SPACE so KenLM sees them as "words"
                # Example: "_hello" " _world" -> "_hello  _world"
                tokenized_line = " ".join(tokens)
                fout.write(tokenized_line + "\n")

    print(f" Done! Ready for KenLM training.")

if __name__ == "__main__":
    tokenize_corpus()
EOF
^Z
[3]+  Stopped                 python run_grid_search.py --kenlm "data/training/wiki_mixed_6gram.arpa"
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# python - <<'EOF'
import torch
from nemo.collections.asr.models import EncDecHybridRNNTCTCBPEModel
from tqdm import tqdm
import os

# CONFIG
MODEL_PATH = "training/models/kathbath_hybrid_h200_scaleup_p3_phase3_final.nemo"
INPUT_TEXT = "data/training/wiki_corpus_multilingual.txt"
OUTPUT_TOKENIZED = "data/training/wiki_tokenized.txt"

def tokenize_corpus():
    print(f" Loading Model Tokenizer from {MODEL_PATH}...")
    try:
        # Load model on CPU to save memory
        model = EncDecHybridRNNTCTCBPEModel.restore_from(MODEL_PATH, map_location="cpu")
        tokenizer = model.tokenizer
    except Exception as e:
        print(f" Failed to load model: {e}")
        return

    print(f" Reading {INPUT_TEXT}...")
    if not os.path.exists(INPUT_TEXT):
        print(" Input text file not found! Run fetch_wiki_v2.py first.")
        return

    print(f"  Tokenizing and writing to {OUTPUT_TOKENIZED}...")
    
    with open(INPUT_TEXT, 'r', encoding='utf-8') as fin, \
         open(OUTPUT_TOKENIZED, 'w', encoding='utf-8') as fout:
        
        # Process line by line
        for line in tqdm(fin):
            line = line.strip()
            if not line: continue
            
            # 1. Tokenize (Text -> IDs)
            ids = tokenizer.text_to_ids(line)
            
            # 2. Convert IDs back to BPE Tokens (IDs -> ["_he", "llo"])
            # We use the low-level API to ensure we get the raw pieces
            tokens = []
            if hasattr(tokenizer, 'ids_to_tokens'):
                tokens = tokenizer.ids_to_tokens(ids)
            elif hasattr(tokenizer, 'tokenizer') and hasattr(tokenizer.tokenizer, 'id_to_piece'):
                tokens = [tokenizer.tokenizer.id_to_piece(i) for i in ids]
            
            if tokens:
                # Join with SPACE so KenLM sees them as "words"
                # Example: "_hello" " _world" -> "_hello  _world"
                tokenized_line = " ".join(tokens)
                fout.write(tokenized_line + "\n")

    print(f" Done! Ready for KenLM training.")

if __name__ == "__main__":
    tokenize_corpus()
EOF
fused_indices_to_multihot has reached end of life. Please migrate to a non-experimental function.
OneLogger: Setting error_handling_strategy to DISABLE_QUIETLY_AND_REPORT_METRIC_ERROR for rank (rank=0) with OneLogger disabled. To override: explicitly set error_handling_strategy parameter.
No exporters were provided. This means that no telemetry data will be collected.
 Loading Model Tokenizer from training/models/kathbath_hybrid_h200_scaleup_p3_phase3_final.nemo...
[NeMo I 2026-01-22 23:52:10 mixins:208] _setup_tokenizer: detected an aggregate tokenizer
[NeMo I 2026-01-22 23:52:10 mixins:347] Tokenizer SentencePieceTokenizer initialized with 1024 tokens
[NeMo I 2026-01-22 23:52:10 mixins:347] Tokenizer SentencePieceTokenizer initialized with 3000 tokens
[NeMo I 2026-01-22 23:52:10 aggregate_tokenizer:73] Aggregate vocab size: 4024
[NeMo W 2026-01-22 23:52:14 modelPT:188] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.
    Train config : 
    manifest_filepath: data/training/v2/master_manifest.json
    sample_rate: 16000
    batch_size: 32
    shuffle: true
    num_workers: 16
    pin_memory: true
    use_start_end_token: false
    min_duration: 1.5
    max_duration: 40.0
    prefetch_factor: 4
    
[NeMo W 2026-01-22 23:52:14 modelPT:195] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). 
    Validation config : 
    manifest_filepath:
    - /mnt/data/asr-finetuning/evaluation/benchmarking/data/v1/en_clean_read.json
    - /mnt/data/asr-finetuning/evaluation/benchmarking/data/v1/kn_clean_read.json
    sample_rate: 16000
    batch_size: 32
    shuffle: false
    num_workers: 16
    
[NeMo W 2026-01-22 23:52:14 modelPT:202] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).
    Test config : 
    manifest_filepath: null
    sample_rate: 16000
    batch_size: 16
    shuffle: false
    num_workers: 8
    pin_memory: true
    use_start_end_token: false
    
[NeMo I 2026-01-22 23:52:16 rnnt_models:226] Using RNNT Loss : warprnnt_numba
    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}
[NeMo I 2026-01-22 23:52:16 rnnt_models:226] Using RNNT Loss : warprnnt_numba
    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}
[NeMo W 2026-01-22 23:52:16 label_looping_base:123] No conditional node support for Cuda.
    Cuda graphs with while loops are disabled, decoding speed will be slower
    Reason: Driver supports cuda toolkit version 12.4, but the driver needs to support at least 12,6. Please update your cuda driver.
[NeMo I 2026-01-22 23:52:17 rnnt_models:226] Using RNNT Loss : warprnnt_numba
    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}
[NeMo W 2026-01-22 23:52:17 label_looping_base:123] No conditional node support for Cuda.
    Cuda graphs with while loops are disabled, decoding speed will be slower
    Reason: Driver supports cuda toolkit version 12.4, but the driver needs to support at least 12,6. Please update your cuda driver.
[NeMo I 2026-01-22 23:52:17 save_restore_connector:285] Model EncDecHybridRNNTCTCBPEModel was successfully restored from /mnt/data/asr-finetuning/training/models/kathbath_hybrid_h200_scaleup_p3_phase3_final.nemo.
 Reading data/training/wiki_corpus_multilingual.txt...
  Tokenizing and writing to data/training/wiki_tokenized.txt...
0it [00:00, ?it/s]
Traceback (most recent call last):
  File "<stdin>", line 56, in <module>
  File "<stdin>", line 37, in tokenize_corpus
TypeError: AggregateTokenizer.text_to_ids() missing 1 required positional argument: 'lang_id'
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# python - <<'EOF'
import torch
from nemo.collections.asr.models import EncDecHybridRNNTCTCBPEModel
from tqdm import tqdm
import os

# CONFIG
MODEL_PATH = "training/models/kathbath_hybrid_h200_scaleup_p3_phase3_final.nemo"
INPUT_TEXT = "data/training/wiki_corpus_multilingual.txt"
OUTPUT_TOKENIZED = "data/training/wiki_tokenized.txt"

def tokenize_corpus():
    print(f" Loading Model Tokenizer from {MODEL_PATH}...")
    try:
        model = EncDecHybridRNNTCTCBPEModel.restore_from(MODEL_PATH, map_location="cpu")
        tokenizer = model.tokenizer
    except Exception as e:
        print(f" Failed to load model: {e}")
        return

    # --- FIX: DETECT LANGUAGE ID ---
    # AggregateTokenizer usually has a .langs attribute (e.g., ['kn', 'en'])
    lang_id = None
    if hasattr(tokenizer, 'langs') and tokenizer.langs:
        lang_id = tokenizer.langs[0]  # Pick the first available language (usually the primary)
        print(f" Detected Language ID: '{lang_id}'")
    else:
        # Fallback: Some older models use 'kannada' or just '0'
        lang_id = "kn" 
        print(f" Could not detect lang_id. Defaulting to: '{lang_id}'")

    print(f" Reading {INPUT_TEXT}...")
    if not os.path.exists(INPUT_TEXT):
        print(" Input text file not found! Run fetch_wiki_v2.py first.")
        return

    print(f"  Tokenizing and writing to {OUTPUT_TOKENIZED}...")
    
    with open(INPUT_TEXT, 'r', encoding='utf-8') as fin, \
         open(OUTPUT_TOKENIZED, 'w', encoding='utf-8') as fout:
        
        for line in tqdm(fin):
            line = line.strip()
            if not line: continue
            
            # --- FIX: PASS lang_id ARGUMENT ---
            try:
                # The crucial fix: explicitly passing the language ID
                ids = tokenizer.text_to_ids(line, lang_id=lang_id)
            except TypeError:
                # If that fails, try without (some versions differ) or with distinct API
                try:
                    ids = tokenizer.text_to_ids(line)
                except:
                    continue # Skip broken lines
            
            # Convert IDs -> Raw Tokens (preserving underscores)
            tokens = []
EOF tokenize_corpus()n__":ized text saved to {OUTPUT_TOKENIZED}")rds"
fused_indices_to_multihot has reached end of life. Please migrate to a non-experimental function.
OneLogger: Setting error_handling_strategy to DISABLE_QUIETLY_AND_REPORT_METRIC_ERROR for rank (rank=0) with OneLogger disabled. To override: explicitly set error_handling_strategy parameter.
No exporters were provided. This means that no telemetry data will be collected.
 Loading Model Tokenizer from training/models/kathbath_hybrid_h200_scaleup_p3_phase3_final.nemo...
[NeMo I 2026-01-22 23:54:18 mixins:208] _setup_tokenizer: detected an aggregate tokenizer
[NeMo I 2026-01-22 23:54:18 mixins:347] Tokenizer SentencePieceTokenizer initialized with 1024 tokens
[NeMo I 2026-01-22 23:54:18 mixins:347] Tokenizer SentencePieceTokenizer initialized with 3000 tokens
[NeMo I 2026-01-22 23:54:18 aggregate_tokenizer:73] Aggregate vocab size: 4024
[NeMo W 2026-01-22 23:54:22 modelPT:188] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.
    Train config : 
    manifest_filepath: data/training/v2/master_manifest.json
    sample_rate: 16000
    batch_size: 32
    shuffle: true
    num_workers: 16
    pin_memory: true
    use_start_end_token: false
    min_duration: 1.5
    max_duration: 40.0
    prefetch_factor: 4
    
[NeMo W 2026-01-22 23:54:22 modelPT:195] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). 
    Validation config : 
    manifest_filepath:
    - /mnt/data/asr-finetuning/evaluation/benchmarking/data/v1/en_clean_read.json
    - /mnt/data/asr-finetuning/evaluation/benchmarking/data/v1/kn_clean_read.json
    sample_rate: 16000
    batch_size: 32
    shuffle: false
    num_workers: 16
    
[NeMo W 2026-01-22 23:54:22 modelPT:202] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).
    Test config : 
    manifest_filepath: null
    sample_rate: 16000
    batch_size: 16
    shuffle: false
    num_workers: 8
    pin_memory: true
    use_start_end_token: false
    
[NeMo I 2026-01-22 23:54:24 rnnt_models:226] Using RNNT Loss : warprnnt_numba
    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}
[NeMo I 2026-01-22 23:54:24 rnnt_models:226] Using RNNT Loss : warprnnt_numba
    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}
[NeMo W 2026-01-22 23:54:24 label_looping_base:123] No conditional node support for Cuda.
    Cuda graphs with while loops are disabled, decoding speed will be slower
    Reason: Driver supports cuda toolkit version 12.4, but the driver needs to support at least 12,6. Please update your cuda driver.
[NeMo I 2026-01-22 23:54:24 rnnt_models:226] Using RNNT Loss : warprnnt_numba
    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}
[NeMo W 2026-01-22 23:54:24 label_looping_base:123] No conditional node support for Cuda.
    Cuda graphs with while loops are disabled, decoding speed will be slower
    Reason: Driver supports cuda toolkit version 12.4, but the driver needs to support at least 12,6. Please update your cuda driver.
[NeMo I 2026-01-22 23:54:25 save_restore_connector:285] Model EncDecHybridRNNTCTCBPEModel was successfully restored from /mnt/data/asr-finetuning/training/models/kathbath_hybrid_h200_scaleup_p3_phase3_final.nemo.
 Detected Language ID: 'en'
 Reading data/training/wiki_corpus_multilingual.txt...
  Tokenizing and writing to data/training/wiki_tokenized.txt...
1554678it [01:11, 21783.91it/s]
 Done! Tokenized text saved to data/training/wiki_tokenized.txt
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# kenlm/build/bin/lmplz -o 6 --prune 0 0 1 < data/training/wiki_tokenized.txt > data/training/wiki_subword_6gram.arpa
=== 1/5 Counting and sorting n-grams ===
Reading /mnt/data/asr-finetuning/data/training/wiki_tokenized.txt
----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100
/mnt/data/asr-finetuning/kenlm/lm/builder/corpus_count.cc:179 in void lm::builder::{anonymous}::ComplainDisallowed(StringPiece, lm::WarningAction&) threw FormatLoadException.
Special word <unk> is not allowed in the corpus.  I plan to support models containing <unk> in the future.  Pass --skip_symbols to convert these symbols to whitespace.
Aborted (core dumped)
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# python run_grid_search_final.py --kenlm "data/training/wiki_subword_6gram.arpa"
python: can't open file '/mnt/data/asr-finetuning/run_grid_search_final.py': [Errno 2] No such file or directory
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# python run_grid_search_final.py --kenlm "data/tr^Cning/wiki_subword_6gram.arpa"
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# python run_grid_search.py --kenlm "data/training/wiki_subword_6gram.arpa"
fused_indices_to_multihot has reached end of life. Please migrate to a non-experimental function.
OneLogger: Setting error_handling_strategy to DISABLE_QUIETLY_AND_REPORT_METRIC_ERROR for rank (rank=0) with OneLogger disabled. To override: explicitly set error_handling_strategy parameter.
No exporters were provided. This means that no telemetry data will be collected.
 Device: cuda
 KenLM: data/training/wiki_subword_6gram.arpa
 Loading Model...
[NeMo I 2026-01-22 23:57:21 mixins:208] _setup_tokenizer: detected an aggregate tokenizer
[NeMo I 2026-01-22 23:57:21 mixins:347] Tokenizer SentencePieceTokenizer initialized with 1024 tokens
[NeMo I 2026-01-22 23:57:21 mixins:347] Tokenizer SentencePieceTokenizer initialized with 3000 tokens
[NeMo I 2026-01-22 23:57:21 aggregate_tokenizer:73] Aggregate vocab size: 4024
[NeMo W 2026-01-22 23:57:25 modelPT:188] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.
    Train config : 
    manifest_filepath: data/training/v2/master_manifest.json
    sample_rate: 16000
    batch_size: 32
    shuffle: true
    num_workers: 16
    pin_memory: true
    use_start_end_token: false
    min_duration: 1.5
    max_duration: 40.0
    prefetch_factor: 4
    
[NeMo W 2026-01-22 23:57:25 modelPT:195] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). 
    Validation config : 
    manifest_filepath:
    - /mnt/data/asr-finetuning/evaluation/benchmarking/data/v1/en_clean_read.json
    - /mnt/data/asr-finetuning/evaluation/benchmarking/data/v1/kn_clean_read.json
    sample_rate: 16000
    batch_size: 32
    shuffle: false
    num_workers: 16
    
[NeMo W 2026-01-22 23:57:25 modelPT:202] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).
    Test config : 
    manifest_filepath: null
    sample_rate: 16000
    batch_size: 16
    shuffle: false
    num_workers: 8
    pin_memory: true
    use_start_end_token: false
    
[NeMo I 2026-01-22 23:57:27 rnnt_models:226] Using RNNT Loss : warprnnt_numba
    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}
[NeMo I 2026-01-22 23:57:27 rnnt_models:226] Using RNNT Loss : warprnnt_numba
    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}
[NeMo W 2026-01-22 23:57:27 label_looping_base:123] No conditional node support for Cuda.
    Cuda graphs with while loops are disabled, decoding speed will be slower
    Reason: Driver supports cuda toolkit version 12.4, but the driver needs to support at least 12,6. Please update your cuda driver.
[NeMo I 2026-01-22 23:57:27 rnnt_models:226] Using RNNT Loss : warprnnt_numba
    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}
[NeMo W 2026-01-22 23:57:27 label_looping_base:123] No conditional node support for Cuda.
    Cuda graphs with while loops are disabled, decoding speed will be slower
    Reason: Driver supports cuda toolkit version 12.4, but the driver needs to support at least 12,6. Please update your cuda driver.
[NeMo I 2026-01-22 23:57:29 save_restore_connector:285] Model EncDecHybridRNNTCTCBPEModel was successfully restored from /mnt/data/asr-finetuning/training/models/kathbath_hybrid_h200_scaleup_p3_phase3_final.nemo.
 Pre-computing logits for 128 files...
100%|| 128/128 [00:07<00:00, 16.12it/s]
 Loading KenLM & Using RAW Vocab...
    Vocab Size: 4024

==================================================
 STARTING GRID SEARCH
==================================================
Alpha    | Beta     | WER     
--------------------------------------------------
Loading the LM will be faster if you build a binary file.
Reading /mnt/data/asr-finetuning/data/training/wiki_subword_6gram.arpa
----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100
Build Failed: Cannot read model 'data/training/wiki_subword_6gram.arpa' (End of file Byte: 0)
Loading the LM will be faster if you build a binary file.
Reading /mnt/data/asr-finetuning/data/training/wiki_subword_6gram.arpa
----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100
Build Failed: Cannot read model 'data/training/wiki_subword_6gram.arpa' (End of file Byte: 0)
Loading the LM will be faster if you build a binary file.
Reading /mnt/data/asr-finetuning/data/training/wiki_subword_6gram.arpa
----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100
Build Failed: Cannot read model 'data/training/wiki_subword_6gram.arpa' (End of file Byte: 0)
Loading the LM will be faster if you build a binary file.
Reading /mnt/data/asr-finetuning/data/training/wiki_subword_6gram.arpa
----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100
Build Failed: Cannot read model 'data/training/wiki_subword_6gram.arpa' (End of file Byte: 0)
Loading the LM will be faster if you build a binary file.
Reading /mnt/data/asr-finetuning/data/training/wiki_subword_6gram.arpa
----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100
Build Failed: Cannot read model 'data/training/wiki_subword_6gram.arpa' (End of file Byte: 0)
Loading the LM will be faster if you build a binary file.
Reading /mnt/data/asr-finetuning/data/training/wiki_subword_6gram.arpa
----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100
Build Failed: Cannot read model 'data/training/wiki_subword_6gram.arpa' (End of file Byte: 0)
==================================================
 BEST RESULT: WER 100.00%
   Alpha: 0
   Beta:  0
==================================================

 QUALITATIVE CHECK
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# sed -i 's/<unk>//g' data/training/wiki_tokenized.txt
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# kenlm/build/bin/lmplz -o 6 --prune 0 0 1 < data/training/wiki_tokenized.txt > data/training/wiki_subword_6gram.arpa
=== 1/5 Counting and sorting n-grams ===
Reading /mnt/data/asr-finetuning/data/training/wiki_tokenized.txt
----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100
****************************************************************************************************
Unigram tokens 17805415 types 1017
=== 2/5 Calculating and sorting adjusted counts ===
Chain sizes: 1:12204 2:13304475648 3:24945891328 4:39913426944 5:58207084544 6:79826853888
/mnt/data/asr-finetuning/kenlm/lm/builder/adjust_counts.cc:60 in void lm::builder::{anonymous}::StatCollector::CalculateDiscounts(const lm::builder::DiscountConfig&) threw BadDiscountException because `discounts_[i].amount[j] < 0.0 || discounts_[i].amount[j] > j'.
ERROR: 1-gram discount out of range for adjusted count 2: -0.8720932.  This means modified Kneser-Ney smoothing thinks something is weird about your data.  To override this error for e.g. a class-based model, rerun with --discount_fallback

Aborted (core dumped)
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# sed -i 's/<unk>//g' data/training/wiki_tokenized.txtawk 'NF' data/training/wiki_tokenized.txt | sort -u > data/training/wiki_tokenized_clean.txt^C
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# awk 'NF' data/training/wiki_tokenized.txt | sort -u > data/training/wiki_tokenized_clean.txt
^C
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# awk 'NF' data/training/wiki_tokenized.txt | sort -u > data/training/wiki_tokenized_clean.txt
^C
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# tmux new -s training
[detached (from session training)]
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# python - <<'EOF'
import re
from nemo.collections.asr.models import EncDecHybridRNNTCTCBPEModel

# CONFIG
MODEL_PATH = "training/models/kathbath_hybrid_h200_scaleup_p3_phase3_final.nemo"

def inspect_vocab():
    print(f" Scanning Tokenizer Vocab for Forbidden Tokens...")
    try:
        model = EncDecHybridRNNTCTCBPEModel.restore_from(MODEL_PATH, map_location="cpu")
        tokenizer = model.tokenizer
    except Exception as e:
        print(f" Failed to load: {e}")
        return

    vocab_size = tokenizer.vocab_size
    print(f"   Total Vocab Size: {vocab_size}")
    
    suspicious = []
    
    # Iterate through every single token ID
    for i in range(vocab_size):
        try:
            # Get the token string
            if hasattr(tokenizer, 'ids_to_tokens'):
                token = tokenizer.ids_to_tokens([i])[0]
            else:
                token = tokenizer.tokenizer.id_to_piece(i)
                
            # CHECKS:
            # 1. Contains brackets <...> or [...]
            # 2. Is empty or whitespace only (but NOT the BPE underscore)
            # 3. Contains control chars (tab, newline, null)
            is_suspicious = False
            
            if re.search(r'[<\[].*?[>\]]', token): # Matches <unk>, [PAD], etc.
                is_suspicious = True
            elif token in ["", "\t", "\n", "\r"]:
                is_suspicious = True
            
            if is_suspicious:
                suspicious.append(f"ID {i}: {repr(token)}")
                
        except:
            pass

    print("\n" + "="*50)
    print(" POTENTIAL POISON TOKENS FOUND")
    print("="*50)
    
    if suspicious:
        for s in suspicious:
            print(s)
        print("\n ADD THESE TO YOUR 'FORBIDDEN' SET")
    else:
        print(" Clean! No obvious special tokens found.")

EOF inspect_vocab()ain__":
fused_indices_to_multihot has reached end of life. Please migrate to a non-experimental function.
OneLogger: Setting error_handling_strategy to DISABLE_QUIETLY_AND_REPORT_METRIC_ERROR for rank (rank=0) with OneLogger disabled. To override: explicitly set error_handling_strategy parameter.
No exporters were provided. This means that no telemetry data will be collected.
 Scanning Tokenizer Vocab for Forbidden Tokens...
[NeMo I 2026-01-23 01:30:18 mixins:208] _setup_tokenizer: detected an aggregate tokenizer
[NeMo I 2026-01-23 01:30:18 mixins:347] Tokenizer SentencePieceTokenizer initialized with 1024 tokens
[NeMo I 2026-01-23 01:30:18 mixins:347] Tokenizer SentencePieceTokenizer initialized with 3000 tokens
[NeMo I 2026-01-23 01:30:18 aggregate_tokenizer:73] Aggregate vocab size: 4024
[NeMo W 2026-01-23 01:30:23 modelPT:188] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.
    Train config : 
    manifest_filepath: data/training/v2/master_manifest.json
    sample_rate: 16000
    batch_size: 32
    shuffle: true
    num_workers: 16
    pin_memory: true
    use_start_end_token: false
    min_duration: 1.5
    max_duration: 40.0
    prefetch_factor: 4
    
[NeMo W 2026-01-23 01:30:23 modelPT:195] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). 
    Validation config : 
    manifest_filepath:
    - /mnt/data/asr-finetuning/evaluation/benchmarking/data/v1/en_clean_read.json
    - /mnt/data/asr-finetuning/evaluation/benchmarking/data/v1/kn_clean_read.json
    sample_rate: 16000
    batch_size: 32
    shuffle: false
    num_workers: 16
    
[NeMo W 2026-01-23 01:30:23 modelPT:202] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).
    Test config : 
    manifest_filepath: null
    sample_rate: 16000
    batch_size: 16
    shuffle: false
    num_workers: 8
    pin_memory: true
    use_start_end_token: false
    
[NeMo I 2026-01-23 01:30:24 rnnt_models:226] Using RNNT Loss : warprnnt_numba
    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}
[NeMo I 2026-01-23 01:30:24 rnnt_models:226] Using RNNT Loss : warprnnt_numba
    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}
[NeMo W 2026-01-23 01:30:24 label_looping_base:123] No conditional node support for Cuda.
    Cuda graphs with while loops are disabled, decoding speed will be slower
    Reason: Driver supports cuda toolkit version 12.4, but the driver needs to support at least 12,6. Please update your cuda driver.
[NeMo I 2026-01-23 01:30:25 rnnt_models:226] Using RNNT Loss : warprnnt_numba
    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}
[NeMo W 2026-01-23 01:30:25 label_looping_base:123] No conditional node support for Cuda.
    Cuda graphs with while loops are disabled, decoding speed will be slower
    Reason: Driver supports cuda toolkit version 12.4, but the driver needs to support at least 12,6. Please update your cuda driver.
[NeMo I 2026-01-23 01:30:27 save_restore_connector:285] Model EncDecHybridRNNTCTCBPEModel was successfully restored from /mnt/data/asr-finetuning/training/models/kathbath_hybrid_h200_scaleup_p3_phase3_final.nemo.
   Total Vocab Size: 4024

==================================================
 POTENTIAL POISON TOKENS FOUND
==================================================
ID 0: '<unk>'
ID 1024: '<unk>'
ID 1025: '<s>'
ID 1026: '</s>'
ID 1027: '<0x00>'
ID 1028: '<0x01>'
ID 1029: '<0x02>'
ID 1030: '<0x03>'
ID 1031: '<0x04>'
ID 1032: '<0x05>'
ID 1033: '<0x06>'
ID 1034: '<0x07>'
ID 1035: '<0x08>'
ID 1036: '<0x09>'
ID 1037: '<0x0A>'
ID 1038: '<0x0B>'
ID 1039: '<0x0C>'
ID 1040: '<0x0D>'
ID 1041: '<0x0E>'
ID 1042: '<0x0F>'
ID 1043: '<0x10>'
ID 1044: '<0x11>'
ID 1045: '<0x12>'
ID 1046: '<0x13>'
ID 1047: '<0x14>'
ID 1048: '<0x15>'
ID 1049: '<0x16>'
ID 1050: '<0x17>'
ID 1051: '<0x18>'
ID 1052: '<0x19>'
ID 1053: '<0x1A>'
ID 1054: '<0x1B>'
ID 1055: '<0x1C>'
ID 1056: '<0x1D>'
ID 1057: '<0x1E>'
ID 1058: '<0x1F>'
ID 1059: '<0x20>'
ID 1060: '<0x21>'
ID 1061: '<0x22>'
ID 1062: '<0x23>'
ID 1063: '<0x24>'
ID 1064: '<0x25>'
ID 1065: '<0x26>'
ID 1066: '<0x27>'
ID 1067: '<0x28>'
ID 1068: '<0x29>'
ID 1069: '<0x2A>'
ID 1070: '<0x2B>'
ID 1071: '<0x2C>'
ID 1072: '<0x2D>'
ID 1073: '<0x2E>'
ID 1074: '<0x2F>'
ID 1075: '<0x30>'
ID 1076: '<0x31>'
ID 1077: '<0x32>'
ID 1078: '<0x33>'
ID 1079: '<0x34>'
ID 1080: '<0x35>'
ID 1081: '<0x36>'
ID 1082: '<0x37>'
ID 1083: '<0x38>'
ID 1084: '<0x39>'
ID 1085: '<0x3A>'
ID 1086: '<0x3B>'
ID 1087: '<0x3C>'
ID 1088: '<0x3D>'
ID 1089: '<0x3E>'
ID 1090: '<0x3F>'
ID 1091: '<0x40>'
ID 1092: '<0x41>'
ID 1093: '<0x42>'
ID 1094: '<0x43>'
ID 1095: '<0x44>'
ID 1096: '<0x45>'
ID 1097: '<0x46>'
ID 1098: '<0x47>'
ID 1099: '<0x48>'
ID 1100: '<0x49>'
ID 1101: '<0x4A>'
ID 1102: '<0x4B>'
ID 1103: '<0x4C>'
ID 1104: '<0x4D>'
ID 1105: '<0x4E>'
ID 1106: '<0x4F>'
ID 1107: '<0x50>'
ID 1108: '<0x51>'
ID 1109: '<0x52>'
ID 1110: '<0x53>'
ID 1111: '<0x54>'
ID 1112: '<0x55>'
ID 1113: '<0x56>'
ID 1114: '<0x57>'
ID 1115: '<0x58>'
ID 1116: '<0x59>'
ID 1117: '<0x5A>'
ID 1118: '<0x5B>'
ID 1119: '<0x5C>'
ID 1120: '<0x5D>'
ID 1121: '<0x5E>'
ID 1122: '<0x5F>'
ID 1123: '<0x60>'
ID 1124: '<0x61>'
ID 1125: '<0x62>'
ID 1126: '<0x63>'
ID 1127: '<0x64>'
ID 1128: '<0x65>'
ID 1129: '<0x66>'
ID 1130: '<0x67>'
ID 1131: '<0x68>'
ID 1132: '<0x69>'
ID 1133: '<0x6A>'
ID 1134: '<0x6B>'
ID 1135: '<0x6C>'
ID 1136: '<0x6D>'
ID 1137: '<0x6E>'
ID 1138: '<0x6F>'
ID 1139: '<0x70>'
ID 1140: '<0x71>'
ID 1141: '<0x72>'
ID 1142: '<0x73>'
ID 1143: '<0x74>'
ID 1144: '<0x75>'
ID 1145: '<0x76>'
ID 1146: '<0x77>'
ID 1147: '<0x78>'
ID 1148: '<0x79>'
ID 1149: '<0x7A>'
ID 1150: '<0x7B>'
ID 1151: '<0x7C>'
ID 1152: '<0x7D>'
ID 1153: '<0x7E>'
ID 1154: '<0x7F>'
ID 1155: '<0x80>'
ID 1156: '<0x81>'
ID 1157: '<0x82>'
ID 1158: '<0x83>'
ID 1159: '<0x84>'
ID 1160: '<0x85>'
ID 1161: '<0x86>'
ID 1162: '<0x87>'
ID 1163: '<0x88>'
ID 1164: '<0x89>'
ID 1165: '<0x8A>'
ID 1166: '<0x8B>'
ID 1167: '<0x8C>'
ID 1168: '<0x8D>'
ID 1169: '<0x8E>'
ID 1170: '<0x8F>'
ID 1171: '<0x90>'
ID 1172: '<0x91>'
ID 1173: '<0x92>'
ID 1174: '<0x93>'
ID 1175: '<0x94>'
ID 1176: '<0x95>'
ID 1177: '<0x96>'
ID 1178: '<0x97>'
ID 1179: '<0x98>'
ID 1180: '<0x99>'
ID 1181: '<0x9A>'
ID 1182: '<0x9B>'
ID 1183: '<0x9C>'
ID 1184: '<0x9D>'
ID 1185: '<0x9E>'
ID 1186: '<0x9F>'
ID 1187: '<0xA0>'
ID 1188: '<0xA1>'
ID 1189: '<0xA2>'
ID 1190: '<0xA3>'
ID 1191: '<0xA4>'
ID 1192: '<0xA5>'
ID 1193: '<0xA6>'
ID 1194: '<0xA7>'
ID 1195: '<0xA8>'
ID 1196: '<0xA9>'
ID 1197: '<0xAA>'
ID 1198: '<0xAB>'
ID 1199: '<0xAC>'
ID 1200: '<0xAD>'
ID 1201: '<0xAE>'
ID 1202: '<0xAF>'
ID 1203: '<0xB0>'
ID 1204: '<0xB1>'
ID 1205: '<0xB2>'
ID 1206: '<0xB3>'
ID 1207: '<0xB4>'
ID 1208: '<0xB5>'
ID 1209: '<0xB6>'
ID 1210: '<0xB7>'
ID 1211: '<0xB8>'
ID 1212: '<0xB9>'
ID 1213: '<0xBA>'
ID 1214: '<0xBB>'
ID 1215: '<0xBC>'
ID 1216: '<0xBD>'
ID 1217: '<0xBE>'
ID 1218: '<0xBF>'
ID 1219: '<0xC0>'
ID 1220: '<0xC1>'
ID 1221: '<0xC2>'
ID 1222: '<0xC3>'
ID 1223: '<0xC4>'
ID 1224: '<0xC5>'
ID 1225: '<0xC6>'
ID 1226: '<0xC7>'
ID 1227: '<0xC8>'
ID 1228: '<0xC9>'
ID 1229: '<0xCA>'
ID 1230: '<0xCB>'
ID 1231: '<0xCC>'
ID 1232: '<0xCD>'
ID 1233: '<0xCE>'
ID 1234: '<0xCF>'
ID 1235: '<0xD0>'
ID 1236: '<0xD1>'
ID 1237: '<0xD2>'
ID 1238: '<0xD3>'
ID 1239: '<0xD4>'
ID 1240: '<0xD5>'
ID 1241: '<0xD6>'
ID 1242: '<0xD7>'
ID 1243: '<0xD8>'
ID 1244: '<0xD9>'
ID 1245: '<0xDA>'
ID 1246: '<0xDB>'
ID 1247: '<0xDC>'
ID 1248: '<0xDD>'
ID 1249: '<0xDE>'
ID 1250: '<0xDF>'
ID 1251: '<0xE0>'
ID 1252: '<0xE1>'
ID 1253: '<0xE2>'
ID 1254: '<0xE3>'
ID 1255: '<0xE4>'
ID 1256: '<0xE5>'
ID 1257: '<0xE6>'
ID 1258: '<0xE7>'
ID 1259: '<0xE8>'
ID 1260: '<0xE9>'
ID 1261: '<0xEA>'
ID 1262: '<0xEB>'
ID 1263: '<0xEC>'
ID 1264: '<0xED>'
ID 1265: '<0xEE>'
ID 1266: '<0xEF>'
ID 1267: '<0xF0>'
ID 1268: '<0xF1>'
ID 1269: '<0xF2>'
ID 1270: '<0xF3>'
ID 1271: '<0xF4>'
ID 1272: '<0xF5>'
ID 1273: '<0xF6>'
ID 1274: '<0xF7>'
ID 1275: '<0xF8>'
ID 1276: '<0xF9>'
ID 1277: '<0xFA>'
ID 1278: '<0xFB>'
ID 1279: '<0xFC>'
ID 1280: '<0xFD>'
ID 1281: '<0xFE>'
ID 1282: '<0xFF>'

 ADD THESE TO YOUR 'FORBIDDEN' SET
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# python - <<'EOF'
import torch
from nemo.collections.asr.models import EncDecHybridRNNTCTCBPEModel
from tqdm import tqdm
import os

# CONFIG
MODEL_PATH = "training/models/kathbath_hybrid_h200_scaleup_p3_phase3_final.nemo"
INPUT_TEXT = "data/training/wiki_corpus_multilingual.txt"
OUTPUT_TOKENIZED = "data/training/wiki_final_clean.txt"

#  MINIMAL FORBIDDEN LIST 
# Only ban tokens that physically break the KenLM builder.
# We KEEP the byte codes (<0x00>...) because the model needs them for fallback.
FORBIDDEN = {
    '<unk>',   # CRASHES KenLM (Reserved for unknown)
    '<s>',     # CRASHES KenLM (Reserved for Start-of-Sentence)
    '</s>',    # CRASHES KenLM (Reserved for End-of-Sentence)
    '<pad>',   # Useless for LM
}

def tokenize_and_clean():
    print(f" Loading Tokenizer from {MODEL_PATH}...")
    try:
        model = EncDecHybridRNNTCTCBPEModel.restore_from(MODEL_PATH, map_location="cpu")
        tokenizer = model.tokenizer
    except Exception as e:
        print(f" Failed to load model: {e}")
        return

    # Detect Language ID
    lang_id = tokenizer.langs[0] if (hasattr(tokenizer, 'langs') and tokenizer.langs) else "kn"
    print(f" Using Language ID: '{lang_id}'")

    print(f" Processing {INPUT_TEXT} -> {OUTPUT_TOKENIZED}...")
    
    if not os.path.exists(INPUT_TEXT):
        print(f" Error: {INPUT_TEXT} missing. Run fetch_wiki_v2.py first.")
        return

    count = 0
    with open(INPUT_TEXT, 'r', encoding='utf-8') as fin, \
         open(OUTPUT_TOKENIZED, 'w', encoding='utf-8') as fout:
        
        for line in tqdm(fin):
            line = line.strip()
            if not line: continue
            
            # 1. Tokenize
            try:
                ids = tokenizer.text_to_ids(line, lang_id=lang_id)
            except:
                try: ids = tokenizer.text_to_ids(line)
                except: continue

            # 2. Convert to Tokens
            if hasattr(tokenizer, 'ids_to_tokens'):
                tokens = tokenizer.ids_to_tokens(ids)
EOF tokenize_and_clean()":ote {count} clean lines to {OUTPUT_TOKENIZED}")>)
fused_indices_to_multihot has reached end of life. Please migrate to a non-experimental function.
OneLogger: Setting error_handling_strategy to DISABLE_QUIETLY_AND_REPORT_METRIC_ERROR for rank (rank=0) with OneLogger disabled. To override: explicitly set error_handling_strategy parameter.
No exporters were provided. This means that no telemetry data will be collected.
 Loading Tokenizer from training/models/kathbath_hybrid_h200_scaleup_p3_phase3_final.nemo...
[NeMo I 2026-01-23 01:35:46 mixins:208] _setup_tokenizer: detected an aggregate tokenizer
[NeMo I 2026-01-23 01:35:46 mixins:347] Tokenizer SentencePieceTokenizer initialized with 1024 tokens
[NeMo I 2026-01-23 01:35:46 mixins:347] Tokenizer SentencePieceTokenizer initialized with 3000 tokens
[NeMo I 2026-01-23 01:35:46 aggregate_tokenizer:73] Aggregate vocab size: 4024
[NeMo W 2026-01-23 01:35:51 modelPT:188] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.
    Train config : 
    manifest_filepath: data/training/v2/master_manifest.json
    sample_rate: 16000
    batch_size: 32
    shuffle: true
    num_workers: 16
    pin_memory: true
    use_start_end_token: false
    min_duration: 1.5
    max_duration: 40.0
    prefetch_factor: 4
    
[NeMo W 2026-01-23 01:35:51 modelPT:195] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). 
    Validation config : 
    manifest_filepath:
    - /mnt/data/asr-finetuning/evaluation/benchmarking/data/v1/en_clean_read.json
    - /mnt/data/asr-finetuning/evaluation/benchmarking/data/v1/kn_clean_read.json
    sample_rate: 16000
    batch_size: 32
    shuffle: false
    num_workers: 16
    
[NeMo W 2026-01-23 01:35:51 modelPT:202] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).
    Test config : 
    manifest_filepath: null
    sample_rate: 16000
    batch_size: 16
    shuffle: false
    num_workers: 8
    pin_memory: true
    use_start_end_token: false
    
[NeMo I 2026-01-23 01:35:53 rnnt_models:226] Using RNNT Loss : warprnnt_numba
    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}
[NeMo I 2026-01-23 01:35:53 rnnt_models:226] Using RNNT Loss : warprnnt_numba
    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}
[NeMo W 2026-01-23 01:35:53 label_looping_base:123] No conditional node support for Cuda.
    Cuda graphs with while loops are disabled, decoding speed will be slower
    Reason: Driver supports cuda toolkit version 12.4, but the driver needs to support at least 12,6. Please update your cuda driver.
[NeMo I 2026-01-23 01:35:53 rnnt_models:226] Using RNNT Loss : warprnnt_numba
    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}
[NeMo W 2026-01-23 01:35:53 label_looping_base:123] No conditional node support for Cuda.
    Cuda graphs with while loops are disabled, decoding speed will be slower
    Reason: Driver supports cuda toolkit version 12.4, but the driver needs to support at least 12,6. Please update your cuda driver.
[NeMo I 2026-01-23 01:35:56 save_restore_connector:285] Model EncDecHybridRNNTCTCBPEModel was successfully restored from /mnt/data/asr-finetuning/training/models/kathbath_hybrid_h200_scaleup_p3_phase3_final.nemo.
 Using Language ID: 'en'
 Processing data/training/wiki_corpus_multilingual.txt -> data/training/wiki_final_clean.txt...
1554678it [01:12, 21301.53it/s]enlm/build/bin/lmplz -o 6 --prune 0 0 1 --discount_fallback < data/training/wiki_final_clean.txt > data/training/wiki_subword_6gram.arpa
 Success! Wrote 1554678 clean lines to data/training/wiki_final_clean.txt
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# kenlm/build/bin/lmplz -o 6 --prune 0 0 1 --discount_fallback < data/training/wiki_final_clean.txt > data/training/wiki_subword_6gram.arpa
=== 1/5 Counting and sorting n-grams ===
Reading /mnt/data/asr-finetuning/data/training/wiki_final_clean.txt
----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100
****************************************************************************************************
Unigram tokens 17805415 types 1017
=== 2/5 Calculating and sorting adjusted counts ===
Chain sizes: 1:12204 2:13304475648 3:24945891328 4:39913426944 5:58207084544 6:79826853888
Substituting fallback discounts for order 0: D1=0.5 D2=1 D3+=1.5
Statistics:
1 1017 D1=0.5 D2=1 D3+=1.5
2 53365 D1=0.629364 D2=1.06177 D3+=1.45565
3 75350/208401 D1=0.758896 D2=1.16546 D3+=1.46632
4 102694/386673 D1=0.835277 D2=1.24258 D3+=1.452
5 100692/513964 D1=0.890874 D2=1.30396 D3+=1.4687
6 91655/588289 D1=0.828021 D2=1.25813 D3+=1.41158
Memory estimate for binary LM:
type       kB
probing  9420 assuming -p 1.5
probing 11370 assuming -r models -p 1.5
trie     4131 without quantization
trie     1977 assuming -q 8 -b 8 quantization 
trie     3729 assuming -a 22 array pointer compression
trie     1575 assuming -a 22 -q 8 -b 8 array pointer compression and quantization
=== 3/5 Calculating and sorting initial probabilities ===
Chain sizes: 1:12204 2:853840 3:1507000 4:2464656 5:2819376 6:2932960
----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100
###************#####################################################################################
=== 4/5 Calculating and writing order-interpolated probabilities ===
Chain sizes: 1:12204 2:853840 3:1507000 4:2464656 5:2819376 6:2932960
----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100
####################################################################################################
=== 5/5 Writing ARPA model ===
----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100
****************************************************************************************************
Name:lmplz	VmPeak:211318920 kB	VmRSS:13572 kB	RSSMax:33360196 kB	user:3.59895	sys:25.4375	CPU:29.0366	real:28.4484
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# python run_grid_search.py --kenlm "data/training/wiki_subword_6gram.arpa"
fused_indices_to_multihot has reached end of life. Please migrate to a non-experimental function.
OneLogger: Setting error_handling_strategy to DISABLE_QUIETLY_AND_REPORT_METRIC_ERROR for rank (rank=0) with OneLogger disabled. To override: explicitly set error_handling_strategy parameter.
No exporters were provided. This means that no telemetry data will be collected.
 Device: cuda
 KenLM: data/training/wiki_subword_6gram.arpa
 Loading Model...
[NeMo I 2026-01-23 01:39:21 mixins:208] _setup_tokenizer: detected an aggregate tokenizer
[NeMo I 2026-01-23 01:39:21 mixins:347] Tokenizer SentencePieceTokenizer initialized with 1024 tokens
[NeMo I 2026-01-23 01:39:21 mixins:347] Tokenizer SentencePieceTokenizer initialized with 3000 tokens
[NeMo I 2026-01-23 01:39:21 aggregate_tokenizer:73] Aggregate vocab size: 4024
[NeMo W 2026-01-23 01:39:25 modelPT:188] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.
    Train config : 
    manifest_filepath: data/training/v2/master_manifest.json
    sample_rate: 16000
    batch_size: 32
    shuffle: true
    num_workers: 16
    pin_memory: true
    use_start_end_token: false
    min_duration: 1.5
    max_duration: 40.0
    prefetch_factor: 4
    
[NeMo W 2026-01-23 01:39:25 modelPT:195] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). 
    Validation config : 
    manifest_filepath:
    - /mnt/data/asr-finetuning/evaluation/benchmarking/data/v1/en_clean_read.json
    - /mnt/data/asr-finetuning/evaluation/benchmarking/data/v1/kn_clean_read.json
    sample_rate: 16000
    batch_size: 32
    shuffle: false
    num_workers: 16
    
[NeMo W 2026-01-23 01:39:25 modelPT:202] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).
    Test config : 
    manifest_filepath: null
    sample_rate: 16000
    batch_size: 16
    shuffle: false
    num_workers: 8
    pin_memory: true
    use_start_end_token: false
    
[NeMo I 2026-01-23 01:39:27 rnnt_models:226] Using RNNT Loss : warprnnt_numba
    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}
[NeMo I 2026-01-23 01:39:27 rnnt_models:226] Using RNNT Loss : warprnnt_numba
    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}
[NeMo W 2026-01-23 01:39:27 label_looping_base:123] No conditional node support for Cuda.
    Cuda graphs with while loops are disabled, decoding speed will be slower
    Reason: Driver supports cuda toolkit version 12.4, but the driver needs to support at least 12,6. Please update your cuda driver.
[NeMo I 2026-01-23 01:39:28 rnnt_models:226] Using RNNT Loss : warprnnt_numba
    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}
[NeMo W 2026-01-23 01:39:28 label_looping_base:123] No conditional node support for Cuda.
    Cuda graphs with while loops are disabled, decoding speed will be slower
    Reason: Driver supports cuda toolkit version 12.4, but the driver needs to support at least 12,6. Please update your cuda driver.
[NeMo I 2026-01-23 01:39:30 save_restore_connector:285] Model EncDecHybridRNNTCTCBPEModel was successfully restored from /mnt/data/asr-finetuning/training/models/kathbath_hybrid_h200_scaleup_p3_phase3_final.nemo.
 Pre-computing logits for 128 files...
100%|| 128/128 [00:08<00:00, 15.36it/s]
 Loading KenLM & Using RAW Vocab...
    Vocab Size: 4024

==================================================
 STARTING GRID SEARCH
==================================================
Alpha    | Beta     | WER     
--------------------------------------------------
Loading the LM will be faster if you build a binary file.
Reading /mnt/data/asr-finetuning/data/training/wiki_subword_6gram.arpa
----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100
****************************************************************************************************
0.3      | 0.5      | 69.09%
0.3      | 1.0      | 68.81%
0.3      | 2.0      | 67.68%
0.3      | 4.0      | 64.14%
Loading the LM will be faster if you build a binary file.
Reading /mnt/data/asr-finetuning/data/training/wiki_subword_6gram.arpa
----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100
****************************************************************************************************
0.5      | 0.5      | 70.65%
0.5      | 1.0      | 70.58%
0.5      | 2.0      | 70.58%
0.5      | 4.0      | 70.44%
Loading the LM will be faster if you build a binary file.
Reading /mnt/data/asr-finetuning/data/training/wiki_subword_6gram.arpa
----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100
****************************************************************************************************
0.7      | 0.5      | 71.00%
0.7      | 1.0      | 71.00%
0.7      | 2.0      | 71.00%
0.7      | 4.0      | 70.86%
Loading the LM will be faster if you build a binary file.
Reading /mnt/data/asr-finetuning/data/training/wiki_subword_6gram.arpa
----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100
****************************************************************************************************
1.0      | 0.5      | 71.00%
1.0      | 1.0      | 71.00%
1.0      | 2.0      | 71.00%
^CTraceback (most recent call last):
  File "/mnt/data/asr-finetuning/run_grid_search.py", line 179, in <module>
    run_grid_search()
  File "/mnt/data/asr-finetuning/run_grid_search.py", line 152, in run_grid_search
    text = decoder.decode(logits, beam_width=64)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/data/asr-env/lib/python3.12/site-packages/pyctcdecode/decoder.py", line 716, in decode
    decoded_beams = self.decode_beams(
                    ^^^^^^^^^^^^^^^^^^
  File "/mnt/data/asr-env/lib/python3.12/site-packages/pyctcdecode/decoder.py", line 596, in decode_beams
    decoded_beams = self._decode_logits(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/mnt/data/asr-env/lib/python3.12/site-packages/pyctcdecode/decoder.py", line 512, in _decode_logits
    scored_beams = self._get_lm_beams(
                   ^^^^^^^^^^^^^^^^^^^
  File "/mnt/data/asr-env/lib/python3.12/site-packages/pyctcdecode/decoder.py", line 352, in _get_lm_beams
    new_text = _merge_tokens(text, next_word)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/data/asr-env/lib/python3.12/site-packages/pyctcdecode/decoder.py", line 154, in _merge_tokens
    def _merge_tokens(token_1: str, token_2: str) -> str:
    
KeyboardInterrupt
^Z
[4]+  Stopped                 python run_grid_search.py --kenlm "data/training/wiki_subword_6gram.arpa"
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# rm^Cun_grid_search.py --kenlm "data/training/wiki_subword_6gram.arpa"
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# rm run_grid_search.py
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# nano run_grid_search.py
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# python run_grid_search_stitched.py --kenlm "data/training/wiki_subword_6gram.arpa"
python: can't open file '/mnt/data/asr-finetuning/run_grid_search_stitched.py': [Errno 2] No such file or directory
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# python run_grid_search.py --kenlm "data/training/wiki_subword_6gram.arpa"
fused_indices_to_multihot has reached end of life. Please migrate to a non-experimental function.
OneLogger: Setting error_handling_strategy to DISABLE_QUIETLY_AND_REPORT_METRIC_ERROR for rank (rank=0) with OneLogger disabled. To override: explicitly set error_handling_strategy parameter.
No exporters were provided. This means that no telemetry data will be collected.
 Device: cuda
 KenLM: data/training/wiki_subword_6gram.arpa
 Loading Model...
[NeMo I 2026-01-23 01:44:09 mixins:208] _setup_tokenizer: detected an aggregate tokenizer
[NeMo I 2026-01-23 01:44:09 mixins:347] Tokenizer SentencePieceTokenizer initialized with 1024 tokens
[NeMo I 2026-01-23 01:44:09 mixins:347] Tokenizer SentencePieceTokenizer initialized with 3000 tokens
[NeMo I 2026-01-23 01:44:09 aggregate_tokenizer:73] Aggregate vocab size: 4024
[NeMo W 2026-01-23 01:44:14 modelPT:188] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.
    Train config : 
    manifest_filepath: data/training/v2/master_manifest.json
    sample_rate: 16000
    batch_size: 32
    shuffle: true
    num_workers: 16
    pin_memory: true
    use_start_end_token: false
    min_duration: 1.5
    max_duration: 40.0
    prefetch_factor: 4
    
[NeMo W 2026-01-23 01:44:14 modelPT:195] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). 
    Validation config : 
    manifest_filepath:
    - /mnt/data/asr-finetuning/evaluation/benchmarking/data/v1/en_clean_read.json
    - /mnt/data/asr-finetuning/evaluation/benchmarking/data/v1/kn_clean_read.json
    sample_rate: 16000
    batch_size: 32
    shuffle: false
    num_workers: 16
    
[NeMo W 2026-01-23 01:44:14 modelPT:202] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).
    Test config : 
    manifest_filepath: null
    sample_rate: 16000
    batch_size: 16
    shuffle: false
    num_workers: 8
    pin_memory: true
    use_start_end_token: false
    
[NeMo I 2026-01-23 01:44:16 rnnt_models:226] Using RNNT Loss : warprnnt_numba
    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}
[NeMo I 2026-01-23 01:44:16 rnnt_models:226] Using RNNT Loss : warprnnt_numba
    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}
[NeMo W 2026-01-23 01:44:16 label_looping_base:123] No conditional node support for Cuda.
    Cuda graphs with while loops are disabled, decoding speed will be slower
    Reason: Driver supports cuda toolkit version 12.4, but the driver needs to support at least 12,6. Please update your cuda driver.
[NeMo I 2026-01-23 01:44:16 rnnt_models:226] Using RNNT Loss : warprnnt_numba
    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}
[NeMo W 2026-01-23 01:44:16 label_looping_base:123] No conditional node support for Cuda.
    Cuda graphs with while loops are disabled, decoding speed will be slower
    Reason: Driver supports cuda toolkit version 12.4, but the driver needs to support at least 12,6. Please update your cuda driver.
[NeMo I 2026-01-23 01:44:19 save_restore_connector:285] Model EncDecHybridRNNTCTCBPEModel was successfully restored from /mnt/data/asr-finetuning/training/models/kathbath_hybrid_h200_scaleup_p3_phase3_final.nemo.
 Pre-computing logits for 128 files...
100%|| 128/128 [00:08<00:00, 15.64it/s]
 Loading KenLM & Using RAW Vocab...

==================================================
 STARTING GRID SEARCH (WITH STITCHING)
==================================================
Alpha    | Beta     | WER     
--------------------------------------------------
Loading the LM will be faster if you build a binary file.
Reading /mnt/data/asr-finetuning/data/training/wiki_subword_6gram.arpa
----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100
****************************************************************************************************
0.5      | 0.5      | 100.00%
0.5      | 1.0      | 100.00%
0.5      | 2.0      | 100.00%
Loading the LM will be faster if you build a binary file.
Reading /mnt/data/asr-finetuning/data/training/wiki_subword_6gram.arpa
----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100
****************************************************************************************************
0.8      | 0.5      | 100.00%
0.8      | 1.0      | 100.00%
0.8      | 2.0      | 100.00%
Loading the LM will be faster if you build a binary file.
Reading /mnt/data/asr-finetuning/data/training/wiki_subword_6gram.arpa
----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100
****************************************************************************************************
1.0      | 0.5      | 100.00%
1.0      | 1.0      | 100.00%
1.0      | 2.0      | 100.00%
Loading the LM will be faster if you build a binary file.
Reading /mnt/data/asr-finetuning/data/training/wiki_subword_6gram.arpa
----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100
****************************************************************************************************
1.5      | 0.5      | 100.00%
1.5      | 1.0      | 100.00%
1.5      | 2.0      | 100.00%
Loading the LM will be faster if you build a binary file.
Reading /mnt/data/asr-finetuning/data/training/wiki_subword_6gram.arpa
----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100
****************************************************************************************************
2.0      | 0.5      | 100.00%
2.0      | 1.0      | 100.00%
2.0      | 2.0      | 100.00%
==================================================
 BEST RESULT: WER 100.00%
   Alpha: 0
   Beta:  0
==================================================

 QUALITATIVE CHECK
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# rm run_grid_search.py
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# nano run_grid_search.py
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# python run_grid_search.py --kenlm "data/training/wiki_subword_6gram.arpa"
fused_indices_to_multihot has reached end of life. Please migrate to a non-experimental function.
OneLogger: Setting error_handling_strategy to DISABLE_QUIETLY_AND_REPORT_METRIC_ERROR for rank (rank=0) with OneLogger disabled. To override: explicitly set error_handling_strategy parameter.
No exporters were provided. This means that no telemetry data will be collected.
 Loading Model...
[NeMo I 2026-01-23 01:47:27 mixins:208] _setup_tokenizer: detected an aggregate tokenizer
[NeMo I 2026-01-23 01:47:27 mixins:347] Tokenizer SentencePieceTokenizer initialized with 1024 tokens
[NeMo I 2026-01-23 01:47:27 mixins:347] Tokenizer SentencePieceTokenizer initialized with 3000 tokens
[NeMo I 2026-01-23 01:47:27 aggregate_tokenizer:73] Aggregate vocab size: 4024
[NeMo W 2026-01-23 01:47:34 modelPT:188] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.
    Train config : 
    manifest_filepath: data/training/v2/master_manifest.json
    sample_rate: 16000
    batch_size: 32
    shuffle: true
    num_workers: 16
    pin_memory: true
    use_start_end_token: false
    min_duration: 1.5
    max_duration: 40.0
    prefetch_factor: 4
    
[NeMo W 2026-01-23 01:47:34 modelPT:195] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). 
    Validation config : 
    manifest_filepath:
    - /mnt/data/asr-finetuning/evaluation/benchmarking/data/v1/en_clean_read.json
    - /mnt/data/asr-finetuning/evaluation/benchmarking/data/v1/kn_clean_read.json
    sample_rate: 16000
    batch_size: 32
    shuffle: false
    num_workers: 16
    
[NeMo W 2026-01-23 01:47:34 modelPT:202] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).
    Test config : 
    manifest_filepath: null
    sample_rate: 16000
    batch_size: 16
    shuffle: false
    num_workers: 8
    pin_memory: true
    use_start_end_token: false
    
[NeMo I 2026-01-23 01:47:36 rnnt_models:226] Using RNNT Loss : warprnnt_numba
    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}
[NeMo I 2026-01-23 01:47:36 rnnt_models:226] Using RNNT Loss : warprnnt_numba
    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}
[NeMo W 2026-01-23 01:47:36 label_looping_base:123] No conditional node support for Cuda.
    Cuda graphs with while loops are disabled, decoding speed will be slower
    Reason: Driver supports cuda toolkit version 12.4, but the driver needs to support at least 12,6. Please update your cuda driver.
[NeMo I 2026-01-23 01:47:36 rnnt_models:226] Using RNNT Loss : warprnnt_numba
    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}
[NeMo W 2026-01-23 01:47:36 label_looping_base:123] No conditional node support for Cuda.
    Cuda graphs with while loops are disabled, decoding speed will be slower
    Reason: Driver supports cuda toolkit version 12.4, but the driver needs to support at least 12,6. Please update your cuda driver.
[NeMo I 2026-01-23 01:47:38 save_restore_connector:285] Model EncDecHybridRNNTCTCBPEModel was successfully restored from /mnt/data/asr-finetuning/training/models/kathbath_hybrid_h200_scaleup_p3_phase3_final.nemo.
 Model Vocab Size: 4024
Traceback (most recent call last):
  File "/mnt/data/asr-finetuning/run_grid_search.py", line 129, in <module>
    debug_one_file()
  File "/mnt/data/asr-finetuning/run_grid_search.py", line 29, in debug_one_file
    num_classes = model.decoder.decoder_layers[0].weight.shape[0]
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/data/asr-env/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1931, in __getattr__
    raise AttributeError(
AttributeError: 'RNNTDecoder' object has no attribute 'decoder_layers'
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# python - <<'EOF'
import torch
import json
import numpy as np
import librosa
import sys
from nemo.collections.asr.models import EncDecHybridRNNTCTCBPEModel

try:
    from pyctcdecode import build_ctcdecoder
except ImportError:
    print(" pyctcdecode not installed")
    exit(1)

# CONFIG
MODEL_PATH = "training/models/kathbath_hybrid_h200_scaleup_p3_phase3_final.nemo"
KENLM_PATH = "data/training/wiki_subword_6gram.arpa"
MANIFEST_PATH = "evaluation/benchmarking/curation/test_data/Kathbath/test_manifest.json"

def get_ctc_output_size(model):
    """Dynamically find the output size of the CTC decoder head."""
    print(" Inspecting CTC Decoder Head...")
    ctc_head = model.ctc_decoder
    print(f"   Type: {type(ctc_head)}")
    
    # Strategy 1: Check for standard 'decoder_layers' (ConvASRDecoder)
    if hasattr(ctc_head, 'decoder_layers'):
        last_layer = ctc_head.decoder_layers[-1]
        if hasattr(last_layer, 'weight'):
            return last_layer.weight.shape[0] # [vocab+1, dim]
            
    # Strategy 2: Check for 'layers' (common in other heads)
    if hasattr(ctc_head, 'layers'):
        for layer in reversed(ctc_head.layers):
            if hasattr(layer, 'weight'):
                return layer.weight.shape[0]

    # Strategy 3: Brute force search for the last Linear/Conv1d layer
    print("    Unknown structure. Searching modules...")
    for name, module in ctc_head.named_modules():
        if isinstance(module, (torch.nn.Linear, torch.nn.Conv1d)):
            # Usually the last one found is the output
            if hasattr(module, 'weight'):
                return module.weight.shape[0]
                
    return None

def diagnose():
    print(f" Loading Model...")
    model = EncDecHybridRNNTCTCBPEModel.restore_from(MODEL_PATH, map_location="cpu")
    model.eval()

    # 1. GET VOCAB SIZE
    vocab_size = model.tokenizer.vocab_size
    print(f" Tokenizer Vocab Size: {vocab_size}")

    # 2. GET CTC OUTPUT SIZE
    num_classes = get_ctc_output_size(model)
EOF diagnose() "__main__":re all {num_classes-1}, the model is predicting silence)")
fused_indices_to_multihot has reached end of life. Please migrate to a non-experimental function.
OneLogger: Setting error_handling_strategy to DISABLE_QUIETLY_AND_REPORT_METRIC_ERROR for rank (rank=0) with OneLogger disabled. To override: explicitly set error_handling_strategy parameter.
No exporters were provided. This means that no telemetry data will be collected.
 Loading Model...
[NeMo I 2026-01-23 01:50:13 mixins:208] _setup_tokenizer: detected an aggregate tokenizer
[NeMo I 2026-01-23 01:50:13 mixins:347] Tokenizer SentencePieceTokenizer initialized with 1024 tokens
[NeMo I 2026-01-23 01:50:13 mixins:347] Tokenizer SentencePieceTokenizer initialized with 3000 tokens
[NeMo I 2026-01-23 01:50:13 aggregate_tokenizer:73] Aggregate vocab size: 4024
[NeMo W 2026-01-23 01:50:18 modelPT:188] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.
    Train config : 
    manifest_filepath: data/training/v2/master_manifest.json
    sample_rate: 16000
    batch_size: 32
    shuffle: true
    num_workers: 16
    pin_memory: true
    use_start_end_token: false
    min_duration: 1.5
    max_duration: 40.0
    prefetch_factor: 4
    
[NeMo W 2026-01-23 01:50:18 modelPT:195] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). 
    Validation config : 
    manifest_filepath:
    - /mnt/data/asr-finetuning/evaluation/benchmarking/data/v1/en_clean_read.json
    - /mnt/data/asr-finetuning/evaluation/benchmarking/data/v1/kn_clean_read.json
    sample_rate: 16000
    batch_size: 32
    shuffle: false
    num_workers: 16
    
[NeMo W 2026-01-23 01:50:18 modelPT:202] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).
    Test config : 
    manifest_filepath: null
    sample_rate: 16000
    batch_size: 16
    shuffle: false
    num_workers: 8
    pin_memory: true
    use_start_end_token: false
    
[NeMo I 2026-01-23 01:50:20 rnnt_models:226] Using RNNT Loss : warprnnt_numba
    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}
[NeMo I 2026-01-23 01:50:20 rnnt_models:226] Using RNNT Loss : warprnnt_numba
    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}
[NeMo W 2026-01-23 01:50:20 label_looping_base:123] No conditional node support for Cuda.
    Cuda graphs with while loops are disabled, decoding speed will be slower
    Reason: Driver supports cuda toolkit version 12.4, but the driver needs to support at least 12,6. Please update your cuda driver.
[NeMo I 2026-01-23 01:50:21 rnnt_models:226] Using RNNT Loss : warprnnt_numba
    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}
[NeMo W 2026-01-23 01:50:21 label_looping_base:123] No conditional node support for Cuda.
    Cuda graphs with while loops are disabled, decoding speed will be slower
    Reason: Driver supports cuda toolkit version 12.4, but the driver needs to support at least 12,6. Please update your cuda driver.
[NeMo I 2026-01-23 01:50:23 save_restore_connector:285] Model EncDecHybridRNNTCTCBPEModel was successfully restored from /mnt/data/asr-finetuning/training/models/kathbath_hybrid_h200_scaleup_p3_phase3_final.nemo.
 Tokenizer Vocab Size: 4024
 Inspecting CTC Decoder Head...
   Type: <class 'nemo.collections.asr.modules.conv_asr.ConvASRDecoder'>
 CTC Output Classes:   4025
  Difference: 1
 Diagnosis: Standard CTC (Vocab + Blank). Blank is last.
  Padding labels with 1 blank token(s)...

 Building Decoder...
Loading the LM will be faster if you build a binary file.
Reading /mnt/data/asr-finetuning/data/training/wiki_subword_6gram.arpa
----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100
****************************************************************************************************
 Reading Manifest: evaluation/benchmarking/curation/test_data/Kathbath/test_manifest.json
 Testing Audio: /mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_0.wav
 Ref Text:         

 --- DECODING RESULT ---
Traceback (most recent call last):
  File "<stdin>", line 158, in <module>
  File "<stdin>", line 146, in diagnose
  File "/mnt/data/asr-env/lib/python3.12/site-packages/pyctcdecode/decoder.py", line 716, in decode
    decoded_beams = self.decode_beams(
                    ^^^^^^^^^^^^^^^^^^
  File "/mnt/data/asr-env/lib/python3.12/site-packages/pyctcdecode/decoder.py", line 586, in decode_beams
    self._check_logits_dimension(logits)
  File "/mnt/data/asr-env/lib/python3.12/site-packages/pyctcdecode/decoder.py", line 307, in _check_logits_dimension
    raise ValueError(
ValueError: Input logits shape is (85, 4025), but vocabulary is size 4026. Need logits of shape: (time, vocabulary)
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# python - <<'EOF'
import torch                                                run_grid_search.py --kenlm "data/training/wiki_subword_6gram.arpa"
                                                     rm run_grid_search.py
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# python - <<'EOF'
import torch                                                run_grid_search.py --kenlm "data/training/wiki_subword_6gram.arpa"
                                                     nano run_grid_search.py
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# python - <<'EOF'
import torch                                                run_grid_search.py --kenlm "data/training/wiki_subword_6gram.arpa"
                                                     nano run_grid_search.py^C
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# python run_grid_search.py --kenlm "data/training/wiki_subword_6gram.arpa"
fused_indices_to_multihot has reached end of life. Please migrate to a non-experimental function.
OneLogger: Setting error_handling_strategy to DISABLE_QUIETLY_AND_REPORT_METRIC_ERROR for rank (rank=0) with OneLogger disabled. To override: explicitly set error_handling_strategy parameter.
No exporters were provided. This means that no telemetry data will be collected.
 Device: cuda
 KenLM: data/training/wiki_subword_6gram.arpa
 Loading Model...
[NeMo I 2026-01-23 01:53:13 mixins:208] _setup_tokenizer: detected an aggregate tokenizer
[NeMo I 2026-01-23 01:53:13 mixins:347] Tokenizer SentencePieceTokenizer initialized with 1024 tokens
[NeMo I 2026-01-23 01:53:13 mixins:347] Tokenizer SentencePieceTokenizer initialized with 3000 tokens
[NeMo I 2026-01-23 01:53:13 aggregate_tokenizer:73] Aggregate vocab size: 4024
[NeMo W 2026-01-23 01:53:20 modelPT:188] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.
    Train config : 
    manifest_filepath: data/training/v2/master_manifest.json
    sample_rate: 16000
    batch_size: 32
    shuffle: true
    num_workers: 16
    pin_memory: true
    use_start_end_token: false
    min_duration: 1.5
    max_duration: 40.0
    prefetch_factor: 4
    
[NeMo W 2026-01-23 01:53:20 modelPT:195] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). 
    Validation config : 
    manifest_filepath:
    - /mnt/data/asr-finetuning/evaluation/benchmarking/data/v1/en_clean_read.json
    - /mnt/data/asr-finetuning/evaluation/benchmarking/data/v1/kn_clean_read.json
    sample_rate: 16000
    batch_size: 32
    shuffle: false
    num_workers: 16
    
[NeMo W 2026-01-23 01:53:20 modelPT:202] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).
    Test config : 
    manifest_filepath: null
    sample_rate: 16000
    batch_size: 16
    shuffle: false
    num_workers: 8
    pin_memory: true
    use_start_end_token: false
    
[NeMo I 2026-01-23 01:53:22 rnnt_models:226] Using RNNT Loss : warprnnt_numba
    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}
[NeMo I 2026-01-23 01:53:22 rnnt_models:226] Using RNNT Loss : warprnnt_numba
    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}
[NeMo W 2026-01-23 01:53:22 label_looping_base:123] No conditional node support for Cuda.
    Cuda graphs with while loops are disabled, decoding speed will be slower
    Reason: Driver supports cuda toolkit version 12.4, but the driver needs to support at least 12,6. Please update your cuda driver.
[NeMo I 2026-01-23 01:53:23 rnnt_models:226] Using RNNT Loss : warprnnt_numba
    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}
[NeMo W 2026-01-23 01:53:23 label_looping_base:123] No conditional node support for Cuda.
    Cuda graphs with while loops are disabled, decoding speed will be slower
    Reason: Driver supports cuda toolkit version 12.4, but the driver needs to support at least 12,6. Please update your cuda driver.
[NeMo I 2026-01-23 01:53:25 save_restore_connector:285] Model EncDecHybridRNNTCTCBPEModel was successfully restored from /mnt/data/asr-finetuning/training/models/kathbath_hybrid_h200_scaleup_p3_phase3_final.nemo.
 Pre-computing logits for 128 files...
100%|| 128/128 [00:10<00:00, 12.77it/s]
 Aligning Vocab & Loading KenLM...
 Model CTC Output Size: 4025
  Padding vocab with 1 blank token(s)...
 Final Vocab Size: 4025 (Matches Model)

==================================================
 STARTING GRID SEARCH (FORCE ALIGNED)
==================================================
Alpha    | Beta     | WER     
--------------------------------------------------
Loading the LM will be faster if you build a binary file.
Reading /mnt/data/asr-finetuning/data/training/wiki_subword_6gram.arpa
----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100
****************************************************************************************************
Traceback (most recent call last):
  File "/mnt/data/asr-finetuning/run_grid_search.py", line 217, in <module>
    run_grid_search()
  File "/mnt/data/asr-finetuning/run_grid_search.py", line 186, in run_grid_search
    raw_text = decoder.decode(logits, beam_width=64)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/data/asr-env/lib/python3.12/site-packages/pyctcdecode/decoder.py", line 716, in decode
    decoded_beams = self.decode_beams(
                    ^^^^^^^^^^^^^^^^^^
  File "/mnt/data/asr-env/lib/python3.12/site-packages/pyctcdecode/decoder.py", line 586, in decode_beams
    self._check_logits_dimension(logits)
  File "/mnt/data/asr-env/lib/python3.12/site-packages/pyctcdecode/decoder.py", line 307, in _check_logits_dimension
    raise ValueError(
ValueError: Input logits shape is (85, 4025), but vocabulary is size 4026. Need logits of shape: (time, vocabulary)
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# rm run_grid_search.py
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# nano run_grid_search.py
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# python run_grid_search.py --kenlm "data/training/wiki_subword_6gram.arpa"
fused_indices_to_multihot has reached end of life. Please migrate to a non-experimental function.
OneLogger: Setting error_handling_strategy to DISABLE_QUIETLY_AND_REPORT_METRIC_ERROR for rank (rank=0) with OneLogger disabled. To override: explicitly set error_handling_strategy parameter.
No exporters were provided. This means that no telemetry data will be collected.
 Device: cuda
 KenLM: data/training/wiki_subword_6gram.arpa
 Loading Model...
[NeMo I 2026-01-23 01:55:45 mixins:208] _setup_tokenizer: detected an aggregate tokenizer
[NeMo I 2026-01-23 01:55:45 mixins:347] Tokenizer SentencePieceTokenizer initialized with 1024 tokens
[NeMo I 2026-01-23 01:55:45 mixins:347] Tokenizer SentencePieceTokenizer initialized with 3000 tokens
[NeMo I 2026-01-23 01:55:45 aggregate_tokenizer:73] Aggregate vocab size: 4024
[NeMo W 2026-01-23 01:55:51 modelPT:188] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.
    Train config : 
    manifest_filepath: data/training/v2/master_manifest.json
    sample_rate: 16000
    batch_size: 32
    shuffle: true
    num_workers: 16
    pin_memory: true
    use_start_end_token: false
    min_duration: 1.5
    max_duration: 40.0
    prefetch_factor: 4
    
[NeMo W 2026-01-23 01:55:51 modelPT:195] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). 
    Validation config : 
    manifest_filepath:
    - /mnt/data/asr-finetuning/evaluation/benchmarking/data/v1/en_clean_read.json
    - /mnt/data/asr-finetuning/evaluation/benchmarking/data/v1/kn_clean_read.json
    sample_rate: 16000
    batch_size: 32
    shuffle: false
    num_workers: 16
    
[NeMo W 2026-01-23 01:55:51 modelPT:202] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).
    Test config : 
    manifest_filepath: null
    sample_rate: 16000
    batch_size: 16
    shuffle: false
    num_workers: 8
    pin_memory: true
    use_start_end_token: false
    
[NeMo I 2026-01-23 01:55:53 rnnt_models:226] Using RNNT Loss : warprnnt_numba
    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}
[NeMo I 2026-01-23 01:55:53 rnnt_models:226] Using RNNT Loss : warprnnt_numba
    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}
[NeMo W 2026-01-23 01:55:53 label_looping_base:123] No conditional node support for Cuda.
    Cuda graphs with while loops are disabled, decoding speed will be slower
    Reason: Driver supports cuda toolkit version 12.4, but the driver needs to support at least 12,6. Please update your cuda driver.
[NeMo I 2026-01-23 01:55:54 rnnt_models:226] Using RNNT Loss : warprnnt_numba
    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}
[NeMo W 2026-01-23 01:55:54 label_looping_base:123] No conditional node support for Cuda.
    Cuda graphs with while loops are disabled, decoding speed will be slower
    Reason: Driver supports cuda toolkit version 12.4, but the driver needs to support at least 12,6. Please update your cuda driver.
[NeMo I 2026-01-23 01:55:58 save_restore_connector:285] Model EncDecHybridRNNTCTCBPEModel was successfully restored from /mnt/data/asr-finetuning/training/models/kathbath_hybrid_h200_scaleup_p3_phase3_final.nemo.
 Measuring exact model output size...
 EXACT Logit Size: 4025
 Pre-computing logits for 128 files...
100%|| 128/128 [00:08<00:00, 15.88it/s]
 Configuring Decoder with exactly 4025 labels...
  Padding vocab from 4024 to 4025 with '<blank>'

==================================================
 STARTING GRID SEARCH (NUCLEAR FIXED)
==================================================
Alpha    | Beta     | WER     
--------------------------------------------------
Loading the LM will be faster if you build a binary file.
Reading /mnt/data/asr-finetuning/data/training/wiki_subword_6gram.arpa
----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100
****************************************************************************************************
Traceback (most recent call last):
  File "/mnt/data/asr-finetuning/run_grid_search.py", line 230, in <module>
    run_grid_search()
  File "/mnt/data/asr-finetuning/run_grid_search.py", line 199, in run_grid_search
    raw_text = decoder.decode(logits, beam_width=64)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/data/asr-env/lib/python3.12/site-packages/pyctcdecode/decoder.py", line 716, in decode
    decoded_beams = self.decode_beams(
                    ^^^^^^^^^^^^^^^^^^
  File "/mnt/data/asr-env/lib/python3.12/site-packages/pyctcdecode/decoder.py", line 586, in decode_beams
    self._check_logits_dimension(logits)
  File "/mnt/data/asr-env/lib/python3.12/site-packages/pyctcdecode/decoder.py", line 307, in _check_logits_dimension
    raise ValueError(
ValueError: Input logits shape is (85, 4025), but vocabulary is size 4026. Need logits of shape: (time, vocabulary)
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# rm run_grid_search.py
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# nano run_grid_search.py
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# python run_grid_search.py --kenlm "data/training/wiki_subword_6gram.arpa"
fused_indices_to_multihot has reached end of life. Please migrate to a non-experimental function.
OneLogger: Setting error_handling_strategy to DISABLE_QUIETLY_AND_REPORT_METRIC_ERROR for rank (rank=0) with OneLogger disabled. To override: explicitly set error_handling_strategy parameter.
No exporters were provided. This means that no telemetry data will be collected.
 Device: cuda
 KenLM: data/training/wiki_subword_6gram.arpa
 Loading Model...
[NeMo I 2026-01-23 01:58:36 mixins:208] _setup_tokenizer: detected an aggregate tokenizer
[NeMo I 2026-01-23 01:58:36 mixins:347] Tokenizer SentencePieceTokenizer initialized with 1024 tokens
[NeMo I 2026-01-23 01:58:36 mixins:347] Tokenizer SentencePieceTokenizer initialized with 3000 tokens
[NeMo I 2026-01-23 01:58:36 aggregate_tokenizer:73] Aggregate vocab size: 4024
[NeMo W 2026-01-23 01:58:40 modelPT:188] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.
    Train config : 
    manifest_filepath: data/training/v2/master_manifest.json
    sample_rate: 16000
    batch_size: 32
    shuffle: true
    num_workers: 16
    pin_memory: true
    use_start_end_token: false
    min_duration: 1.5
    max_duration: 40.0
    prefetch_factor: 4
    
[NeMo W 2026-01-23 01:58:40 modelPT:195] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). 
    Validation config : 
    manifest_filepath:
    - /mnt/data/asr-finetuning/evaluation/benchmarking/data/v1/en_clean_read.json
    - /mnt/data/asr-finetuning/evaluation/benchmarking/data/v1/kn_clean_read.json
    sample_rate: 16000
    batch_size: 32
    shuffle: false
    num_workers: 16
    
[NeMo W 2026-01-23 01:58:40 modelPT:202] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).
    Test config : 
    manifest_filepath: null
    sample_rate: 16000
    batch_size: 16
    shuffle: false
    num_workers: 8
    pin_memory: true
    use_start_end_token: false
    
[NeMo I 2026-01-23 01:58:42 rnnt_models:226] Using RNNT Loss : warprnnt_numba
    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}
[NeMo I 2026-01-23 01:58:42 rnnt_models:226] Using RNNT Loss : warprnnt_numba
    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}
[NeMo W 2026-01-23 01:58:42 label_looping_base:123] No conditional node support for Cuda.
    Cuda graphs with while loops are disabled, decoding speed will be slower
    Reason: Driver supports cuda toolkit version 12.4, but the driver needs to support at least 12,6. Please update your cuda driver.
[NeMo I 2026-01-23 01:58:43 rnnt_models:226] Using RNNT Loss : warprnnt_numba
    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}
[NeMo W 2026-01-23 01:58:43 label_looping_base:123] No conditional node support for Cuda.
    Cuda graphs with while loops are disabled, decoding speed will be slower
    Reason: Driver supports cuda toolkit version 12.4, but the driver needs to support at least 12,6. Please update your cuda driver.
[NeMo I 2026-01-23 01:58:45 save_restore_connector:285] Model EncDecHybridRNNTCTCBPEModel was successfully restored from /mnt/data/asr-finetuning/training/models/kathbath_hybrid_h200_scaleup_p3_phase3_final.nemo.
 Loading Manifest...
 Computing logits for 128 files...
100%|| 128/128 [00:08<00:00, 15.27it/s]

 DETECTED LOGIT DIMENSION: 4025
 INITIAL VOCAB SIZE: 4024
  Padding vocab with 1 blank(s) to match logits.
 FINAL VOCAB SIZE: 4025 (Must match 4025)

==================================================
 STARTING GRID SEARCH (LAZY ALIGNMENT)
==================================================
Alpha    | Beta     | WER     
--------------------------------------------------
Loading the LM will be faster if you build a binary file.
Reading /mnt/data/asr-finetuning/data/training/wiki_subword_6gram.arpa
----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100
****************************************************************************************************
Traceback (most recent call last):
  File "/mnt/data/asr-finetuning/run_grid_search.py", line 197, in <module>
    run_grid_search()
  File "/mnt/data/asr-finetuning/run_grid_search.py", line 166, in run_grid_search
    raw_text = decoder.decode(logits, beam_width=64)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/data/asr-env/lib/python3.12/site-packages/pyctcdecode/decoder.py", line 716, in decode
    decoded_beams = self.decode_beams(
                    ^^^^^^^^^^^^^^^^^^
  File "/mnt/data/asr-env/lib/python3.12/site-packages/pyctcdecode/decoder.py", line 586, in decode_beams
    self._check_logits_dimension(logits)
  File "/mnt/data/asr-env/lib/python3.12/site-packages/pyctcdecode/decoder.py", line 307, in _check_logits_dimension
    raise ValueError(
ValueError: Input logits shape is (85, 4025), but vocabulary is size 4026. Need logits of shape: (time, vocabulary)
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# rm run_grid_search.py
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# nano run_grid_search.py
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# rm run_grid_search.py
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# nano run_grid_search.py
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# python run_grid_search.py --kenlm "data/training/wiki_subword_6gram.arpa"
fused_indices_to_multihot has reached end of life. Please migrate to a non-experimental function.
OneLogger: Setting error_handling_strategy to DISABLE_QUIETLY_AND_REPORT_METRIC_ERROR for rank (rank=0) with OneLogger disabled. To override: explicitly set error_handling_strategy parameter.
No exporters were provided. This means that no telemetry data will be collected.
 RUNNING SELF-HEALING SCRIPT v2.0
 Device: cuda
 KenLM: data/training/wiki_subword_6gram.arpa
 Loading Model...
[NeMo I 2026-01-23 02:03:34 mixins:208] _setup_tokenizer: detected an aggregate tokenizer
[NeMo I 2026-01-23 02:03:34 mixins:347] Tokenizer SentencePieceTokenizer initialized with 1024 tokens
[NeMo I 2026-01-23 02:03:34 mixins:347] Tokenizer SentencePieceTokenizer initialized with 3000 tokens
[NeMo I 2026-01-23 02:03:34 aggregate_tokenizer:73] Aggregate vocab size: 4024
[NeMo W 2026-01-23 02:03:40 modelPT:188] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.
    Train config : 
    manifest_filepath: data/training/v2/master_manifest.json
    sample_rate: 16000
    batch_size: 32
    shuffle: true
    num_workers: 16
    pin_memory: true
    use_start_end_token: false
    min_duration: 1.5
    max_duration: 40.0
    prefetch_factor: 4
    
[NeMo W 2026-01-23 02:03:40 modelPT:195] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). 
    Validation config : 
    manifest_filepath:
    - /mnt/data/asr-finetuning/evaluation/benchmarking/data/v1/en_clean_read.json
    - /mnt/data/asr-finetuning/evaluation/benchmarking/data/v1/kn_clean_read.json
    sample_rate: 16000
    batch_size: 32
    shuffle: false
    num_workers: 16
    
[NeMo W 2026-01-23 02:03:40 modelPT:202] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).
    Test config : 
    manifest_filepath: null
    sample_rate: 16000
    batch_size: 16
    shuffle: false
    num_workers: 8
    pin_memory: true
    use_start_end_token: false
    
[NeMo I 2026-01-23 02:03:42 rnnt_models:226] Using RNNT Loss : warprnnt_numba
    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}
[NeMo I 2026-01-23 02:03:42 rnnt_models:226] Using RNNT Loss : warprnnt_numba
    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}
[NeMo W 2026-01-23 02:03:42 label_looping_base:123] No conditional node support for Cuda.
    Cuda graphs with while loops are disabled, decoding speed will be slower
    Reason: Driver supports cuda toolkit version 12.4, but the driver needs to support at least 12,6. Please update your cuda driver.
[NeMo I 2026-01-23 02:03:43 rnnt_models:226] Using RNNT Loss : warprnnt_numba
    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}
[NeMo W 2026-01-23 02:03:43 label_looping_base:123] No conditional node support for Cuda.
    Cuda graphs with while loops are disabled, decoding speed will be slower
    Reason: Driver supports cuda toolkit version 12.4, but the driver needs to support at least 12,6. Please update your cuda driver.
[NeMo I 2026-01-23 02:03:47 save_restore_connector:285] Model EncDecHybridRNNTCTCBPEModel was successfully restored from /mnt/data/asr-finetuning/training/models/kathbath_hybrid_h200_scaleup_p3_phase3_final.nemo.
 Computing logits for 128 files...
100%|| 128/128 [00:10<00:00, 12.64it/s]
 TARGET VOCAB SIZE: 4025 (Detected from model output)

==================================================
 STARTING GRID SEARCH
==================================================
Alpha    | Beta     | WER     
--------------------------------------------------
Loading the LM will be faster if you build a binary file.
Reading /mnt/data/asr-finetuning/data/training/wiki_subword_6gram.arpa
----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100
****************************************************************************************************
Traceback (most recent call last):
  File "/mnt/data/asr-finetuning/run_grid_search.py", line 201, in <module>
    run_grid_search()
  File "/mnt/data/asr-finetuning/run_grid_search.py", line 170, in run_grid_search
    raw_text = decoder.decode(logits, beam_width=64)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/data/asr-env/lib/python3.12/site-packages/pyctcdecode/decoder.py", line 716, in decode
    decoded_beams = self.decode_beams(
                    ^^^^^^^^^^^^^^^^^^
  File "/mnt/data/asr-env/lib/python3.12/site-packages/pyctcdecode/decoder.py", line 586, in decode_beams
    self._check_logits_dimension(logits)
  File "/mnt/data/asr-env/lib/python3.12/site-packages/pyctcdecode/decoder.py", line 307, in _check_logits_dimension
    raise ValueError(
ValueError: Input logits shape is (85, 4025), but vocabulary is size 4026. Need logits of shape: (time, vocabulary)
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# rm run_grid_search.py
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# nano run_grid_search.py
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# python run_grid_search.py --kenlm "data/training/wiki_subword_6gram.arpa"
fused_indices_to_multihot has reached end of life. Please migrate to a non-experimental function.
OneLogger: Setting error_handling_strategy to DISABLE_QUIETLY_AND_REPORT_METRIC_ERROR for rank (rank=0) with OneLogger disabled. To override: explicitly set error_handling_strategy parameter.
No exporters were provided. This means that no telemetry data will be collected.
 RUNNING BRUTE-FORCE SCRIPT
 Loading Model...
[NeMo I 2026-01-23 02:05:52 mixins:208] _setup_tokenizer: detected an aggregate tokenizer
[NeMo I 2026-01-23 02:05:52 mixins:347] Tokenizer SentencePieceTokenizer initialized with 1024 tokens
[NeMo I 2026-01-23 02:05:52 mixins:347] Tokenizer SentencePieceTokenizer initialized with 3000 tokens
[NeMo I 2026-01-23 02:05:52 aggregate_tokenizer:73] Aggregate vocab size: 4024
[NeMo W 2026-01-23 02:05:59 modelPT:188] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.
    Train config : 
    manifest_filepath: data/training/v2/master_manifest.json
    sample_rate: 16000
    batch_size: 32
    shuffle: true
    num_workers: 16
    pin_memory: true
    use_start_end_token: false
    min_duration: 1.5
    max_duration: 40.0
    prefetch_factor: 4
    
[NeMo W 2026-01-23 02:05:59 modelPT:195] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). 
    Validation config : 
    manifest_filepath:
    - /mnt/data/asr-finetuning/evaluation/benchmarking/data/v1/en_clean_read.json
    - /mnt/data/asr-finetuning/evaluation/benchmarking/data/v1/kn_clean_read.json
    sample_rate: 16000
    batch_size: 32
    shuffle: false
    num_workers: 16
    
[NeMo W 2026-01-23 02:05:59 modelPT:202] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).
    Test config : 
    manifest_filepath: null
    sample_rate: 16000
    batch_size: 16
    shuffle: false
    num_workers: 8
    pin_memory: true
    use_start_end_token: false
    
[NeMo I 2026-01-23 02:06:00 rnnt_models:226] Using RNNT Loss : warprnnt_numba
    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}
[NeMo I 2026-01-23 02:06:00 rnnt_models:226] Using RNNT Loss : warprnnt_numba
    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}
[NeMo W 2026-01-23 02:06:01 label_looping_base:123] No conditional node support for Cuda.
    Cuda graphs with while loops are disabled, decoding speed will be slower
    Reason: Driver supports cuda toolkit version 12.4, but the driver needs to support at least 12,6. Please update your cuda driver.
[NeMo I 2026-01-23 02:06:01 rnnt_models:226] Using RNNT Loss : warprnnt_numba
    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}
[NeMo W 2026-01-23 02:06:01 label_looping_base:123] No conditional node support for Cuda.
    Cuda graphs with while loops are disabled, decoding speed will be slower
    Reason: Driver supports cuda toolkit version 12.4, but the driver needs to support at least 12,6. Please update your cuda driver.
[NeMo I 2026-01-23 02:06:05 save_restore_connector:285] Model EncDecHybridRNNTCTCBPEModel was successfully restored from /mnt/data/asr-finetuning/training/models/kathbath_hybrid_h200_scaleup_p3_phase3_final.nemo.
 Initial Tokenizer Vocab Size: 4024
 Pre-computing logits for 128 files...
100%|| 128/128 [00:10<00:00, 12.70it/s]

 EXACT LOGIT DIMENSION: 4025
  Padding vocab from 4024 up to 4025
 FINAL VOCAB SIZE: 4025 (MUST match 4025)

==================================================
 STARTING GRID SEARCH
==================================================
Alpha    | Beta     | WER     
--------------------------------------------------
Loading the LM will be faster if you build a binary file.
Reading /mnt/data/asr-finetuning/data/training/wiki_subword_6gram.arpa
----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100
****************************************************************************************************
Traceback (most recent call last):
  File "/mnt/data/asr-finetuning/run_grid_search.py", line 202, in <module>
    run_grid_search()
  File "/mnt/data/asr-finetuning/run_grid_search.py", line 171, in run_grid_search
    raw_text = decoder.decode(logits, beam_width=64)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/data/asr-env/lib/python3.12/site-packages/pyctcdecode/decoder.py", line 716, in decode
    decoded_beams = self.decode_beams(
                    ^^^^^^^^^^^^^^^^^^
  File "/mnt/data/asr-env/lib/python3.12/site-packages/pyctcdecode/decoder.py", line 586, in decode_beams
    self._check_logits_dimension(logits)
  File "/mnt/data/asr-env/lib/python3.12/site-packages/pyctcdecode/decoder.py", line 307, in _check_logits_dimension
    raise ValueError(
ValueError: Input logits shape is (85, 4025), but vocabulary is size 4026. Need logits of shape: (time, vocabulary)
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# python - <<'EOF'
import torch
import numpy as np
import librosa
import json
from nemo.collections.asr.models import EncDecHybridRNNTCTCBPEModel

# CONFIG
MODEL_PATH = "training/models/kathbath_hybrid_h200_scaleup_p3_phase3_final.nemo"
MANIFEST_PATH = "evaluation/benchmarking/curation/test_data/Kathbath/test_manifest.json"

def diagnose():
    print(" STARTING DIAGNOSIS...")
    
    # 1. LOAD MODEL
    print(f" Loading Model: {MODEL_PATH}")
    model = EncDecHybridRNNTCTCBPEModel.restore_from(MODEL_PATH, map_location="cpu")
    model.eval()

    # 2. INSPECT TOKENIZER (SOURCE OF TRUTH 1)
    vocab_size_reported = model.tokenizer.vocab_size
    print(f"\n--- TOKENIZER STATS ---")
    print(f"1. Tokenizer.vocab_size reports: {vocab_size_reported}")
    
    # Extract the raw list
    vocab_list = []
    if hasattr(model.tokenizer, 'ids_to_tokens'):
        # Method A: ids_to_tokens
        vocab_list = model.tokenizer.ids_to_tokens(list(range(vocab_size_reported)))
    else:
        # Method B: id_to_text fallback
        for i in range(vocab_size_reported):
            vocab_list.append(model.tokenizer.ids_to_text([i]))
            
    print(f"2. Actual length of extracted list: {len(vocab_list)}")
    print(f"3. First 5 tokens: {vocab_list[:5]}")
    print(f"4. Last 5 tokens:  {vocab_list[-5:]}")

    # 3. INSPECT MODEL OUTPUT (SOURCE OF TRUTH 2)
    print(f"\n--- MODEL OUTPUT STATS ---")
    # Run one dummy file to get undeniable truth
    with open(MANIFEST_PATH, 'r') as f:
        path = json.loads(f.readline())['audio_filepath']
    
    print(f" Running inference on: {path}")
    audio, _ = librosa.load(path, sr=16000)
    tensor = torch.tensor(audio, dtype=torch.float32).unsqueeze(0)
    length = torch.tensor([len(audio)])
    
    with torch.no_grad():
        p_sig, p_len = model.preprocessor(input_signal=tensor, length=length)
        enc, enc_len = model.encoder(audio_signal=p_sig, length=p_len)
        log_probs = model.ctc_decoder(encoder_output=enc)
        logits = log_probs[0].numpy()
        
    logit_dim = logits.shape[1]
    print(f" EXACT LOGIT DIMENSION: {logit_dim}")
    
EOF diagnose() "__main__":tokens at the end are: {simulated_vocab[-3:]}")?")
fused_indices_to_multihot has reached end of life. Please migrate to a non-experimental function.
OneLogger: Setting error_handling_strategy to DISABLE_QUIETLY_AND_REPORT_METRIC_ERROR for rank (rank=0) with OneLogger disabled. To override: explicitly set error_handling_strategy parameter.
No exporters were provided. This means that no telemetry data will be collected.
 STARTING DIAGNOSIS...
 Loading Model: training/models/kathbath_hybrid_h200_scaleup_p3_phase3_final.nemo
[NeMo I 2026-01-23 02:08:47 mixins:208] _setup_tokenizer: detected an aggregate tokenizer
[NeMo I 2026-01-23 02:08:47 mixins:347] Tokenizer SentencePieceTokenizer initialized with 1024 tokens
[NeMo I 2026-01-23 02:08:47 mixins:347] Tokenizer SentencePieceTokenizer initialized with 3000 tokens
[NeMo I 2026-01-23 02:08:47 aggregate_tokenizer:73] Aggregate vocab size: 4024
[NeMo W 2026-01-23 02:08:52 modelPT:188] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.
    Train config : 
    manifest_filepath: data/training/v2/master_manifest.json
    sample_rate: 16000
    batch_size: 32
    shuffle: true
    num_workers: 16
    pin_memory: true
    use_start_end_token: false
    min_duration: 1.5
    max_duration: 40.0
    prefetch_factor: 4
    
[NeMo W 2026-01-23 02:08:52 modelPT:195] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). 
    Validation config : 
    manifest_filepath:
    - /mnt/data/asr-finetuning/evaluation/benchmarking/data/v1/en_clean_read.json
    - /mnt/data/asr-finetuning/evaluation/benchmarking/data/v1/kn_clean_read.json
    sample_rate: 16000
    batch_size: 32
    shuffle: false
    num_workers: 16
    
[NeMo W 2026-01-23 02:08:52 modelPT:202] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).
    Test config : 
    manifest_filepath: null
    sample_rate: 16000
    batch_size: 16
    shuffle: false
    num_workers: 8
    pin_memory: true
    use_start_end_token: false
    
[NeMo I 2026-01-23 02:08:54 rnnt_models:226] Using RNNT Loss : warprnnt_numba
    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}
[NeMo I 2026-01-23 02:08:54 rnnt_models:226] Using RNNT Loss : warprnnt_numba
    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}
[NeMo W 2026-01-23 02:08:54 label_looping_base:123] No conditional node support for Cuda.
    Cuda graphs with while loops are disabled, decoding speed will be slower
    Reason: Driver supports cuda toolkit version 12.4, but the driver needs to support at least 12,6. Please update your cuda driver.
[NeMo I 2026-01-23 02:08:55 rnnt_models:226] Using RNNT Loss : warprnnt_numba
    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}
[NeMo W 2026-01-23 02:08:55 label_looping_base:123] No conditional node support for Cuda.
    Cuda graphs with while loops are disabled, decoding speed will be slower
    Reason: Driver supports cuda toolkit version 12.4, but the driver needs to support at least 12,6. Please update your cuda driver.
[NeMo I 2026-01-23 02:08:56 save_restore_connector:285] Model EncDecHybridRNNTCTCBPEModel was successfully restored from /mnt/data/asr-finetuning/training/models/kathbath_hybrid_h200_scaleup_p3_phase3_final.nemo.

--- TOKENIZER STATS ---
1. Tokenizer.vocab_size reports: 4024
2. Actual length of extracted list: 4024
3. First 5 tokens: ['<unk>', 's', 'the', 't', 'a']
4. Last 5 tokens:  ['', '', '', '', '']

--- MODEL OUTPUT STATS ---
 Running inference on: /mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_0.wav
 EXACT LOGIT DIMENSION: 4025

--- THE CONFLICT ---
Tokenizer List Length: 4024
Model Output Width:    4025
Difference:            1
Diagnosis: Model has 1 extra output (Blank).
Action: We must append exactly ONE <blank> token.

--- SIMULATING THE CRASH LIST ---
Simulated List Length: 4025
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# python - <<'EOF'
import torch                                                run_grid_search.py --kenlm "data/training/wiki_subword_6gram.arpa"
                                                     rm run_grid_search.py
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# python - <<'EOF'
import torch                                                run_grid_search.py --kenlm "data/training/wiki_subword_6gram.arpa"
                                                     nano run_grid_search.py
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# python - <<'EOF'
import torch                                                run_grid_search.py --kenlm "data/training/wiki_subword_6gram.arpa"
                                                     python run_grid_search.py --kenlm "data/training/wiki_subword_6gram.arpa"
fused_indices_to_multihot has reached end of life. Please migrate to a non-experimental function.
OneLogger: Setting error_handling_strategy to DISABLE_QUIETLY_AND_REPORT_METRIC_ERROR for rank (rank=0) with OneLogger disabled. To override: explicitly set error_handling_strategy parameter.
No exporters were provided. This means that no telemetry data will be collected.
 RUNNING PARANOID SCRIPT
 Loading Model...
[NeMo I 2026-01-23 02:12:08 mixins:208] _setup_tokenizer: detected an aggregate tokenizer
[NeMo I 2026-01-23 02:12:08 mixins:347] Tokenizer SentencePieceTokenizer initialized with 1024 tokens
[NeMo I 2026-01-23 02:12:08 mixins:347] Tokenizer SentencePieceTokenizer initialized with 3000 tokens
[NeMo I 2026-01-23 02:12:08 aggregate_tokenizer:73] Aggregate vocab size: 4024
[NeMo W 2026-01-23 02:12:13 modelPT:188] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.
    Train config : 
    manifest_filepath: data/training/v2/master_manifest.json
    sample_rate: 16000
    batch_size: 32
    shuffle: true
    num_workers: 16
    pin_memory: true
    use_start_end_token: false
    min_duration: 1.5
    max_duration: 40.0
    prefetch_factor: 4
    
[NeMo W 2026-01-23 02:12:13 modelPT:195] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). 
    Validation config : 
    manifest_filepath:
    - /mnt/data/asr-finetuning/evaluation/benchmarking/data/v1/en_clean_read.json
    - /mnt/data/asr-finetuning/evaluation/benchmarking/data/v1/kn_clean_read.json
    sample_rate: 16000
    batch_size: 32
    shuffle: false
    num_workers: 16
    
[NeMo W 2026-01-23 02:12:13 modelPT:202] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).
    Test config : 
    manifest_filepath: null
    sample_rate: 16000
    batch_size: 16
    shuffle: false
    num_workers: 8
    pin_memory: true
    use_start_end_token: false
    
[NeMo I 2026-01-23 02:12:15 rnnt_models:226] Using RNNT Loss : warprnnt_numba
    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}
[NeMo I 2026-01-23 02:12:15 rnnt_models:226] Using RNNT Loss : warprnnt_numba
    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}
[NeMo W 2026-01-23 02:12:15 label_looping_base:123] No conditional node support for Cuda.
    Cuda graphs with while loops are disabled, decoding speed will be slower
    Reason: Driver supports cuda toolkit version 12.4, but the driver needs to support at least 12,6. Please update your cuda driver.
[NeMo I 2026-01-23 02:12:15 rnnt_models:226] Using RNNT Loss : warprnnt_numba
    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}
[NeMo W 2026-01-23 02:12:15 label_looping_base:123] No conditional node support for Cuda.
    Cuda graphs with while loops are disabled, decoding speed will be slower
    Reason: Driver supports cuda toolkit version 12.4, but the driver needs to support at least 12,6. Please update your cuda driver.
[NeMo I 2026-01-23 02:12:19 save_restore_connector:285] Model EncDecHybridRNNTCTCBPEModel was successfully restored from /mnt/data/asr-finetuning/training/models/kathbath_hybrid_h200_scaleup_p3_phase3_final.nemo.
 FINAL VOCAB SIZE PASSED TO DECODER: 4025
 Pre-computing logits for 128 files...
100%|| 128/128 [00:09<00:00, 13.93it/s]

==================================================
 STARTING GRID SEARCH
==================================================
Alpha    | Beta     | WER     
--------------------------------------------------
Loading the LM will be faster if you build a binary file.
Reading /mnt/data/asr-finetuning/data/training/wiki_subword_6gram.arpa
----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100
****************************************************************************************************
Traceback (most recent call last):
  File "/mnt/data/asr-finetuning/run_grid_search.py", line 187, in <module>
    run_grid_search()
  File "/mnt/data/asr-finetuning/run_grid_search.py", line 156, in run_grid_search
    raw_text = decoder.decode(logits, beam_width=64)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/data/asr-env/lib/python3.12/site-packages/pyctcdecode/decoder.py", line 716, in decode
    decoded_beams = self.decode_beams(
                    ^^^^^^^^^^^^^^^^^^
  File "/mnt/data/asr-env/lib/python3.12/site-packages/pyctcdecode/decoder.py", line 586, in decode_beams
    self._check_logits_dimension(logits)
  File "/mnt/data/asr-env/lib/python3.12/site-packages/pyctcdecode/decoder.py", line 307, in _check_logits_dimension
    raise ValueError(
ValueError: Input logits shape is (85, 4025), but vocabulary is size 4026. Need logits of shape: (time, vocabulary)
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# rm run_grid_search.py
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# nano run_grid_search.py
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# python run_grid_search.py --kenlm "data/training/wiki_subword_6gram.arpa"
fused_indices_to_multihot has reached end of life. Please migrate to a non-experimental function.
OneLogger: Setting error_handling_strategy to DISABLE_QUIETLY_AND_REPORT_METRIC_ERROR for rank (rank=0) with OneLogger disabled. To override: explicitly set error_handling_strategy parameter.
No exporters were provided. This means that no telemetry data will be collected.
 RUNNING PARANOID SCRIPT
 Loading Model...
[NeMo I 2026-01-23 02:15:57 mixins:208] _setup_tokenizer: detected an aggregate tokenizer
[NeMo I 2026-01-23 02:15:57 mixins:347] Tokenizer SentencePieceTokenizer initialized with 1024 tokens
[NeMo I 2026-01-23 02:15:57 mixins:347] Tokenizer SentencePieceTokenizer initialized with 3000 tokens
[NeMo I 2026-01-23 02:15:57 aggregate_tokenizer:73] Aggregate vocab size: 4024
[NeMo W 2026-01-23 02:16:01 modelPT:188] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.
    Train config : 
    manifest_filepath: data/training/v2/master_manifest.json
    sample_rate: 16000
    batch_size: 32
    shuffle: true
    num_workers: 16
    pin_memory: true
    use_start_end_token: false
    min_duration: 1.5
    max_duration: 40.0
    prefetch_factor: 4
    
[NeMo W 2026-01-23 02:16:01 modelPT:195] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). 
    Validation config : 
    manifest_filepath:
    - /mnt/data/asr-finetuning/evaluation/benchmarking/data/v1/en_clean_read.json
    - /mnt/data/asr-finetuning/evaluation/benchmarking/data/v1/kn_clean_read.json
    sample_rate: 16000
    batch_size: 32
    shuffle: false
    num_workers: 16
    
[NeMo W 2026-01-23 02:16:01 modelPT:202] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).
    Test config : 
    manifest_filepath: null
    sample_rate: 16000
    batch_size: 16
    shuffle: false
    num_workers: 8
    pin_memory: true
    use_start_end_token: false
    
[NeMo I 2026-01-23 02:16:03 rnnt_models:226] Using RNNT Loss : warprnnt_numba
    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}
[NeMo I 2026-01-23 02:16:03 rnnt_models:226] Using RNNT Loss : warprnnt_numba
    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}
[NeMo W 2026-01-23 02:16:03 label_looping_base:123] No conditional node support for Cuda.
    Cuda graphs with while loops are disabled, decoding speed will be slower
    Reason: Driver supports cuda toolkit version 12.4, but the driver needs to support at least 12,6. Please update your cuda driver.
[NeMo I 2026-01-23 02:16:04 rnnt_models:226] Using RNNT Loss : warprnnt_numba
    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}
[NeMo W 2026-01-23 02:16:04 label_looping_base:123] No conditional node support for Cuda.
    Cuda graphs with while loops are disabled, decoding speed will be slower
    Reason: Driver supports cuda toolkit version 12.4, but the driver needs to support at least 12,6. Please update your cuda driver.
[NeMo I 2026-01-23 02:16:07 save_restore_connector:285] Model EncDecHybridRNNTCTCBPEModel was successfully restored from /mnt/data/asr-finetuning/training/models/kathbath_hybrid_h200_scaleup_p3_phase3_final.nemo.
 FINAL VOCAB SIZE PASSED TO DECODER: 4025
 Pre-computing logits for 128 files...
100%|| 128/128 [00:09<00:00, 13.89it/s]

==================================================
 STARTING GRID SEARCH
==================================================
Alpha    | Beta     | WER     
--------------------------------------------------
Loading the LM will be faster if you build a binary file.
Reading /mnt/data/asr-finetuning/data/training/wiki_subword_6gram.arpa
----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100
****************************************************************************************************
Traceback (most recent call last):
  File "/mnt/data/asr-finetuning/run_grid_search.py", line 187, in <module>
    run_grid_search()
  File "/mnt/data/asr-finetuning/run_grid_search.py", line 156, in run_grid_search
    raw_text = decoder.decode(logits, beam_width=64)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/data/asr-env/lib/python3.12/site-packages/pyctcdecode/decoder.py", line 716, in decode
    decoded_beams = self.decode_beams(
                    ^^^^^^^^^^^^^^^^^^
  File "/mnt/data/asr-env/lib/python3.12/site-packages/pyctcdecode/decoder.py", line 586, in decode_beams
    self._check_logits_dimension(logits)
  File "/mnt/data/asr-env/lib/python3.12/site-packages/pyctcdecode/decoder.py", line 307, in _check_logits_dimension
    raise ValueError(
ValueError: Input logits shape is (85, 4025), but vocabulary is size 4026. Need logits of shape: (time, vocabulary)
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# nano final_eval.py
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# python final_eval.py
fused_indices_to_multihot has reached end of life. Please migrate to a non-experimental function.
OneLogger: Setting error_handling_strategy to DISABLE_QUIETLY_AND_REPORT_METRIC_ERROR for rank (rank=0) with OneLogger disabled. To override: explicitly set error_handling_strategy parameter.
No exporters were provided. This means that no telemetry data will be collected.
 RUNNING GOLDEN SCRIPT (final_eval.py) 
 Loading Model on cuda...
[NeMo I 2026-01-23 02:17:17 mixins:208] _setup_tokenizer: detected an aggregate tokenizer
[NeMo I 2026-01-23 02:17:17 mixins:347] Tokenizer SentencePieceTokenizer initialized with 1024 tokens
[NeMo I 2026-01-23 02:17:17 mixins:347] Tokenizer SentencePieceTokenizer initialized with 3000 tokens
[NeMo I 2026-01-23 02:17:17 aggregate_tokenizer:73] Aggregate vocab size: 4024
[NeMo W 2026-01-23 02:17:22 modelPT:188] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.
    Train config : 
    manifest_filepath: data/training/v2/master_manifest.json
    sample_rate: 16000
    batch_size: 32
    shuffle: true
    num_workers: 16
    pin_memory: true
    use_start_end_token: false
    min_duration: 1.5
    max_duration: 40.0
    prefetch_factor: 4
    
[NeMo W 2026-01-23 02:17:22 modelPT:195] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). 
    Validation config : 
    manifest_filepath:
    - /mnt/data/asr-finetuning/evaluation/benchmarking/data/v1/en_clean_read.json
    - /mnt/data/asr-finetuning/evaluation/benchmarking/data/v1/kn_clean_read.json
    sample_rate: 16000
    batch_size: 32
    shuffle: false
    num_workers: 16
    
[NeMo W 2026-01-23 02:17:22 modelPT:202] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).
    Test config : 
    manifest_filepath: null
    sample_rate: 16000
    batch_size: 16
    shuffle: false
    num_workers: 8
    pin_memory: true
    use_start_end_token: false
    
[NeMo I 2026-01-23 02:17:24 rnnt_models:226] Using RNNT Loss : warprnnt_numba
    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}
[NeMo I 2026-01-23 02:17:24 rnnt_models:226] Using RNNT Loss : warprnnt_numba
    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}
[NeMo W 2026-01-23 02:17:24 label_looping_base:123] No conditional node support for Cuda.
    Cuda graphs with while loops are disabled, decoding speed will be slower
    Reason: Driver supports cuda toolkit version 12.4, but the driver needs to support at least 12,6. Please update your cuda driver.
[NeMo I 2026-01-23 02:17:25 rnnt_models:226] Using RNNT Loss : warprnnt_numba
    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}
[NeMo W 2026-01-23 02:17:25 label_looping_base:123] No conditional node support for Cuda.
    Cuda graphs with while loops are disabled, decoding speed will be slower
    Reason: Driver supports cuda toolkit version 12.4, but the driver needs to support at least 12,6. Please update your cuda driver.
[NeMo I 2026-01-23 02:17:28 save_restore_connector:285] Model EncDecHybridRNNTCTCBPEModel was successfully restored from /mnt/data/asr-finetuning/training/models/kathbath_hybrid_h200_scaleup_p3_phase3_final.nemo.
 Loading Manifest...
 Computing logits for 128 files...
100%|| 128/128 [00:08<00:00, 15.11it/s]

 DETECTED LOGIT DIMENSION: 4025
  Padding vocab with 1 blank(s)
 Final Vocab Size: 4025 (Matches 4025)

 STARTING DECODING
Loading the LM will be faster if you build a binary file.
Reading /mnt/data/asr-finetuning/data/training/wiki_subword_6gram.arpa
----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100
****************************************************************************************************
Traceback (most recent call last):
  File "/mnt/data/asr-finetuning/final_eval.py", line 153, in <module>
    run_eval()
  File "/mnt/data/asr-finetuning/final_eval.py", line 137, in run_eval
    raw_text = decoder.decode(logits, beam_width=64)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/data/asr-env/lib/python3.12/site-packages/pyctcdecode/decoder.py", line 716, in decode
    decoded_beams = self.decode_beams(
                    ^^^^^^^^^^^^^^^^^^
  File "/mnt/data/asr-env/lib/python3.12/site-packages/pyctcdecode/decoder.py", line 586, in decode_beams
    self._check_logits_dimension(logits)
  File "/mnt/data/asr-env/lib/python3.12/site-packages/pyctcdecode/decoder.py", line 307, in _check_logits_dimension
    raise ValueError(
ValueError: Input logits shape is (85, 4025), but vocabulary is size 4026. Need logits of shape: (time, vocabulary)
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# python - <<'EOF'
import numpy as np
try:
    from pyctcdecode import build_ctcdecoder
except ImportError:
    print(" Error: pyctcdecode not found.")
    exit(1)

def run_sanity_check():
    print(" RUNNING ISOLATION TEST")
    
    # 1. Simulate the exact dimensions we observed
    TARGET_SIZE = 4025
    print(f" Target Dimension: {TARGET_SIZE}")

    # 2. Create a clean, dummy vocabulary
    # just ["token_0", "token_1", ..., "token_4024"]
    vocab = [f"t_{i}" for i in range(TARGET_SIZE)]
    print(f" Created Dummy Vocab of size: {len(vocab)}")

    # 3. Create dummy logits (Batch=1, Time=100, Class=4025)
    logits = np.random.rand(100, TARGET_SIZE)
    print(f" Created Dummy Logits of shape: {logits.shape}")

    # 4. Build Decoder
    print(" Building Decoder...")
    try:
        decoder = build_ctcdecoder(
            labels=vocab,
            kenlm_model_path=None, # Pure greedy decode, no LM to complicate things
        )
    except Exception as e:
        print(f" CRASH DURING BUILD: {e}")
        return

    # 5. Run Decode
    print(" Running Decode...")
    try:
        text = decoder.decode(logits)
        print(f" SUCCESS! Output text: '{text}'")
        print("Conclusion: The library works. The issue is inside the Model's vocabulary list.")
    except ValueError as e:
        print(f"\n CRASH CONFIRMED: {e}")
        print("Conclusion: pyctcdecode is modifying the list size internally!")
    except Exception as e:
        print(f"\n UNEXPECTED CRASH: {e}")

if __name__ == "__main__":
    run_sanity_check()
EOF
 RUNNING ISOLATION TEST
 Target Dimension: 4025
 Created Dummy Vocab of size: 4025
 Created Dummy Logits of shape: (100, 4025)
 Building Decoder...
Found entries of length > 1 in alphabet. This is unusual unless style is BPE, but the alphabet was not recognized as BPE type. Is this correct?
Space token ' ' missing from vocabulary.
 Running Decode...

 CRASH CONFIRMED: Input logits shape is (100, 4025), but vocabulary is size 4026. Need logits of shape: (time, vocabulary)
Conclusion: pyctcdecode is modifying the list size internally!
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# rm final_eval.py
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# nano final_eval.py
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# python final_eval.py
fused_indices_to_multihot has reached end of life. Please migrate to a non-experimental function.
OneLogger: Setting error_handling_strategy to DISABLE_QUIETLY_AND_REPORT_METRIC_ERROR for rank (rank=0) with OneLogger disabled. To override: explicitly set error_handling_strategy parameter.
No exporters were provided. This means that no telemetry data will be collected.
 RUNNING FINAL EVAL FIXED (NO PADDING) 
 Loading Model on cuda...
[NeMo I 2026-01-23 02:21:19 mixins:208] _setup_tokenizer: detected an aggregate tokenizer
[NeMo I 2026-01-23 02:21:19 mixins:347] Tokenizer SentencePieceTokenizer initialized with 1024 tokens
[NeMo I 2026-01-23 02:21:19 mixins:347] Tokenizer SentencePieceTokenizer initialized with 3000 tokens
[NeMo I 2026-01-23 02:21:19 aggregate_tokenizer:73] Aggregate vocab size: 4024
[NeMo W 2026-01-23 02:21:23 modelPT:188] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.
    Train config : 
    manifest_filepath: data/training/v2/master_manifest.json
    sample_rate: 16000
    batch_size: 32
    shuffle: true
    num_workers: 16
    pin_memory: true
    use_start_end_token: false
    min_duration: 1.5
    max_duration: 40.0
    prefetch_factor: 4
    
[NeMo W 2026-01-23 02:21:23 modelPT:195] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). 
    Validation config : 
    manifest_filepath:
    - /mnt/data/asr-finetuning/evaluation/benchmarking/data/v1/en_clean_read.json
    - /mnt/data/asr-finetuning/evaluation/benchmarking/data/v1/kn_clean_read.json
    sample_rate: 16000
    batch_size: 32
    shuffle: false
    num_workers: 16
    
[NeMo W 2026-01-23 02:21:23 modelPT:202] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).
    Test config : 
    manifest_filepath: null
    sample_rate: 16000
    batch_size: 16
    shuffle: false
    num_workers: 8
    pin_memory: true
    use_start_end_token: false
    
[NeMo I 2026-01-23 02:21:25 rnnt_models:226] Using RNNT Loss : warprnnt_numba
    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}
[NeMo I 2026-01-23 02:21:25 rnnt_models:226] Using RNNT Loss : warprnnt_numba
    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}
[NeMo W 2026-01-23 02:21:25 label_looping_base:123] No conditional node support for Cuda.
    Cuda graphs with while loops are disabled, decoding speed will be slower
    Reason: Driver supports cuda toolkit version 12.4, but the driver needs to support at least 12,6. Please update your cuda driver.
[NeMo I 2026-01-23 02:21:26 rnnt_models:226] Using RNNT Loss : warprnnt_numba
    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}
[NeMo W 2026-01-23 02:21:26 label_looping_base:123] No conditional node support for Cuda.
    Cuda graphs with while loops are disabled, decoding speed will be slower
    Reason: Driver supports cuda toolkit version 12.4, but the driver needs to support at least 12,6. Please update your cuda driver.
[NeMo I 2026-01-23 02:21:29 save_restore_connector:285] Model EncDecHybridRNNTCTCBPEModel was successfully restored from /mnt/data/asr-finetuning/training/models/kathbath_hybrid_h200_scaleup_p3_phase3_final.nemo.
 Loading Manifest...
 Computing logits for 128 files...
100%|| 128/128 [00:08<00:00, 14.43it/s]
 Passing Vocab Size: 4024 (Library will +1 to match 4025)

 STARTING DECODING
Loading the LM will be faster if you build a binary file.
Reading /mnt/data/asr-finetuning/data/training/wiki_subword_6gram.arpa
----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100
****************************************************************************************************

 FINAL RESULT (Alpha=0.5, Beta=1.0): WER 100.00%

 EXAMPLE:
Ref:          
Pred: 
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# rm final_eval.py
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# nano final_eval.py
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# python final_eval.py
fused_indices_to_multihot has reached end of life. Please migrate to a non-experimental function.
OneLogger: Setting error_handling_strategy to DISABLE_QUIETLY_AND_REPORT_METRIC_ERROR for rank (rank=0) with OneLogger disabled. To override: explicitly set error_handling_strategy parameter.
No exporters were provided. This means that no telemetry data will be collected.
 RUNNING FINAL EVAL WITH GHOST SPACE 
 Loading Model on cuda...
[NeMo I 2026-01-23 02:25:19 mixins:208] _setup_tokenizer: detected an aggregate tokenizer
[NeMo I 2026-01-23 02:25:19 mixins:347] Tokenizer SentencePieceTokenizer initialized with 1024 tokens
[NeMo I 2026-01-23 02:25:19 mixins:347] Tokenizer SentencePieceTokenizer initialized with 3000 tokens
[NeMo I 2026-01-23 02:25:19 aggregate_tokenizer:73] Aggregate vocab size: 4024
[NeMo W 2026-01-23 02:25:26 modelPT:188] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.
    Train config : 
    manifest_filepath: data/training/v2/master_manifest.json
    sample_rate: 16000
    batch_size: 32
    shuffle: true
    num_workers: 16
    pin_memory: true
    use_start_end_token: false
    min_duration: 1.5
    max_duration: 40.0
    prefetch_factor: 4
    
[NeMo W 2026-01-23 02:25:26 modelPT:195] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). 
    Validation config : 
    manifest_filepath:
    - /mnt/data/asr-finetuning/evaluation/benchmarking/data/v1/en_clean_read.json
    - /mnt/data/asr-finetuning/evaluation/benchmarking/data/v1/kn_clean_read.json
    sample_rate: 16000
    batch_size: 32
    shuffle: false
    num_workers: 16
    
[NeMo W 2026-01-23 02:25:26 modelPT:202] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).
    Test config : 
    manifest_filepath: null
    sample_rate: 16000
    batch_size: 16
    shuffle: false
    num_workers: 8
    pin_memory: true
    use_start_end_token: false
    
[NeMo I 2026-01-23 02:25:28 rnnt_models:226] Using RNNT Loss : warprnnt_numba
    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}
[NeMo I 2026-01-23 02:25:28 rnnt_models:226] Using RNNT Loss : warprnnt_numba
    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}
[NeMo W 2026-01-23 02:25:28 label_looping_base:123] No conditional node support for Cuda.
    Cuda graphs with while loops are disabled, decoding speed will be slower
    Reason: Driver supports cuda toolkit version 12.4, but the driver needs to support at least 12,6. Please update your cuda driver.
[NeMo I 2026-01-23 02:25:28 rnnt_models:226] Using RNNT Loss : warprnnt_numba
    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}
[NeMo W 2026-01-23 02:25:28 label_looping_base:123] No conditional node support for Cuda.
    Cuda graphs with while loops are disabled, decoding speed will be slower
    Reason: Driver supports cuda toolkit version 12.4, but the driver needs to support at least 12,6. Please update your cuda driver.
[NeMo I 2026-01-23 02:25:32 save_restore_connector:285] Model EncDecHybridRNNTCTCBPEModel was successfully restored from /mnt/data/asr-finetuning/training/models/kathbath_hybrid_h200_scaleup_p3_phase3_final.nemo.
 Loading Manifest...
 Computing logits for 128 files...
100%|| 128/128 [00:09<00:00, 12.90it/s]
 Building Vocabulary...
 Vocab Size: 4025 (Library will add Space at 4026)

 STARTING DECODING
Loading the LM will be faster if you build a binary file.
Reading /mnt/data/asr-finetuning/data/training/wiki_subword_6gram.arpa
----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100
****************************************************************************************************

 FINAL RESULT (Alpha=0.5, Beta=1.0): WER 100.00%

 EXAMPLE:
Ref:          
Pred: <blank><blank><blank><blank><blank><blank><blank><blank><blank>
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# tmux attach -t training
[detached (from session training)]
[1]   Killed                  python - <<'EOF'
import argparse
import json
import torch
import os
import jiwer
import numpy as np
import librosa
from nemo.collections.asr.models import EncDecHybridRNNTCTCBPEModel
from tqdm import tqdm

try:
    from pyctcdecode import build_ctcdecoder
except ImportError:
    print(" Error: pyctcdecode not found. Run: pip install pyctcdecode")
    exit(1)

# --- CONFIG ---
DEFAULT_MODEL = "training/models/kathbath_hybrid_h200_scaleup_p3_phase3_final.nemo"
DEFAULT_KENLM = "data/training/wiki_6gram.arpa"
DEFAULT_MANIFEST = "evaluation/benchmarking/curation/test_data/Kathbath/test_manifest.json"
SUBSET_SIZE = 128

# --- THE FIX: VOCABULARY TRANSLATION ---
def get_translated_vocab(model):
    """
    Extracts vocabulary and TRANSLATES SentencePiece '_' to Space ' '.
    This aligns the Model's alphabet with KenLM's alphabet.
    """
    vocab_raw = []
    
    # 1. Extract Raw Tokens (with underscores)
    if hasattr(model, 'tokenizer') and hasattr(model.tokenizer, 'ids_to_tokens'):
        vocab_size = model.tokenizer.vocab_size
        for i in range(vocab_size):
            try:
                tokens = model.tokenizer.ids_to_tokens([i])
                vocab_raw.append(tokens[0] if tokens else str(i))
            except:
                vocab_raw.append(f"<unk_{i}>")
    else:
        # Fallback for other tokenizer types
        vocab_size = model.tokenizer.vocab_size
        for i in range(vocab_size):
            vocab_raw.append(model.tokenizer.ids_to_text([i]))

    # 2. Translate & Deduplicate
    vocab_final = []
    seen_counts = {}
    
    print("     Translating Vocab: U+2581 (_) -> U+0020 (Space)...")
    
    for token in vocab_raw:
        # --- THE TRANSLATION STEP ---
        # Replace SentencePiece underscore (U+2581) with standard space
        clean_token = token.replace("\u2581", " ")
        
        # Deduplicate (renaming duplicates to keep list size identical)
        if clean_token in seen_counts:
            seen_counts[clean_token] += 1
            vocab_final.append(f"{clean_token}_dup{seen_counts[clean_token]}")
        else:
            seen_counts[clean_token] = 0
            vocab_final.append(clean_token)
            
    return vocab_final

def load_audio(path):
    try:
        audio, _ = librosa.load(path, sr=16000)
        return torch.tensor(audio, dtype=torch.float32), len(audio)
    except:
        return None, 0

def parse_args():
    parser = argparse.ArgumentParser()
    parser.add_argument("--model", type=str, default=DEFAULT_MODEL)
    parser.add_argument("--kenlm", type=str, default=DEFAULT_KENLM)
    parser.add_argument("--manifest", type=str, default=DEFAULT_MANIFEST)
    parser.add_argument("--subset", type=int, default=SUBSET_SIZE)
    return parser.parse_args()

def run_grid_search():
    args = parse_args()
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f" Device: {device}")

    # 1. Load Model
    print(f" Loading Model...")
    model = EncDecHybridRNNTCTCBPEModel.restore_from(args.model)
    model.eval()
    model.freeze()
    model = model.to(device)

    # 2. Get Logits
    print(f" Pre-computing logits for {args.subset} files...")
    filepaths, references = [], []
    with open(args.manifest, 'r', encoding='utf-8') as f:
        for line in f:
            if len(filepaths) >= args.subset: break
            item = json.loads(line)
            filepaths.append(item['audio_filepath'])
            references.append(item.get('text', ''))

    all_logits = []
    with torch.no_grad():
        for path in tqdm(filepaths):
            tensor, length = load_audio(path)
            if tensor is None: 
                all_logits.append(None)
                continue
            t_in = tensor.unsqueeze(0).to(device)
            l_in = torch.tensor([length], device=device)
            p_sig, p_len = model.preprocessor(input_signal=t_in, length=l_in)
            enc, enc_len = model.encoder(audio_signal=p_sig, length=p_len)
            log_probs = model.ctc_decoder(encoder_output=enc)
            valid_len = int(enc_len[0].item())
            all_logits.append(log_probs[0][:valid_len].cpu().numpy())

    # 3. Setup Decoder (Translated)
    print(f" Loading KenLM & Translating Vocab...")
    vocab = get_translated_vocab(model)
    print(f"    Vocab Size: {len(vocab)}")
    
    # 4. GRID SEARCH
    alphas = [0.1, 0.5, 0.8, 1.0, 1.5, 2.0]
    betas = [0.0, 1.0, 2.0, 3.0]
    
    print("\n" + "="*50)
    print(" STARTING GRID SEARCH (TRANSLATED VOCAB)")
    print("="*50)
    print(f"{'Alpha':<8} | {'Beta':<8} | {'WER':<8}")
    print("-" * 50)

    best_wer = 100.0
    best_params = (0, 0)
    best_preds = []

    for alpha in alphas:
        # Rebuild decoder occasionally to ensure clean state
        try:
            decoder = build_ctcdecoder(
                labels=vocab,
                kenlm_model_path=args.kenlm,
                alpha=alpha,
                beta=0.0
            )
        except Exception as e:
            print(f"Build Failed: {e}")
            continue

        for beta in betas:
            decoder.reset_params(alpha=alpha, beta=beta)
            preds = []
            valid_refs = []
            
            for i, logits in enumerate(all_logits):
                if logits is None: continue
                text = decoder.decode(logits, beam_width=64)
                preds.append(text)
                valid_refs.append(references[i])

            if not preds: continue
            wer = jiwer.wer(valid_refs, preds) * 100
            
            print(f"{alpha:<8} | {beta:<8} | {wer:.2f}%")
            
            if wer < best_wer:
                best_wer = wer
                best_params = (alpha, beta)
                best_preds = preds

    print("="*50)
    print(f" BEST RESULT: WER {best_wer:.2f}%")
    print(f"   Alpha: {best_params[0]}")
    print(f"   Beta:  {best_params[1]}")
    print("="*50)

    print("\n QUALITATIVE CHECK")
    for i in range(min(3, len(best_preds))):
        print(f"\nExample {i+1}:")
        print(f"Ref:  {valid_refs[i]}")
        print(f"Pred: {best_preds[i]}")

if __name__ == "__main__":
    run_grid_search()
EOF

[2]   Killed                  python run_grid_search.py --kenlm "data/training/wiki_mixed_6gram.arpa"
[3]-  Killed                  python run_grid_search.py --kenlm "data/training/wiki_mixed_6gram.arpa"
[4]+  Killed                  python run_grid_search.py --kenlm "data/training/wiki_subword_6gram.arpa"
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# python - <<'EOF'
import argparse
import json
import torch
import os
import jiwer
import numpy as np
import librosa
from nemo.collections.asr.models import EncDecHybridRNNTCTCBPEModel
from tqdm import tqdm

try:
    from pyctcdecode import build_ctcdecoder
except ImportError:
    print(" Error: pyctcdecode not found. Run: pip install pyctcdecode")
    exit(1)

# --- CONFIG ---
DEFAULT_MODEL = "training/models/kathbath_hybrid_h200_scaleup_p3_phase3_final.nemo"
DEFAULT_KENLM = "data/training/wiki_subword_6gram.arpa"
DEFAULT_MANIFEST = "evaluation/benchmarking/curation/test_data/Kathbath/test_manifest.json"
SUBSET_SIZE = 128

def load_audio(path):
    try:
        audio, _ = librosa.load(path, sr=16000)
        return torch.tensor(audio, dtype=torch.float32), len(audio)
    except:
        return None, 0

def run_eval():
    print(" RUNNING DIAGNOSTIC EVAL (RAW OUTPUT) ")
    
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f" Loading Model on {device}...")
    model = EncDecHybridRNNTCTCBPEModel.restore_from(DEFAULT_MODEL)
    model.eval()
    model.freeze()
    model = model.to(device)

    # 1. GET VOCAB (CLEAN 4024)
    # We strip <unk> and other special tokens if they exist, but generally
    # we just want the pure list. We DO NOT add <blank>.
    vocab_raw = []
    vocab_size = model.tokenizer.vocab_size 
    
    if hasattr(model.tokenizer, 'ids_to_tokens'):
        vocab_raw = model.tokenizer.ids_to_tokens(list(range(vocab_size)))
    else:
        for i in range(vocab_size):
            vocab_raw.append(model.tokenizer.ids_to_text([i]))

    # Deduplicate
    vocab_clean = []
    seen = {}
    for t in vocab_raw:
        if t in seen:
            seen[t] += 1
            vocab_clean.append(f"{t}_dup{seen[t]}")
        else:
EOF run_eval() "__main__":NCE:          '{references[i]}'")u2581", " ").strip()
fused_indices_to_multihot has reached end of life. Please migrate to a non-experimental function.
OneLogger: Setting error_handling_strategy to DISABLE_QUIETLY_AND_REPORT_METRIC_ERROR for rank (rank=0) with OneLogger disabled. To override: explicitly set error_handling_strategy parameter.
No exporters were provided. This means that no telemetry data will be collected.
 RUNNING DIAGNOSTIC EVAL (RAW OUTPUT) 
 Loading Model on cuda...
[NeMo I 2026-01-23 02:41:08 mixins:208] _setup_tokenizer: detected an aggregate tokenizer
[NeMo I 2026-01-23 02:41:09 mixins:347] Tokenizer SentencePieceTokenizer initialized with 1024 tokens
[NeMo I 2026-01-23 02:41:09 mixins:347] Tokenizer SentencePieceTokenizer initialized with 3000 tokens
[NeMo I 2026-01-23 02:41:09 aggregate_tokenizer:73] Aggregate vocab size: 4024
[NeMo W 2026-01-23 02:41:15 modelPT:188] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.
    Train config : 
    manifest_filepath: data/training/v2/master_manifest.json
    sample_rate: 16000
    batch_size: 32
    shuffle: true
    num_workers: 16
    pin_memory: true
    use_start_end_token: false
    min_duration: 1.5
    max_duration: 40.0
    prefetch_factor: 4
    
[NeMo W 2026-01-23 02:41:15 modelPT:195] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). 
    Validation config : 
    manifest_filepath:
    - /mnt/data/asr-finetuning/evaluation/benchmarking/data/v1/en_clean_read.json
    - /mnt/data/asr-finetuning/evaluation/benchmarking/data/v1/kn_clean_read.json
    sample_rate: 16000
    batch_size: 32
    shuffle: false
    num_workers: 16
    
[NeMo W 2026-01-23 02:41:15 modelPT:202] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).
    Test config : 
    manifest_filepath: null
    sample_rate: 16000
    batch_size: 16
    shuffle: false
    num_workers: 8
    pin_memory: true
    use_start_end_token: false
    
[NeMo I 2026-01-23 02:41:17 rnnt_models:226] Using RNNT Loss : warprnnt_numba
    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}
[NeMo I 2026-01-23 02:41:17 rnnt_models:226] Using RNNT Loss : warprnnt_numba
    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}
[NeMo W 2026-01-23 02:41:17 label_looping_base:123] No conditional node support for Cuda.
    Cuda graphs with while loops are disabled, decoding speed will be slower
    Reason: Driver supports cuda toolkit version 12.4, but the driver needs to support at least 12,6. Please update your cuda driver.
[NeMo I 2026-01-23 02:41:17 rnnt_models:226] Using RNNT Loss : warprnnt_numba
    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}
[NeMo W 2026-01-23 02:41:17 label_looping_base:123] No conditional node support for Cuda.
    Cuda graphs with while loops are disabled, decoding speed will be slower
    Reason: Driver supports cuda toolkit version 12.4, but the driver needs to support at least 12,6. Please update your cuda driver.
[NeMo I 2026-01-23 02:41:20 save_restore_connector:285] Model EncDecHybridRNNTCTCBPEModel was successfully restored from /mnt/data/asr-finetuning/training/models/kathbath_hybrid_h200_scaleup_p3_phase3_final.nemo.
 Vocab Size: 4024 (Passing to decoder)
Loading the LM will be faster if you build a binary file.
Reading /mnt/data/asr-finetuning/data/training/wiki_subword_6gram.arpa
----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100
****************************************************************************************************
 Processing first 5 files for inspection...

--- Sample 1 ---
RAW DECODER OUTPUT: '  '
STITCHED OUTPUT:    ''
REFERENCE:          '        '

--- Sample 2 ---
RAW DECODER OUTPUT: '     '
STITCHED OUTPUT:    ''
REFERENCE:          '        '

--- Sample 3 ---
RAW DECODER OUTPUT: '        '
STITCHED OUTPUT:    ''
REFERENCE:          '             '

--- Sample 4 ---
RAW DECODER OUTPUT: '      '
STITCHED OUTPUT:    ''
REFERENCE:          '         '

--- Sample 5 ---
RAW DECODER OUTPUT: '    '
STITCHED OUTPUT:    ''
REFERENCE:          '        '
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# python - <<'EOF'
import argparse
import json
import torch
import os
import jiwer
import numpy as np
import librosa
from nemo.collections.asr.models import EncDecHybridRNNTCTCBPEModel
from tqdm import tqdm

try:
    from pyctcdecode import build_ctcdecoder
except ImportError:
    print(" Error: pyctcdecode not found. Run: pip install pyctcdecode")
    exit(1)

# --- CONFIG ---
DEFAULT_MODEL = "training/models/kathbath_hybrid_h200_scaleup_p3_phase3_final.nemo"
DEFAULT_KENLM = "data/training/wiki_subword_6gram.arpa"
DEFAULT_MANIFEST = "evaluation/benchmarking/curation/test_data/Kathbath/test_manifest.json"
SUBSET_SIZE = 128

def load_audio(path):
    try:
        audio, _ = librosa.load(path, sr=16000)
        return torch.tensor(audio, dtype=torch.float32), len(audio)
    except:
        return None, 0

def run_eval():
    print(" RUNNING FINAL EVAL (CORRECT TEXT FORMATTING) ")
    
    # 1. Load Model
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f" Loading Model on {device}...")
    model = EncDecHybridRNNTCTCBPEModel.restore_from(DEFAULT_MODEL)
    model.eval()
    model.freeze()
    model = model.to(device)

    # 2. Get Data
    print(f" Loading Manifest...")
    filepaths, references = [], []
    with open(DEFAULT_MANIFEST, 'r', encoding='utf-8') as f:
        for line in f:
            if len(filepaths) >= SUBSET_SIZE: break
            item = json.loads(line)
            filepaths.append(item['audio_filepath'])
            references.append(item.get('text', ''))

    # 3. Compute Logits
    print(f" Computing logits for {len(filepaths)} files...")
    all_logits = []
    
    with torch.no_grad():
        for path in tqdm(filepaths):
            tensor, length = load_audio(path)
            if tensor is None: 
                all_logits.append(None)
EOF run_eval() "__main__":ds[i]}")s[i]}") Beta=1.0): WER {wer:.2f}%")ze)))lly
fused_indices_to_multihot has reached end of life. Please migrate to a non-experimental function.
OneLogger: Setting error_handling_strategy to DISABLE_QUIETLY_AND_REPORT_METRIC_ERROR for rank (rank=0) with OneLogger disabled. To override: explicitly set error_handling_strategy parameter.
No exporters were provided. This means that no telemetry data will be collected.
 RUNNING FINAL EVAL (CORRECT TEXT FORMATTING) 
 Loading Model on cuda...
[NeMo I 2026-01-23 02:43:30 mixins:208] _setup_tokenizer: detected an aggregate tokenizer
[NeMo I 2026-01-23 02:43:30 mixins:347] Tokenizer SentencePieceTokenizer initialized with 1024 tokens
[NeMo I 2026-01-23 02:43:30 mixins:347] Tokenizer SentencePieceTokenizer initialized with 3000 tokens
[NeMo I 2026-01-23 02:43:30 aggregate_tokenizer:73] Aggregate vocab size: 4024
[NeMo W 2026-01-23 02:43:35 modelPT:188] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.
    Train config : 
    manifest_filepath: data/training/v2/master_manifest.json
    sample_rate: 16000
    batch_size: 32
    shuffle: true
    num_workers: 16
    pin_memory: true
    use_start_end_token: false
    min_duration: 1.5
    max_duration: 40.0
    prefetch_factor: 4
    
[NeMo W 2026-01-23 02:43:35 modelPT:195] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). 
    Validation config : 
    manifest_filepath:
    - /mnt/data/asr-finetuning/evaluation/benchmarking/data/v1/en_clean_read.json
    - /mnt/data/asr-finetuning/evaluation/benchmarking/data/v1/kn_clean_read.json
    sample_rate: 16000
    batch_size: 32
    shuffle: false
    num_workers: 16
    
[NeMo W 2026-01-23 02:43:35 modelPT:202] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).
    Test config : 
    manifest_filepath: null
    sample_rate: 16000
    batch_size: 16
    shuffle: false
    num_workers: 8
    pin_memory: true
    use_start_end_token: false
    
[NeMo I 2026-01-23 02:43:36 rnnt_models:226] Using RNNT Loss : warprnnt_numba
    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}
[NeMo I 2026-01-23 02:43:36 rnnt_models:226] Using RNNT Loss : warprnnt_numba
    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}
[NeMo W 2026-01-23 02:43:37 label_looping_base:123] No conditional node support for Cuda.
    Cuda graphs with while loops are disabled, decoding speed will be slower
    Reason: Driver supports cuda toolkit version 12.4, but the driver needs to support at least 12,6. Please update your cuda driver.
[NeMo I 2026-01-23 02:43:37 rnnt_models:226] Using RNNT Loss : warprnnt_numba
    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}
[NeMo W 2026-01-23 02:43:37 label_looping_base:123] No conditional node support for Cuda.
    Cuda graphs with while loops are disabled, decoding speed will be slower
    Reason: Driver supports cuda toolkit version 12.4, but the driver needs to support at least 12,6. Please update your cuda driver.
[NeMo I 2026-01-23 02:43:40 save_restore_connector:285] Model EncDecHybridRNNTCTCBPEModel was successfully restored from /mnt/data/asr-finetuning/training/models/kathbath_hybrid_h200_scaleup_p3_phase3_final.nemo.
 Loading Manifest...
 Computing logits for 128 files...
100%|| 128/128 [00:08<00:00, 14.71it/s]
 Passing Vocab Size: 4024

 STARTING DECODING
Loading the LM will be faster if you build a binary file.
Reading /mnt/data/asr-finetuning/data/training/wiki_subword_6gram.arpa
----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100
****************************************************************************************************

 FINAL RESULT (Alpha=0.5, Beta=1.0): WER 70.58%

 EXAMPLES:

Ref:          
Pred:   

Ref:          
Pred:      

Ref:               
Pred:         
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# Read from remote host 47.29.24.119: Operation timed out
Connection to 47.29.24.119 closed.
client_loop: send disconnect: Broken pipe
chaitanyakartik@Chaitanyas-MacBook-Air:~ $ ssh ubuntu@47.29.24.119

Authorized uses only. All activity may be monitored and reported.
Welcome to Ubuntu 22.04.5 LTS (GNU/Linux 5.15.0-144-generic x86_64)

 * Documentation:  https://help.ubuntu.com
 * Management:     https://landscape.canonical.com
 * Support:        https://ubuntu.com/pro

 System information as of Fri Jan 23 02:35:33 PM IST 2026

  System load:    0.04              Processes:               275
  Usage of /home: 43.5% of 4.99GB   Users logged in:         0
  Memory usage:   4%                IPv4 address for enp3s0: 10.0.0.234
  Swap usage:     0%


Expanded Security Maintenance for Applications is not enabled.

97 updates can be applied immediately.
75 of these updates are standard security updates.
To see these additional updates run: apt list --upgradable

Enable ESM Apps to receive additional future security updates.
See https://ubuntu.com/esm or run: sudo pro status


The list of available updates is more than a week old.
To check for new updates run: sudo apt update
New release '24.04.3 LTS' available.
Run 'do-release-upgrade' to upgrade to it.


Authorized uses only. All activity may be monitored and reported.
Last login: Thu Jan 22 21:39:43 2026 from 103.83.29.160
ubuntu@bh-01:~$ ssh neurodx@10.0.0.147
Authorized uses only. All activity may be monitored and reported.
neurodx@10.0.0.147's password: 
Welcome to Ubuntu 24.04.2 LTS (GNU/Linux 6.8.0-56-generic x86_64)

 * Documentation:  https://help.ubuntu.com
 * Management:     https://landscape.canonical.com
 * Support:        https://ubuntu.com/pro

 System information as of Fri Jan 23 02:35:39 PM IST 2026

  System load:    3.94              Processes:               999
  Usage of /home: 55.1% of 4.94GB   Users logged in:         2
  Memory usage:   12%               IPv4 address for enp3s0: 10.0.0.147
  Swap usage:     0%

  => /var/log/audit is using 100.0% of 4.94GB

 * Strictly confined Kubernetes makes edge and IoT secure. Learn how MicroK8s
   just raised the bar for easy, resilient and secure K8s cluster deployment.

   https://ubuntu.com/engage/secure-kubernetes-at-the-edge

Expanded Security Maintenance for Applications is not enabled.

232 updates can be applied immediately.
139 of these updates are standard security updates.
To see these additional updates run: apt list --upgradable

13 additional security updates can be applied with ESM Apps.
Learn more about enabling ESM Apps service at https://ubuntu.com/esm


Last login: Thu Jan 22 21:40:53 2026 from 10.0.0.234

(base) neurodx@h200-nvl-2x:~$ 
(base) neurodx@h200-nvl-2x:~$ sudo su
root@h200-nvl-2x:/home/neurodx# cd /mnt/data
source asr-env/bin/activate 
cd asr-finetuning
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# python evaluation/benchmarking/run/run_benchmark_bypass.py \
--model=/mnt/data/asr-finetuning/training/experiments/kathbath_hybrid_h200_scaleup_phase4/2026-01-23_02-31-05/checkpoints/kathbath_hybrid_h200_scaleup_phase4.nemo \
--manifest=evaluation/benchmarking/curation/evaluation/benchmarking/data/v1/kn_clean_read.json \
--output-dir=models/results_conf_100m_v3_incomplete
fused_indices_to_multihot has reached end of life. Please migrate to a non-experimental function.
OneLogger: Setting error_handling_strategy to DISABLE_QUIETLY_AND_REPORT_METRIC_ERROR for rank (rank=0) with OneLogger disabled. To override: explicitly set error_handling_strategy parameter.
No exporters were provided. This means that no telemetry data will be collected.
================================================================================
ASR BENCHMARK RUNNER (SINGLE MANIFEST)
================================================================================
Model:    /mnt/data/asr-finetuning/training/experiments/kathbath_hybrid_h200_scaleup_phase4/2026-01-23_02-31-05/checkpoints/kathbath_hybrid_h200_scaleup_phase4.nemo
Manifest: evaluation/benchmarking/curation/evaluation/benchmarking/data/v1/kn_clean_read.json
Output:   models/results_conf_100m_v3_incomplete
================================================================================
 Manifest OK: Valid manifest with 2062 entries

 Loading ASR model...
[NeMo I 2026-01-23 14:36:18 mixins:208] _setup_tokenizer: detected an aggregate tokenizer
[NeMo I 2026-01-23 14:36:18 mixins:347] Tokenizer SentencePieceTokenizer initialized with 1024 tokens
[NeMo I 2026-01-23 14:36:18 mixins:347] Tokenizer SentencePieceTokenizer initialized with 3000 tokens
[NeMo I 2026-01-23 14:36:18 aggregate_tokenizer:73] Aggregate vocab size: 4024
[NeMo W 2026-01-23 14:36:25 modelPT:188] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.
    Train config : 
    manifest_filepath: data/training/v2.1/master_manifest.json
    sample_rate: 16000
    batch_size: 32
    shuffle: true
    num_workers: 16
    pin_memory: true
    use_start_end_token: false
    min_duration: 3.0
    max_duration: 20.0
    prefetch_factor: 4
    
[NeMo W 2026-01-23 14:36:25 modelPT:195] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). 
    Validation config : 
    manifest_filepath:
    - /mnt/data/asr-finetuning/evaluation/benchmarking/data/v1/en_clean_read.json
    - /mnt/data/asr-finetuning/evaluation/benchmarking/data/v1/kn_clean_read.json
    sample_rate: 16000
    batch_size: 32
    shuffle: false
    num_workers: 16
    
[NeMo W 2026-01-23 14:36:25 modelPT:202] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).
    Test config : 
    manifest_filepath: null
    sample_rate: 16000
    batch_size: 16
    shuffle: false
    num_workers: 8
    pin_memory: true
    use_start_end_token: false
    
[NeMo I 2026-01-23 14:36:27 rnnt_models:226] Using RNNT Loss : warprnnt_numba
    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}
[NeMo I 2026-01-23 14:36:27 rnnt_models:226] Using RNNT Loss : warprnnt_numba
    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}
[NeMo W 2026-01-23 14:36:27 label_looping_base:123] No conditional node support for Cuda.
    Cuda graphs with while loops are disabled, decoding speed will be slower
    Reason: Driver supports cuda toolkit version 12.4, but the driver needs to support at least 12,6. Please update your cuda driver.
[NeMo I 2026-01-23 14:36:27 rnnt_models:226] Using RNNT Loss : warprnnt_numba
    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}
[NeMo W 2026-01-23 14:36:27 label_looping_base:123] No conditional node support for Cuda.
    Cuda graphs with while loops are disabled, decoding speed will be slower
    Reason: Driver supports cuda toolkit version 12.4, but the driver needs to support at least 12,6. Please update your cuda driver.
[NeMo I 2026-01-23 14:36:31 save_restore_connector:285] Model EncDecHybridRNNTCTCBPEModel was successfully restored from /mnt/data/asr-finetuning/training/experiments/kathbath_hybrid_h200_scaleup_phase4/2026-01-23_02-31-05/checkpoints/kathbath_hybrid_h200_scaleup_phase4.nemo.
 Model loaded: EncDecHybridRNNTCTCBPEModel
 Running inference (manual RNNT path)
   Manifest: evaluation/benchmarking/curation/evaluation/benchmarking/data/v1/kn_clean_read.json
   Output:   models/results_conf_100m_v3_incomplete
   Files to transcribe: 2062
   Processed 10/2062
   Processed 20/2062
   Processed 30/2062
   Processed 40/2062
   Processed 50/2062
   Processed 60/2062
   Processed 70/2062
   Processed 80/2062
   Processed 90/2062
   Processed 100/2062
   Processed 110/2062
   Processed 120/2062
   Processed 130/2062
   Processed 140/2062
   Processed 150/2062
   Processed 160/2062
   Processed 170/2062
   Processed 180/2062
   Processed 190/2062
   Processed 200/2062
   Processed 210/2062
   Processed 220/2062
   Processed 230/2062
   Processed 240/2062
   Processed 250/2062
   Processed 260/2062
   Processed 270/2062
   Processed 280/2062
   Processed 290/2062
   Processed 300/2062
   Processed 310/2062
   Processed 320/2062
   Processed 330/2062
   Processed 340/2062
   Processed 350/2062
   Processed 360/2062
   Processed 370/2062
   Processed 380/2062
   Processed 390/2062
   Processed 400/2062
   Processed 410/2062
   Processed 420/2062
   Processed 430/2062
   Processed 440/2062
   Processed 450/2062
   Processed 460/2062
   Processed 470/2062
   Processed 480/2062
   Processed 490/2062
   Processed 500/2062
   Processed 510/2062
   Processed 520/2062
   Processed 530/2062
   Processed 540/2062
   Processed 550/2062
   Processed 560/2062
   Processed 570/2062
   Processed 580/2062
   Processed 590/2062
   Processed 600/2062
   Processed 610/2062
   Processed 620/2062
   Processed 630/2062
   Processed 640/2062
   Processed 650/2062
   Processed 660/2062
   Processed 670/2062
   Processed 680/2062
   Processed 690/2062
   Processed 700/2062
   Processed 710/2062
   Processed 720/2062
   Processed 730/2062
   Processed 740/2062
   Processed 750/2062
   Processed 760/2062
   Processed 770/2062
   Processed 780/2062
   Processed 790/2062
   Processed 800/2062
   Processed 810/2062
   Processed 820/2062
   Processed 830/2062
   Processed 840/2062
   Processed 850/2062
   Processed 860/2062
   Processed 870/2062
   Processed 880/2062
   Processed 890/2062
   Processed 900/2062
   Processed 910/2062
   Processed 920/2062
   Processed 930/2062
   Processed 940/2062
   Processed 950/2062
   Processed 960/2062
   Processed 970/2062
   Processed 980/2062
   Processed 990/2062
   Processed 1000/2062
   Processed 1010/2062
   Processed 1020/2062
   Processed 1030/2062
   Processed 1040/2062
   Processed 1050/2062
   Processed 1060/2062
   Processed 1070/2062
   Processed 1080/2062
   Processed 1090/2062
   Processed 1100/2062
   Processed 1110/2062
   Processed 1120/2062
   Processed 1130/2062
   Processed 1140/2062
   Processed 1150/2062
   Processed 1160/2062
   Processed 1170/2062
   Processed 1180/2062
   Processed 1190/2062
   Processed 1200/2062
   Processed 1210/2062
   Processed 1220/2062
   Processed 1230/2062
   Processed 1240/2062
   Processed 1250/2062
   Processed 1260/2062
   Processed 1270/2062
   Processed 1280/2062
   Processed 1290/2062
   Processed 1300/2062
   Processed 1310/2062
   Processed 1320/2062
   Processed 1330/2062
   Processed 1340/2062
   Processed 1350/2062
   Processed 1360/2062
   Processed 1370/2062
   Processed 1380/2062
   Processed 1390/2062
   Processed 1400/2062
   Processed 1410/2062
   Processed 1420/2062
   Processed 1430/2062
   Processed 1440/2062
   Processed 1450/2062
   Processed 1460/2062
   Processed 1470/2062
   Processed 1480/2062
   Processed 1490/2062
   Processed 1500/2062
   Processed 1510/2062
   Processed 1520/2062
   Processed 1530/2062
   Processed 1540/2062
   Processed 1550/2062
   Processed 1560/2062
   Processed 1570/2062
   Processed 1580/2062
   Processed 1590/2062
   Processed 1600/2062
   Processed 1610/2062
   Processed 1620/2062
   Processed 1630/2062
   Processed 1640/2062
   Processed 1650/2062
   Processed 1660/2062
   Processed 1670/2062
   Processed 1680/2062
   Processed 1690/2062
   Processed 1700/2062
   Processed 1710/2062
   Processed 1720/2062
   Processed 1730/2062
   Processed 1740/2062
   Processed 1750/2062
   Processed 1760/2062
   Processed 1770/2062
   Processed 1780/2062
   Processed 1790/2062
   Processed 1800/2062
   Processed 1810/2062
   Processed 1820/2062
   Processed 1830/2062
   Processed 1840/2062
   Processed 1850/2062
   Processed 1860/2062
   Processed 1870/2062
   Processed 1880/2062
   Processed 1890/2062
   Processed 1900/2062
   Processed 1910/2062
   Processed 1920/2062
   Processed 1930/2062
   Processed 1940/2062
   Processed 1950/2062
   Processed 1960/2062
   Processed 1970/2062
   Processed 1980/2062
   Processed 1990/2062
   Processed 2000/2062
   Processed 2010/2062
   Processed 2020/2062
   Processed 2030/2062
   Processed 2040/2062
   Processed 2050/2062
   Processed 2060/2062
 Inference complete
 Computing metrics

================================================================================
RESULTS
================================================================================
{'wer': 14.56, 'cer': 2.87, 'num_samples': 2062}

 JSON report saved to: /mnt/data/asr-finetuning/models/benchmark_report.json
 Text report saved to: /mnt/data/asr-finetuning/models/report.txt

 Benchmark complete
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# ls /mnt/data/asr-finetuning/models/
benchmark_report.json                         models      results_a14b_indicconf_600m  results_conf_100m_scaleup_v2_final  results_conf_16m_kathbath
download_model.py                             README.md   results_ai4b_indicconf_100m  results_conf_100m_v2                results_kenlm_v1
indicconformer_stt_kn_hybrid_rnnt_large.nemo  report.txt  results_conf_100m_kathbath   results_conf_100m_v3_incomplete     test_600m.py
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# ls /mnt/data/asr-finetuning/models/results_conf_100m_v3_incomplete
predictions.json
(asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# cat /mnt/data/asr-finetuning/models/results_conf_100m_v3_incomplete/predictions.json
[
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_0.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 0
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 1
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_2.wav",
    "ground_truth": "             ",
    "prediction": "              ",
    "index": 2
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_3.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 3
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_4.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 4
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_5.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 5
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_6.wav",
    "ground_truth": "              ",
    "prediction": "              ",
    "index": 6
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_7.wav",
    "ground_truth": "              ",
    "prediction": "              ",
    "index": 7
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_8.wav",
    "ground_truth": "           ",
    "prediction": "             ",
    "index": 8
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_9.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 9
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_10.wav",
    "ground_truth": "           ",
    "prediction": "            ",
    "index": 10
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_11.wav",
    "ground_truth": "             ",
    "prediction": "              ",
    "index": 11
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_12.wav",
    "ground_truth": "           ",
    "prediction": "            ",
    "index": 12
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_13.wav",
    "ground_truth": "           ",
    "prediction": "           ",
    "index": 13
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_14.wav",
    "ground_truth": "           ",
    "prediction": "           ",
    "index": 14
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_15.wav",
    "ground_truth": "             ",
    "prediction": "             ",
    "index": 15
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_16.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 16
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_17.wav",
    "ground_truth": "              ",
    "prediction": "               ",
    "index": 17
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_18.wav",
    "ground_truth": "          ",
    "prediction": "          ",
    "index": 18
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_19.wav",
    "ground_truth": "          ",
    "prediction": "            ",
    "index": 19
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_20.wav",
    "ground_truth": "           ",
    "prediction": "            ",
    "index": 20
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_21.wav",
    "ground_truth": "           ",
    "prediction": "            ",
    "index": 21
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_22.wav",
    "ground_truth": "            ",
    "prediction": "             ",
    "index": 22
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_23.wav",
    "ground_truth": "             ",
    "prediction": "              ",
    "index": 23
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_24.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 24
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_25.wav",
    "ground_truth": "          ",
    "prediction": "          ",
    "index": 25
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_26.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 26
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_27.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 27
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_28.wav",
    "ground_truth": "           ",
    "prediction": "            ",
    "index": 28
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_29.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 29
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_30.wav",
    "ground_truth": "        ",
    "prediction": "          ",
    "index": 30
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_31.wav",
    "ground_truth": "            ",
    "prediction": "             ",
    "index": 31
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_32.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 32
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_33.wav",
    "ground_truth": "         ",
    "prediction": "           ",
    "index": 33
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_34.wav",
    "ground_truth": "          ",
    "prediction": "         ",
    "index": 34
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_35.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 35
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_36.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 36
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_37.wav",
    "ground_truth": "            ",
    "prediction": "             ",
    "index": 37
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_38.wav",
    "ground_truth": "             ",
    "prediction": "             ",
    "index": 38
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_39.wav",
    "ground_truth": "           ",
    "prediction": "            ",
    "index": 39
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_40.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 40
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_41.wav",
    "ground_truth": "           ",
    "prediction": "            ",
    "index": 41
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_42.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 42
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_43.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 43
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_44.wav",
    "ground_truth": "            ",
    "prediction": "              ",
    "index": 44
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_45.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 45
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_46.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 46
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_47.wav",
    "ground_truth": "            ",
    "prediction": "            ",
    "index": 47
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_48.wav",
    "ground_truth": "             ",
    "prediction": "             ",
    "index": 48
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_49.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 49
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_50.wav",
    "ground_truth": "        ",
    "prediction": "        ",
    "index": 50
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_51.wav",
    "ground_truth": "              ",
    "prediction": "         <0xE0><0xB2><0x94>   ",
    "index": 51
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_52.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 52
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_53.wav",
    "ground_truth": "              ",
    "prediction": "             <0xE0><0xB2><0x8A>  ",
    "index": 53
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_54.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 54
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_55.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 55
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_56.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 56
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_57.wav",
    "ground_truth": "         ",
    "prediction": "            ",
    "index": 57
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_58.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 58
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_59.wav",
    "ground_truth": "              ",
    "prediction": "          <0xE0><0xB2><0x94>    ",
    "index": 59
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_60.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 60
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_61.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 61
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_62.wav",
    "ground_truth": "        ",
    "prediction": "         <0xE0><0xB2><0x8A>",
    "index": 62
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_63.wav",
    "ground_truth": "        ",
    "prediction": "          ",
    "index": 63
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_64.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 64
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_65.wav",
    "ground_truth": "            ",
    "prediction": "         <0xE0><0xB2><0x8A>    ",
    "index": 65
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_66.wav",
    "ground_truth": "        ",
    "prediction": "  <0xE0><0xB2><0x94>       ",
    "index": 66
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_67.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 67
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_68.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 68
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_69.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 69
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_70.wav",
    "ground_truth": "           ",
    "prediction": "            ",
    "index": 70
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_71.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 71
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_72.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 72
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_73.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 73
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_74.wav",
    "ground_truth": "              ",
    "prediction": "             ",
    "index": 74
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_75.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 75
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_76.wav",
    "ground_truth": "            ",
    "prediction": "             ",
    "index": 76
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_77.wav",
    "ground_truth": "           ",
    "prediction": "            ",
    "index": 77
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_78.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 78
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_79.wav",
    "ground_truth": "         ",
    "prediction": "           ",
    "index": 79
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_80.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 80
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_81.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 81
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_82.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 82
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_83.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 83
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_84.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 84
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_85.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 85
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_86.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 86
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_87.wav",
    "ground_truth": "             ",
    "prediction": "              ",
    "index": 87
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_88.wav",
    "ground_truth": "          ",
    "prediction": "          ",
    "index": 88
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_89.wav",
    "ground_truth": "           ",
    "prediction": "            ",
    "index": 89
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_90.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 90
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_91.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 91
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_92.wav",
    "ground_truth": "            ",
    "prediction": "            ",
    "index": 92
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_93.wav",
    "ground_truth": "        ",
    "prediction": "           ",
    "index": 93
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_94.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 94
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_95.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 95
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_96.wav",
    "ground_truth": "          ",
    "prediction": "            ",
    "index": 96
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_97.wav",
    "ground_truth": "         ",
    "prediction": "         ",
    "index": 97
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_98.wav",
    "ground_truth": "           ",
    "prediction": "            ",
    "index": 98
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_99.wav",
    "ground_truth": "             ",
    "prediction": "              ",
    "index": 99
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_100.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 100
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_101.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 101
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_102.wav",
    "ground_truth": "             ",
    "prediction": "              ",
    "index": 102
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_103.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 103
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_104.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 104
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_105.wav",
    "ground_truth": "           ",
    "prediction": "            ",
    "index": 105
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_106.wav",
    "ground_truth": "            ",
    "prediction": "             ",
    "index": 106
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_107.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 107
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_108.wav",
    "ground_truth": "        ",
    "prediction": "          ",
    "index": 108
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_109.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 109
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_110.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 110
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_111.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 111
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_112.wav",
    "ground_truth": "              ",
    "prediction": "              ",
    "index": 112
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_113.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 113
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_114.wav",
    "ground_truth": "         ",
    "prediction": "           ",
    "index": 114
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_115.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 115
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_116.wav",
    "ground_truth": "              ",
    "prediction": "              ",
    "index": 116
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_117.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 117
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_118.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 118
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_119.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 119
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_120.wav",
    "ground_truth": "         ",
    "prediction": "           ",
    "index": 120
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_121.wav",
    "ground_truth": "           ",
    "prediction": "           ",
    "index": 121
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_122.wav",
    "ground_truth": "          ",
    "prediction": "            ",
    "index": 122
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_123.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 123
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_124.wav",
    "ground_truth": "              ",
    "prediction": "               ",
    "index": 124
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_125.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 125
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_126.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 126
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_127.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 127
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_128.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 128
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_129.wav",
    "ground_truth": "           ",
    "prediction": "            ",
    "index": 129
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_130.wav",
    "ground_truth": "          ",
    "prediction": "          ",
    "index": 130
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_131.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 131
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_132.wav",
    "ground_truth": "        ",
    "prediction": "          ",
    "index": 132
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_133.wav",
    "ground_truth": "           ",
    "prediction": "            ",
    "index": 133
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_134.wav",
    "ground_truth": "            ",
    "prediction": "              ",
    "index": 134
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_135.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 135
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_136.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 136
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_137.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 137
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_138.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 138
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_139.wav",
    "ground_truth": "             ",
    "prediction": "             ",
    "index": 139
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_140.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 140
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_141.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 141
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_142.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 142
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_143.wav",
    "ground_truth": "              ",
    "prediction": "             ",
    "index": 143
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_144.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 144
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_145.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 145
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_146.wav",
    "ground_truth": "            ",
    "prediction": "              ",
    "index": 146
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_147.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 147
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_148.wav",
    "ground_truth": "          ",
    "prediction": "          ",
    "index": 148
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_149.wav",
    "ground_truth": "           ",
    "prediction": "            ",
    "index": 149
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_150.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 150
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_151.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 151
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_152.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 152
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_153.wav",
    "ground_truth": "             ",
    "prediction": "             ",
    "index": 153
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_154.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 154
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_155.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 155
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_156.wav",
    "ground_truth": "              ",
    "prediction": "               ",
    "index": 156
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_157.wav",
    "ground_truth": "         ",
    "prediction": "         ",
    "index": 157
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_158.wav",
    "ground_truth": "         ",
    "prediction": "           ",
    "index": 158
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_159.wav",
    "ground_truth": "           ",
    "prediction": "            ",
    "index": 159
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_160.wav",
    "ground_truth": "         ",
    "prediction": "         ",
    "index": 160
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_161.wav",
    "ground_truth": "           ",
    "prediction": "            ",
    "index": 161
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_162.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 162
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_163.wav",
    "ground_truth": "           ",
    "prediction": "            ",
    "index": 163
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_164.wav",
    "ground_truth": "           ",
    "prediction": "            ",
    "index": 164
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_165.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 165
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_166.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 166
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_167.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 167
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_168.wav",
    "ground_truth": "         ",
    "prediction": "        ",
    "index": 168
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_169.wav",
    "ground_truth": "        ",
    "prediction": "          ",
    "index": 169
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_170.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 170
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_171.wav",
    "ground_truth": "           ",
    "prediction": "            ",
    "index": 171
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_172.wav",
    "ground_truth": "           ",
    "prediction": "            ",
    "index": 172
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_173.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 173
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_174.wav",
    "ground_truth": "           ",
    "prediction": "            ",
    "index": 174
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_175.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 175
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_176.wav",
    "ground_truth": "              ",
    "prediction": "               ",
    "index": 176
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_177.wav",
    "ground_truth": "        ",
    "prediction": "        ",
    "index": 177
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_178.wav",
    "ground_truth": "            ",
    "prediction": "            ",
    "index": 178
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_179.wav",
    "ground_truth": "           ",
    "prediction": "            ",
    "index": 179
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_180.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 180
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_181.wav",
    "ground_truth": "             ",
    "prediction": "              ",
    "index": 181
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_182.wav",
    "ground_truth": "           ",
    "prediction": "            ",
    "index": 182
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_183.wav",
    "ground_truth": "        ",
    "prediction": "        ",
    "index": 183
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_184.wav",
    "ground_truth": "        ",
    "prediction": "        ",
    "index": 184
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_185.wav",
    "ground_truth": "           ",
    "prediction": "            ",
    "index": 185
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_186.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 186
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_187.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 187
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_188.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 188
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_189.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 189
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_190.wav",
    "ground_truth": "           ",
    "prediction": "          ",
    "index": 190
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_191.wav",
    "ground_truth": "            ",
    "prediction": "             ",
    "index": 191
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_192.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 192
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_193.wav",
    "ground_truth": "              ",
    "prediction": "               ",
    "index": 193
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_194.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 194
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_195.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 195
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_196.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 196
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_197.wav",
    "ground_truth": "             ",
    "prediction": "             ",
    "index": 197
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_198.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 198
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_199.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 199
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_200.wav",
    "ground_truth": "           ",
    "prediction": "             ",
    "index": 200
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_201.wav",
    "ground_truth": "             ",
    "prediction": "              ",
    "index": 201
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_202.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 202
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_203.wav",
    "ground_truth": "            ",
    "prediction": "             ",
    "index": 203
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_204.wav",
    "ground_truth": "         ",
    "prediction": "         ",
    "index": 204
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_205.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 205
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_206.wav",
    "ground_truth": "          ",
    "prediction": "            ",
    "index": 206
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_207.wav",
    "ground_truth": "            ",
    "prediction": "             ",
    "index": 207
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_208.wav",
    "ground_truth": "           ",
    "prediction": "            ",
    "index": 208
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_209.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 209
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_210.wav",
    "ground_truth": "             ",
    "prediction": "              ",
    "index": 210
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_211.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 211
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_212.wav",
    "ground_truth": "            ",
    "prediction": "             ",
    "index": 212
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_213.wav",
    "ground_truth": "           ",
    "prediction": "            ",
    "index": 213
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_214.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 214
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_215.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 215
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_216.wav",
    "ground_truth": "           ",
    "prediction": "            ",
    "index": 216
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_217.wav",
    "ground_truth": "            ",
    "prediction": "             ",
    "index": 217
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_218.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 218
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_219.wav",
    "ground_truth": "            ",
    "prediction": "            ",
    "index": 219
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_220.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 220
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_221.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 221
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_222.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 222
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_223.wav",
    "ground_truth": "           ",
    "prediction": "            ",
    "index": 223
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_224.wav",
    "ground_truth": "             ",
    "prediction": "    <0xE0><0xB2><0x9D>          ",
    "index": 224
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_225.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 225
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_226.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 226
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_227.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 227
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_228.wav",
    "ground_truth": "              ",
    "prediction": "               ",
    "index": 228
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_229.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 229
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_230.wav",
    "ground_truth": "             ",
    "prediction": "              ",
    "index": 230
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_231.wav",
    "ground_truth": "           ",
    "prediction": "            ",
    "index": 231
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_232.wav",
    "ground_truth": "              ",
    "prediction": "              ",
    "index": 232
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_233.wav",
    "ground_truth": "            ",
    "prediction": "             ",
    "index": 233
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_234.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 234
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_235.wav",
    "ground_truth": "          ",
    "prediction": "       <0xE0><0xB2><0x94>    ",
    "index": 235
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_236.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 236
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_237.wav",
    "ground_truth": "           ",
    "prediction": "             ",
    "index": 237
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_238.wav",
    "ground_truth": "         ",
    "prediction": "         ",
    "index": 238
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_239.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 239
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_240.wav",
    "ground_truth": "           ",
    "prediction": "           ",
    "index": 240
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_241.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 241
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_242.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 242
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_243.wav",
    "ground_truth": "            ",
    "prediction": "             ",
    "index": 243
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_244.wav",
    "ground_truth": "             ",
    "prediction": "              ",
    "index": 244
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_245.wav",
    "ground_truth": "         ",
    "prediction": "         ",
    "index": 245
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_246.wav",
    "ground_truth": "             ",
    "prediction": "               ",
    "index": 246
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_247.wav",
    "ground_truth": "              ",
    "prediction": "               ",
    "index": 247
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_248.wav",
    "ground_truth": "              ",
    "prediction": "               ",
    "index": 248
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_249.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 249
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_250.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 250
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_251.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 251
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_252.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 252
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_253.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 253
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_254.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 254
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_255.wav",
    "ground_truth": "              ",
    "prediction": "               ",
    "index": 255
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_256.wav",
    "ground_truth": "           ",
    "prediction": "            ",
    "index": 256
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_257.wav",
    "ground_truth": "         ",
    "prediction": "         ",
    "index": 257
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_258.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 258
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_259.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 259
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_260.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 260
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_261.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 261
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_262.wav",
    "ground_truth": "           ",
    "prediction": "            ",
    "index": 262
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_263.wav",
    "ground_truth": "           ",
    "prediction": "            ",
    "index": 263
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_264.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 264
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_265.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 265
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_266.wav",
    "ground_truth": "         ",
    "prediction": "            ",
    "index": 266
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_267.wav",
    "ground_truth": "         ",
    "prediction": "           ",
    "index": 267
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_268.wav",
    "ground_truth": "              ",
    "prediction": "               ",
    "index": 268
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_269.wav",
    "ground_truth": "        ",
    "prediction": "          ",
    "index": 269
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_270.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 270
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_271.wav",
    "ground_truth": "        ",
    "prediction": "          ",
    "index": 271
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_272.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 272
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_273.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 273
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_274.wav",
    "ground_truth": "            ",
    "prediction": "             ",
    "index": 274
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_275.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 275
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_276.wav",
    "ground_truth": "        ",
    "prediction": "        ",
    "index": 276
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_277.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 277
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_278.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 278
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_279.wav",
    "ground_truth": "        ",
    "prediction": "        ",
    "index": 279
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_280.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 280
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_281.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 281
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_282.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 282
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_283.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 283
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_284.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 284
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_285.wav",
    "ground_truth": "             ",
    "prediction": "              ",
    "index": 285
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_286.wav",
    "ground_truth": "             ",
    "prediction": "              ",
    "index": 286
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_287.wav",
    "ground_truth": "           ",
    "prediction": "            ",
    "index": 287
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_288.wav",
    "ground_truth": "         ",
    "prediction": "           ",
    "index": 288
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_289.wav",
    "ground_truth": "         ",
    "prediction": "           ",
    "index": 289
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_290.wav",
    "ground_truth": "            ",
    "prediction": "             ",
    "index": 290
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_291.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 291
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_292.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 292
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_293.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 293
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_294.wav",
    "ground_truth": "              ",
    "prediction": "               ",
    "index": 294
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_295.wav",
    "ground_truth": "              ",
    "prediction": "               ",
    "index": 295
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_296.wav",
    "ground_truth": "         ",
    "prediction": "           ",
    "index": 296
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_297.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 297
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_298.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 298
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_299.wav",
    "ground_truth": "        ",
    "prediction": "          ",
    "index": 299
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_300.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 300
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_301.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 301
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_302.wav",
    "ground_truth": "          ",
    "prediction": "          ",
    "index": 302
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_303.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 303
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_304.wav",
    "ground_truth": "             ",
    "prediction": "             ",
    "index": 304
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_305.wav",
    "ground_truth": "         ",
    "prediction": "         ",
    "index": 305
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_306.wav",
    "ground_truth": "         ",
    "prediction": "         ",
    "index": 306
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_307.wav",
    "ground_truth": "           ",
    "prediction": "            ",
    "index": 307
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_308.wav",
    "ground_truth": "             ",
    "prediction": "              ",
    "index": 308
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_309.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 309
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_310.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 310
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_311.wav",
    "ground_truth": "              ",
    "prediction": "               ",
    "index": 311
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_312.wav",
    "ground_truth": "        ",
    "prediction": "          ",
    "index": 312
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_313.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 313
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_314.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 314
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_315.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 315
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_316.wav",
    "ground_truth": "        ",
    "prediction": "    <0xE0><0xB2><0xA2>     ",
    "index": 316
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_317.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 317
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_318.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 318
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_319.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 319
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_320.wav",
    "ground_truth": "           ",
    "prediction": "           ",
    "index": 320
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_321.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 321
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_322.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 322
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_323.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 323
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_324.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 324
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_325.wav",
    "ground_truth": "             ",
    "prediction": "             ",
    "index": 325
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_326.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 326
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_327.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 327
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_328.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 328
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_329.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 329
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_330.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 330
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_331.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 331
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_332.wav",
    "ground_truth": "              ",
    "prediction": "               ",
    "index": 332
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_333.wav",
    "ground_truth": "           ",
    "prediction": "             ",
    "index": 333
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_334.wav",
    "ground_truth": "             ",
    "prediction": "              ",
    "index": 334
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_335.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 335
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_336.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 336
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_337.wav",
    "ground_truth": "           ",
    "prediction": "            ",
    "index": 337
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_338.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 338
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_339.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 339
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_340.wav",
    "ground_truth": "          ",
    "prediction": "            ",
    "index": 340
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_341.wav",
    "ground_truth": "           ",
    "prediction": "            ",
    "index": 341
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_342.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 342
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_343.wav",
    "ground_truth": "        ",
    "prediction": "          ",
    "index": 343
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_344.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 344
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_345.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 345
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_346.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 346
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_347.wav",
    "ground_truth": "         ",
    "prediction": "           ",
    "index": 347
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_348.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 348
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_349.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 349
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_350.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 350
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_351.wav",
    "ground_truth": "        ",
    "prediction": "          ",
    "index": 351
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_352.wav",
    "ground_truth": "             ",
    "prediction": "              ",
    "index": 352
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_353.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 353
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_354.wav",
    "ground_truth": "         ",
    "prediction": "           ",
    "index": 354
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_355.wav",
    "ground_truth": "           ",
    "prediction": "            ",
    "index": 355
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_356.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 356
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_357.wav",
    "ground_truth": "        ",
    "prediction": "        ",
    "index": 357
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_358.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 358
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_359.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 359
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_360.wav",
    "ground_truth": "        ",
    "prediction": "          ",
    "index": 360
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_361.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 361
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_362.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 362
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_363.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 363
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_364.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 364
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_365.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 365
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_366.wav",
    "ground_truth": "        ",
    "prediction": "          ",
    "index": 366
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_367.wav",
    "ground_truth": "           ",
    "prediction": "            ",
    "index": 367
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_368.wav",
    "ground_truth": "        ",
    "prediction": "          ",
    "index": 368
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_369.wav",
    "ground_truth": "          ",
    "prediction": "            ",
    "index": 369
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_370.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 370
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_371.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 371
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_372.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 372
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_373.wav",
    "ground_truth": "            ",
    "prediction": "             ",
    "index": 373
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_374.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 374
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_375.wav",
    "ground_truth": "              ",
    "prediction": "             ",
    "index": 375
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_376.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 376
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_377.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 377
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_378.wav",
    "ground_truth": "           ",
    "prediction": "           ",
    "index": 378
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_379.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 379
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_380.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 380
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_381.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 381
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_382.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 382
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_383.wav",
    "ground_truth": "            ",
    "prediction": "             ",
    "index": 383
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_384.wav",
    "ground_truth": "         ",
    "prediction": "         ",
    "index": 384
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_385.wav",
    "ground_truth": "            ",
    "prediction": "             ",
    "index": 385
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_386.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 386
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_387.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 387
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_388.wav",
    "ground_truth": "            ",
    "prediction": "             ",
    "index": 388
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_389.wav",
    "ground_truth": "              ",
    "prediction": "               ",
    "index": 389
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_390.wav",
    "ground_truth": "            ",
    "prediction": "             ",
    "index": 390
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_391.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 391
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_392.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 392
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_393.wav",
    "ground_truth": "           ",
    "prediction": "            ",
    "index": 393
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_394.wav",
    "ground_truth": "          ",
    "prediction": "          ",
    "index": 394
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_395.wav",
    "ground_truth": "             ",
    "prediction": "              ",
    "index": 395
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_396.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 396
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_397.wav",
    "ground_truth": "         ",
    "prediction": "          <0xE0><0xB2><0xA2> ",
    "index": 397
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_398.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 398
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_399.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 399
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_400.wav",
    "ground_truth": "             ",
    "prediction": "              ",
    "index": 400
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_401.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 401
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_402.wav",
    "ground_truth": "           ",
    "prediction": "            ",
    "index": 402
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_403.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 403
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_404.wav",
    "ground_truth": "             ",
    "prediction": "              ",
    "index": 404
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_405.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 405
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_406.wav",
    "ground_truth": "           ",
    "prediction": "             ",
    "index": 406
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_407.wav",
    "ground_truth": "            ",
    "prediction": "             ",
    "index": 407
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_408.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 408
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_409.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 409
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_410.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 410
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_411.wav",
    "ground_truth": "             ",
    "prediction": "               ",
    "index": 411
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_412.wav",
    "ground_truth": "           ",
    "prediction": "            ",
    "index": 412
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_413.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 413
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_414.wav",
    "ground_truth": "              ",
    "prediction": "    <0xE0><0xB2><0x8A>      <0xE0><0xB2><0x8A>     ",
    "index": 414
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_415.wav",
    "ground_truth": "        ",
    "prediction": "  <0xE0><0xB2><0x8A>       ",
    "index": 415
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_416.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 416
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_417.wav",
    "ground_truth": "        ",
    "prediction": "          ",
    "index": 417
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_418.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 418
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_419.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 419
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_420.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 420
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_421.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 421
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_422.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 422
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_423.wav",
    "ground_truth": "             ",
    "prediction": "              ",
    "index": 423
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_424.wav",
    "ground_truth": "             ",
    "prediction": "               ",
    "index": 424
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_425.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 425
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_426.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 426
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_427.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 427
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_428.wav",
    "ground_truth": "             ",
    "prediction": "              ",
    "index": 428
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_429.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 429
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_430.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 430
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_431.wav",
    "ground_truth": "              ",
    "prediction": "                   ",
    "index": 431
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_432.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 432
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_433.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 433
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_434.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 434
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_435.wav",
    "ground_truth": "           ",
    "prediction": "            ",
    "index": 435
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_436.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 436
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_437.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 437
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_438.wav",
    "ground_truth": "             ",
    "prediction": "              ",
    "index": 438
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_439.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 439
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_440.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 440
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_441.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 441
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_442.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 442
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_443.wav",
    "ground_truth": "           ",
    "prediction": "            ",
    "index": 443
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_444.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 444
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_445.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 445
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_446.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 446
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_447.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 447
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_448.wav",
    "ground_truth": "        ",
    "prediction": "        ",
    "index": 448
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_449.wav",
    "ground_truth": "           ",
    "prediction": "            ",
    "index": 449
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_450.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 450
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_451.wav",
    "ground_truth": "              ",
    "prediction": "             ",
    "index": 451
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_452.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 452
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_453.wav",
    "ground_truth": "           ",
    "prediction": "           ",
    "index": 453
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_454.wav",
    "ground_truth": "            ",
    "prediction": "             ",
    "index": 454
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_455.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 455
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_456.wav",
    "ground_truth": "            ",
    "prediction": "             ",
    "index": 456
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_457.wav",
    "ground_truth": "            ",
    "prediction": "             ",
    "index": 457
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_458.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 458
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_459.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 459
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_460.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 460
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_461.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 461
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_462.wav",
    "ground_truth": "              ",
    "prediction": "               ",
    "index": 462
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_463.wav",
    "ground_truth": "          ",
    "prediction": "            ",
    "index": 463
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_464.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 464
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_465.wav",
    "ground_truth": "            ",
    "prediction": "            ",
    "index": 465
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_466.wav",
    "ground_truth": "              ",
    "prediction": "               ",
    "index": 466
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_467.wav",
    "ground_truth": "           ",
    "prediction": "            ",
    "index": 467
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_468.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 468
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_469.wav",
    "ground_truth": "             ",
    "prediction": "              ",
    "index": 469
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_470.wav",
    "ground_truth": "           ",
    "prediction": "            ",
    "index": 470
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_471.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 471
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_472.wav",
    "ground_truth": "           ",
    "prediction": "            ",
    "index": 472
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_473.wav",
    "ground_truth": "         ",
    "prediction": "         ",
    "index": 473
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_474.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 474
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_475.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 475
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_476.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 476
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_477.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 477
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_478.wav",
    "ground_truth": "           ",
    "prediction": "           ",
    "index": 478
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_479.wav",
    "ground_truth": "              ",
    "prediction": "                ",
    "index": 479
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_480.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 480
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_481.wav",
    "ground_truth": "            ",
    "prediction": "             ",
    "index": 481
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_482.wav",
    "ground_truth": "              ",
    "prediction": "                ",
    "index": 482
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_483.wav",
    "ground_truth": "            ",
    "prediction": "             ",
    "index": 483
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_484.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 484
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_485.wav",
    "ground_truth": "        ",
    "prediction": "          ",
    "index": 485
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_486.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 486
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_487.wav",
    "ground_truth": "            ",
    "prediction": "             ",
    "index": 487
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_488.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 488
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_489.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 489
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_490.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 490
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_491.wav",
    "ground_truth": "            ",
    "prediction": "             ",
    "index": 491
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_492.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 492
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_493.wav",
    "ground_truth": "        ",
    "prediction": "        ",
    "index": 493
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_494.wav",
    "ground_truth": "           ",
    "prediction": "            ",
    "index": 494
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_495.wav",
    "ground_truth": "           ",
    "prediction": "            ",
    "index": 495
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_496.wav",
    "ground_truth": "            ",
    "prediction": "             ",
    "index": 496
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_497.wav",
    "ground_truth": "             ",
    "prediction": "              ",
    "index": 497
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_498.wav",
    "ground_truth": "           ",
    "prediction": "           ",
    "index": 498
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_499.wav",
    "ground_truth": "             ",
    "prediction": "              ",
    "index": 499
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_500.wav",
    "ground_truth": "            ",
    "prediction": "              ",
    "index": 500
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_501.wav",
    "ground_truth": "            ",
    "prediction": "             ",
    "index": 501
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_502.wav",
    "ground_truth": "          ",
    "prediction": "          ",
    "index": 502
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_503.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 503
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_504.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 504
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_505.wav",
    "ground_truth": "            ",
    "prediction": "            ",
    "index": 505
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_506.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 506
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_507.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 507
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_508.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 508
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_509.wav",
    "ground_truth": "           ",
    "prediction": "            ",
    "index": 509
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_510.wav",
    "ground_truth": "         ",
    "prediction": "         ",
    "index": 510
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_511.wav",
    "ground_truth": "             ",
    "prediction": "              ",
    "index": 511
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_512.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 512
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_513.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 513
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_514.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 514
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_515.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 515
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_516.wav",
    "ground_truth": "              ",
    "prediction": "               ",
    "index": 516
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_517.wav",
    "ground_truth": "            ",
    "prediction": "            ",
    "index": 517
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_518.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 518
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_519.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 519
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_520.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 520
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_521.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 521
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_522.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 522
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_523.wav",
    "ground_truth": "        ",
    "prediction": "          ",
    "index": 523
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_524.wav",
    "ground_truth": "          ",
    "prediction": "          ",
    "index": 524
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_525.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 525
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_526.wav",
    "ground_truth": "           ",
    "prediction": "            ",
    "index": 526
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_527.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 527
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_528.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 528
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_529.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 529
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_530.wav",
    "ground_truth": "           ",
    "prediction": "            ",
    "index": 530
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_531.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 531
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_532.wav",
    "ground_truth": "           ",
    "prediction": "            ",
    "index": 532
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_533.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 533
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_534.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 534
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_535.wav",
    "ground_truth": "            ",
    "prediction": "             ",
    "index": 535
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_536.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 536
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_537.wav",
    "ground_truth": "             ",
    "prediction": "              ",
    "index": 537
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_538.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 538
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_539.wav",
    "ground_truth": "              ",
    "prediction": "                ",
    "index": 539
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_540.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 540
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_541.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 541
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_542.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 542
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_543.wav",
    "ground_truth": "            ",
    "prediction": "             ",
    "index": 543
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_544.wav",
    "ground_truth": "              ",
    "prediction": "               ",
    "index": 544
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_545.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 545
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_546.wav",
    "ground_truth": "         ",
    "prediction": "           ",
    "index": 546
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_547.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 547
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_548.wav",
    "ground_truth": "           ",
    "prediction": "            ",
    "index": 548
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_549.wav",
    "ground_truth": "              ",
    "prediction": "             ",
    "index": 549
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_550.wav",
    "ground_truth": "             ",
    "prediction": "              ",
    "index": 550
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_551.wav",
    "ground_truth": "              ",
    "prediction": "               ",
    "index": 551
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_552.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 552
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_553.wav",
    "ground_truth": "            ",
    "prediction": "             ",
    "index": 553
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_554.wav",
    "ground_truth": "           ",
    "prediction": "            ",
    "index": 554
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_555.wav",
    "ground_truth": "        ",
    "prediction": "          ",
    "index": 555
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_556.wav",
    "ground_truth": "            ",
    "prediction": "             ",
    "index": 556
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_557.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 557
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_558.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 558
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_559.wav",
    "ground_truth": "             ",
    "prediction": "               ",
    "index": 559
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_560.wav",
    "ground_truth": "            ",
    "prediction": "             ",
    "index": 560
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_561.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 561
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_562.wav",
    "ground_truth": "              ",
    "prediction": "                ",
    "index": 562
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_563.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 563
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_564.wav",
    "ground_truth": "            ",
    "prediction": "             ",
    "index": 564
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_565.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 565
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_566.wav",
    "ground_truth": "            ",
    "prediction": "            ",
    "index": 566
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_567.wav",
    "ground_truth": "           ",
    "prediction": "             ",
    "index": 567
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_568.wav",
    "ground_truth": "          ",
    "prediction": "            ",
    "index": 568
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_569.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 569
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_570.wav",
    "ground_truth": "        ",
    "prediction": "        ",
    "index": 570
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_571.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 571
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_572.wav",
    "ground_truth": "            ",
    "prediction": "             ",
    "index": 572
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_573.wav",
    "ground_truth": "           ",
    "prediction": "            ",
    "index": 573
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_574.wav",
    "ground_truth": "          ",
    "prediction": "          ",
    "index": 574
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_575.wav",
    "ground_truth": "           ",
    "prediction": "            ",
    "index": 575
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_576.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 576
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_577.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 577
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_578.wav",
    "ground_truth": "           ",
    "prediction": "            ",
    "index": 578
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_579.wav",
    "ground_truth": "        ",
    "prediction": "           ",
    "index": 579
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_580.wav",
    "ground_truth": "              ",
    "prediction": "               ",
    "index": 580
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_581.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 581
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_582.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 582
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_583.wav",
    "ground_truth": "           ",
    "prediction": "             ",
    "index": 583
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_584.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 584
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_585.wav",
    "ground_truth": "        ",
    "prediction": " <0xE0><0xB2><0x8A>        ",
    "index": 585
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_586.wav",
    "ground_truth": "           ",
    "prediction": "           ",
    "index": 586
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_587.wav",
    "ground_truth": "              ",
    "prediction": "               ",
    "index": 587
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_588.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 588
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_589.wav",
    "ground_truth": "           ",
    "prediction": "            ",
    "index": 589
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_590.wav",
    "ground_truth": "              ",
    "prediction": "               ",
    "index": 590
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_591.wav",
    "ground_truth": "             ",
    "prediction": "             ",
    "index": 591
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_592.wav",
    "ground_truth": "          ",
    "prediction": "          ",
    "index": 592
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_593.wav",
    "ground_truth": "             ",
    "prediction": "              ",
    "index": 593
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_594.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 594
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_595.wav",
    "ground_truth": "          ",
    "prediction": "          ",
    "index": 595
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_596.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 596
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_597.wav",
    "ground_truth": "         ",
    "prediction": "       <0xE0><0xB2><0x8B>   ",
    "index": 597
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_598.wav",
    "ground_truth": "          ",
    "prediction": "        <0xE0><0xB2><0xA2>    ",
    "index": 598
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_599.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 599
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_600.wav",
    "ground_truth": "            ",
    "prediction": "             ",
    "index": 600
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_601.wav",
    "ground_truth": "           ",
    "prediction": "            ",
    "index": 601
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_602.wav",
    "ground_truth": "            ",
    "prediction": "             ",
    "index": 602
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_603.wav",
    "ground_truth": "           ",
    "prediction": "           ",
    "index": 603
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_604.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 604
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_605.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 605
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_606.wav",
    "ground_truth": "           ",
    "prediction": "            ",
    "index": 606
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_607.wav",
    "ground_truth": "        ",
    "prediction": "        ",
    "index": 607
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_608.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 608
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_609.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 609
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_610.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 610
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_611.wav",
    "ground_truth": "             ",
    "prediction": "              ",
    "index": 611
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_612.wav",
    "ground_truth": "         ",
    "prediction": "           ",
    "index": 612
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_613.wav",
    "ground_truth": "          ",
    "prediction": "            ",
    "index": 613
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_614.wav",
    "ground_truth": "           ",
    "prediction": "            ",
    "index": 614
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_615.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 615
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_616.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 616
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_617.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 617
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_618.wav",
    "ground_truth": "           ",
    "prediction": "            ",
    "index": 618
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_619.wav",
    "ground_truth": "             ",
    "prediction": "              ",
    "index": 619
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_620.wav",
    "ground_truth": "        ",
    "prediction": "            ",
    "index": 620
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_621.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 621
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_622.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 622
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_623.wav",
    "ground_truth": "              ",
    "prediction": "               ",
    "index": 623
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_624.wav",
    "ground_truth": "            ",
    "prediction": "           ",
    "index": 624
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_625.wav",
    "ground_truth": "             ",
    "prediction": "              ",
    "index": 625
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_626.wav",
    "ground_truth": "           ",
    "prediction": "            ",
    "index": 626
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_627.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 627
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_628.wav",
    "ground_truth": "             ",
    "prediction": "              ",
    "index": 628
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_629.wav",
    "ground_truth": "         ",
    "prediction": "           ",
    "index": 629
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_630.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 630
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_631.wav",
    "ground_truth": "            ",
    "prediction": "             ",
    "index": 631
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_632.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 632
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_633.wav",
    "ground_truth": "           ",
    "prediction": "            ",
    "index": 633
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_634.wav",
    "ground_truth": "            ",
    "prediction": "             ",
    "index": 634
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_635.wav",
    "ground_truth": "              ",
    "prediction": "               ",
    "index": 635
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_636.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 636
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_637.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 637
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_638.wav",
    "ground_truth": "          ",
    "prediction": "             ",
    "index": 638
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_639.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 639
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_640.wav",
    "ground_truth": "        ",
    "prediction": "     <0xE0><0xB2><0x94>     ",
    "index": 640
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_641.wav",
    "ground_truth": "           ",
    "prediction": "            ",
    "index": 641
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_642.wav",
    "ground_truth": "            ",
    "prediction": "            ",
    "index": 642
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_643.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 643
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_644.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 644
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_645.wav",
    "ground_truth": "           ",
    "prediction": "            ",
    "index": 645
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_646.wav",
    "ground_truth": "           ",
    "prediction": "           ",
    "index": 646
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_647.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 647
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_648.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 648
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_649.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 649
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_650.wav",
    "ground_truth": "           ",
    "prediction": "            ",
    "index": 650
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_651.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 651
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_652.wav",
    "ground_truth": "             ",
    "prediction": "              ",
    "index": 652
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_653.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 653
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_654.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 654
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_655.wav",
    "ground_truth": "         ",
    "prediction": "         ",
    "index": 655
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_656.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 656
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_657.wav",
    "ground_truth": "             ",
    "prediction": "              ",
    "index": 657
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_658.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 658
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_659.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 659
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_660.wav",
    "ground_truth": "            ",
    "prediction": "             ",
    "index": 660
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_661.wav",
    "ground_truth": "            ",
    "prediction": "             ",
    "index": 661
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_662.wav",
    "ground_truth": "           ",
    "prediction": "            ",
    "index": 662
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_663.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 663
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_664.wav",
    "ground_truth": "            ",
    "prediction": "             ",
    "index": 664
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_665.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 665
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_666.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 666
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_667.wav",
    "ground_truth": "              ",
    "prediction": "                ",
    "index": 667
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_668.wav",
    "ground_truth": "              ",
    "prediction": "              ",
    "index": 668
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_669.wav",
    "ground_truth": "              ",
    "prediction": "                ",
    "index": 669
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_670.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 670
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_671.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 671
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_672.wav",
    "ground_truth": "        ",
    "prediction": "          ",
    "index": 672
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_673.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 673
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_674.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 674
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_675.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 675
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_676.wav",
    "ground_truth": "         ",
    "prediction": "           ",
    "index": 676
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_677.wav",
    "ground_truth": "             ",
    "prediction": "              ",
    "index": 677
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_678.wav",
    "ground_truth": "           ",
    "prediction": "            ",
    "index": 678
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_679.wav",
    "ground_truth": "        ",
    "prediction": "          ",
    "index": 679
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_680.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 680
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_681.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 681
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_682.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 682
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_683.wav",
    "ground_truth": "            ",
    "prediction": "             ",
    "index": 683
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_684.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 684
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_685.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 685
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_686.wav",
    "ground_truth": "            ",
    "prediction": "            ",
    "index": 686
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_687.wav",
    "ground_truth": "            ",
    "prediction": "              ",
    "index": 687
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_688.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 688
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_689.wav",
    "ground_truth": "              ",
    "prediction": "               ",
    "index": 689
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_690.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 690
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_691.wav",
    "ground_truth": "              ",
    "prediction": "               ",
    "index": 691
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_692.wav",
    "ground_truth": "            ",
    "prediction": "             ",
    "index": 692
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_693.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 693
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_694.wav",
    "ground_truth": "          ",
    "prediction": "          <0xE0><0xB2><0x8A> ",
    "index": 694
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_695.wav",
    "ground_truth": "             ",
    "prediction": "              ",
    "index": 695
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_696.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 696
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_697.wav",
    "ground_truth": "           ",
    "prediction": "           ",
    "index": 697
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_698.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 698
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_699.wav",
    "ground_truth": "              ",
    "prediction": "                ",
    "index": 699
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_700.wav",
    "ground_truth": "          ",
    "prediction": "            ",
    "index": 700
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_701.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 701
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_702.wav",
    "ground_truth": "          ",
    "prediction": "          ",
    "index": 702
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_703.wav",
    "ground_truth": "            ",
    "prediction": "            ",
    "index": 703
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_704.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 704
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_705.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 705
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_706.wav",
    "ground_truth": "             ",
    "prediction": "               ",
    "index": 706
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_707.wav",
    "ground_truth": "          ",
    "prediction": "  <0xE0><0xB2><0x94>         ",
    "index": 707
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_708.wav",
    "ground_truth": "            ",
    "prediction": "             ",
    "index": 708
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_709.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 709
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_710.wav",
    "ground_truth": "             ",
    "prediction": "              ",
    "index": 710
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_711.wav",
    "ground_truth": "           ",
    "prediction": "            ",
    "index": 711
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_712.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 712
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_713.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 713
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_714.wav",
    "ground_truth": "           ",
    "prediction": "            ",
    "index": 714
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_715.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 715
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_716.wav",
    "ground_truth": "           ",
    "prediction": "            ",
    "index": 716
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_717.wav",
    "ground_truth": "            ",
    "prediction": "             ",
    "index": 717
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_718.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 718
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_719.wav",
    "ground_truth": "            ",
    "prediction": "             ",
    "index": 719
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_720.wav",
    "ground_truth": "            ",
    "prediction": "             ",
    "index": 720
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_721.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 721
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_722.wav",
    "ground_truth": "           ",
    "prediction": "            ",
    "index": 722
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_723.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 723
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_724.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 724
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_725.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 725
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_726.wav",
    "ground_truth": "         ",
    "prediction": "           ",
    "index": 726
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_727.wav",
    "ground_truth": "          ",
    "prediction": "            ",
    "index": 727
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_728.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 728
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_729.wav",
    "ground_truth": "           ",
    "prediction": "            ",
    "index": 729
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_730.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 730
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_731.wav",
    "ground_truth": "        ",
    "prediction": "          ",
    "index": 731
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_732.wav",
    "ground_truth": "            ",
    "prediction": "             ",
    "index": 732
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_733.wav",
    "ground_truth": "           ",
    "prediction": "            ",
    "index": 733
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_734.wav",
    "ground_truth": "            ",
    "prediction": "            ",
    "index": 734
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_735.wav",
    "ground_truth": "         ",
    "prediction": "           ",
    "index": 735
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_736.wav",
    "ground_truth": "          ",
    "prediction": "            ",
    "index": 736
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_737.wav",
    "ground_truth": "         ",
    "prediction": "         ",
    "index": 737
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_738.wav",
    "ground_truth": "           ",
    "prediction": "           ",
    "index": 738
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_739.wav",
    "ground_truth": "           ",
    "prediction": "            ",
    "index": 739
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_740.wav",
    "ground_truth": "            ",
    "prediction": "             ",
    "index": 740
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_741.wav",
    "ground_truth": "          ",
    "prediction": "            ",
    "index": 741
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_742.wav",
    "ground_truth": "          ",
    "prediction": "         ",
    "index": 742
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_743.wav",
    "ground_truth": "            ",
    "prediction": "             ",
    "index": 743
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_744.wav",
    "ground_truth": "           ",
    "prediction": "            ",
    "index": 744
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_745.wav",
    "ground_truth": "           ",
    "prediction": "            ",
    "index": 745
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_746.wav",
    "ground_truth": "            ",
    "prediction": "             ",
    "index": 746
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_747.wav",
    "ground_truth": "             ",
    "prediction": "              ",
    "index": 747
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_748.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 748
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_749.wav",
    "ground_truth": "         ",
    "prediction": "        ",
    "index": 749
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_750.wav",
    "ground_truth": "           ",
    "prediction": "            ",
    "index": 750
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_751.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 751
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_752.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 752
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_753.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 753
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_754.wav",
    "ground_truth": "             ",
    "prediction": "              ",
    "index": 754
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_755.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 755
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_756.wav",
    "ground_truth": "           ",
    "prediction": "            ",
    "index": 756
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_757.wav",
    "ground_truth": "              ",
    "prediction": "               ",
    "index": 757
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_758.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 758
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_759.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 759
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_760.wav",
    "ground_truth": "           ",
    "prediction": "       <0xE0><0xB2><0x8B>     ",
    "index": 760
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_761.wav",
    "ground_truth": "           ",
    "prediction": "             ",
    "index": 761
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_762.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 762
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_763.wav",
    "ground_truth": "              ",
    "prediction": "              ",
    "index": 763
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_764.wav",
    "ground_truth": "           ",
    "prediction": "            ",
    "index": 764
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_765.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 765
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_766.wav",
    "ground_truth": "              ",
    "prediction": "               ",
    "index": 766
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_767.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 767
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_768.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 768
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_769.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 769
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_770.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 770
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_771.wav",
    "ground_truth": "           ",
    "prediction": "            ",
    "index": 771
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_772.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 772
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_773.wav",
    "ground_truth": "           ",
    "prediction": "            ",
    "index": 773
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_774.wav",
    "ground_truth": "         ",
    "prediction": "         ",
    "index": 774
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_775.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 775
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_776.wav",
    "ground_truth": "          ",
    "prediction": "          ",
    "index": 776
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_777.wav",
    "ground_truth": "          ",
    "prediction": "            ",
    "index": 777
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_778.wav",
    "ground_truth": "            ",
    "prediction": "             ",
    "index": 778
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_779.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 779
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_780.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 780
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_781.wav",
    "ground_truth": "             ",
    "prediction": "               ",
    "index": 781
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_782.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 782
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_783.wav",
    "ground_truth": "             ",
    "prediction": "             ",
    "index": 783
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_784.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 784
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_785.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 785
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_786.wav",
    "ground_truth": "        ",
    "prediction": "          ",
    "index": 786
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_787.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 787
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_788.wav",
    "ground_truth": "          ",
    "prediction": "         ",
    "index": 788
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_789.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 789
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_790.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 790
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_791.wav",
    "ground_truth": "           ",
    "prediction": "            ",
    "index": 791
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_792.wav",
    "ground_truth": "            ",
    "prediction": "             ",
    "index": 792
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_793.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 793
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_794.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 794
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_795.wav",
    "ground_truth": "              ",
    "prediction": "               ",
    "index": 795
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_796.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 796
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_797.wav",
    "ground_truth": "             ",
    "prediction": "               ",
    "index": 797
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_798.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 798
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_799.wav",
    "ground_truth": "        ",
    "prediction": "          ",
    "index": 799
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_800.wav",
    "ground_truth": "              ",
    "prediction": "               ",
    "index": 800
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_801.wav",
    "ground_truth": "           ",
    "prediction": "            ",
    "index": 801
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_802.wav",
    "ground_truth": "          ",
    "prediction": "            ",
    "index": 802
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_803.wav",
    "ground_truth": "           ",
    "prediction": "           ",
    "index": 803
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_804.wav",
    "ground_truth": "            ",
    "prediction": "              ",
    "index": 804
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_805.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 805
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_806.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 806
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_807.wav",
    "ground_truth": "        ",
    "prediction": "          ",
    "index": 807
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_808.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 808
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_809.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 809
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_810.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 810
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_811.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 811
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_812.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 812
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_813.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 813
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_814.wav",
    "ground_truth": "            ",
    "prediction": "             ",
    "index": 814
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_815.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 815
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_816.wav",
    "ground_truth": "           ",
    "prediction": "            ",
    "index": 816
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_817.wav",
    "ground_truth": "          ",
    "prediction": "          ",
    "index": 817
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_818.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 818
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_819.wav",
    "ground_truth": "           ",
    "prediction": "            ",
    "index": 819
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_820.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 820
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_821.wav",
    "ground_truth": "            ",
    "prediction": "             ",
    "index": 821
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_822.wav",
    "ground_truth": "           ",
    "prediction": "           ",
    "index": 822
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_823.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 823
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_824.wav",
    "ground_truth": "        ",
    "prediction": "        ",
    "index": 824
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_825.wav",
    "ground_truth": "           ",
    "prediction": "            ",
    "index": 825
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_826.wav",
    "ground_truth": "          ",
    "prediction": "  <0xE0><0xB2><0xA2>         ",
    "index": 826
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_827.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 827
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_828.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 828
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_829.wav",
    "ground_truth": "           ",
    "prediction": "           ",
    "index": 829
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_830.wav",
    "ground_truth": "            ",
    "prediction": "             ",
    "index": 830
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_831.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 831
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_832.wav",
    "ground_truth": "        ",
    "prediction": "        ",
    "index": 832
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_833.wav",
    "ground_truth": "         ",
    "prediction": "           ",
    "index": 833
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_834.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 834
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_835.wav",
    "ground_truth": "           ",
    "prediction": "            ",
    "index": 835
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_836.wav",
    "ground_truth": "          ",
    "prediction": "            ",
    "index": 836
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_837.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 837
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_838.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 838
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_839.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 839
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_840.wav",
    "ground_truth": "              ",
    "prediction": "               ",
    "index": 840
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_841.wav",
    "ground_truth": "         ",
    "prediction": "         ",
    "index": 841
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_842.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 842
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_843.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 843
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_844.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 844
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_845.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 845
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_846.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 846
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_847.wav",
    "ground_truth": "           ",
    "prediction": "            ",
    "index": 847
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_848.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 848
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_849.wav",
    "ground_truth": "        ",
    "prediction": "        ",
    "index": 849
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_850.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 850
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_851.wav",
    "ground_truth": "             ",
    "prediction": "              ",
    "index": 851
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_852.wav",
    "ground_truth": "           ",
    "prediction": "            ",
    "index": 852
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_853.wav",
    "ground_truth": "             ",
    "prediction": "              ",
    "index": 853
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_854.wav",
    "ground_truth": "            ",
    "prediction": "              ",
    "index": 854
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_855.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 855
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_856.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 856
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_857.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 857
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_858.wav",
    "ground_truth": "           ",
    "prediction": "            ",
    "index": 858
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_859.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 859
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_860.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 860
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_861.wav",
    "ground_truth": "           ",
    "prediction": "             ",
    "index": 861
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_862.wav",
    "ground_truth": "            ",
    "prediction": "             ",
    "index": 862
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_863.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 863
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_864.wav",
    "ground_truth": "           ",
    "prediction": "            ",
    "index": 864
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_865.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 865
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_866.wav",
    "ground_truth": "           ",
    "prediction": "          ",
    "index": 866
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_867.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 867
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_868.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 868
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_869.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 869
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_870.wav",
    "ground_truth": "          ",
    "prediction": "  <0xE0><0xB2><0x94>         ",
    "index": 870
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_871.wav",
    "ground_truth": "        ",
    "prediction": "          ",
    "index": 871
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_872.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 872
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_873.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 873
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_874.wav",
    "ground_truth": "           ",
    "prediction": "            ",
    "index": 874
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_875.wav",
    "ground_truth": "            ",
    "prediction": "            ",
    "index": 875
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_876.wav",
    "ground_truth": "        ",
    "prediction": "        ",
    "index": 876
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_877.wav",
    "ground_truth": "           ",
    "prediction": "             ",
    "index": 877
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_878.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 878
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_879.wav",
    "ground_truth": "           ",
    "prediction": "         <0xE0><0xB2><0x94>   ",
    "index": 879
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_880.wav",
    "ground_truth": "           ",
    "prediction": "            ",
    "index": 880
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_881.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 881
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_882.wav",
    "ground_truth": "           ",
    "prediction": "            ",
    "index": 882
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_883.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 883
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_884.wav",
    "ground_truth": "          ",
    "prediction": "          ",
    "index": 884
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_885.wav",
    "ground_truth": "           ",
    "prediction": "           ",
    "index": 885
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_886.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 886
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_887.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 887
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_888.wav",
    "ground_truth": "             ",
    "prediction": "              ",
    "index": 888
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_889.wav",
    "ground_truth": "           ",
    "prediction": "            ",
    "index": 889
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_890.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 890
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_891.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 891
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_892.wav",
    "ground_truth": "             ",
    "prediction": "              ",
    "index": 892
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_893.wav",
    "ground_truth": "           ",
    "prediction": "           ",
    "index": 893
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_894.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 894
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_895.wav",
    "ground_truth": "              ",
    "prediction": "            <0xE0><0xB2><0x9D>   ",
    "index": 895
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_896.wav",
    "ground_truth": "            ",
    "prediction": "             ",
    "index": 896
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_897.wav",
    "ground_truth": "         ",
    "prediction": "           ",
    "index": 897
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_898.wav",
    "ground_truth": "          ",
    "prediction": "          ",
    "index": 898
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_899.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 899
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_900.wav",
    "ground_truth": "           ",
    "prediction": "            ",
    "index": 900
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_901.wav",
    "ground_truth": "           ",
    "prediction": "            ",
    "index": 901
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_902.wav",
    "ground_truth": "           ",
    "prediction": "             ",
    "index": 902
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_903.wav",
    "ground_truth": "            ",
    "prediction": "             ",
    "index": 903
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_904.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 904
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_905.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 905
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_906.wav",
    "ground_truth": "             ",
    "prediction": "              ",
    "index": 906
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_907.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 907
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_908.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 908
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_909.wav",
    "ground_truth": "        ",
    "prediction": "          ",
    "index": 909
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_910.wav",
    "ground_truth": "         ",
    "prediction": "         ",
    "index": 910
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_911.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 911
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_912.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 912
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_913.wav",
    "ground_truth": "          ",
    "prediction": "          ",
    "index": 913
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_914.wav",
    "ground_truth": "        ",
    "prediction": "        ",
    "index": 914
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_915.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 915
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_916.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 916
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_917.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 917
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_918.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 918
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_919.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 919
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_920.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 920
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_921.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 921
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_922.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 922
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_923.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 923
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_924.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 924
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_925.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 925
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_926.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 926
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_927.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 927
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_928.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 928
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_929.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 929
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_930.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 930
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_931.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 931
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_932.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 932
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_933.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 933
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_934.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 934
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_935.wav",
    "ground_truth": "             ",
    "prediction": "              ",
    "index": 935
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_936.wav",
    "ground_truth": "         ",
    "prediction": "           ",
    "index": 936
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_937.wav",
    "ground_truth": "        ",
    "prediction": "          ",
    "index": 937
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_938.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 938
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_939.wav",
    "ground_truth": "             ",
    "prediction": "             ",
    "index": 939
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_940.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 940
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_941.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 941
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_942.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 942
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_943.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 943
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_944.wav",
    "ground_truth": "             ",
    "prediction": "            ",
    "index": 944
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_945.wav",
    "ground_truth": "            ",
    "prediction": "             ",
    "index": 945
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_946.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 946
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_947.wav",
    "ground_truth": "        ",
    "prediction": "          ",
    "index": 947
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_948.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 948
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_949.wav",
    "ground_truth": "              ",
    "prediction": "               ",
    "index": 949
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_950.wav",
    "ground_truth": "            ",
    "prediction": "             ",
    "index": 950
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_951.wav",
    "ground_truth": "              ",
    "prediction": "               ",
    "index": 951
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_952.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 952
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_953.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 953
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_954.wav",
    "ground_truth": "         ",
    "prediction": "         ",
    "index": 954
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_955.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 955
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_956.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 956
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_957.wav",
    "ground_truth": "            ",
    "prediction": "             ",
    "index": 957
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_958.wav",
    "ground_truth": "           ",
    "prediction": "           ",
    "index": 958
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_959.wav",
    "ground_truth": "           ",
    "prediction": "          ",
    "index": 959
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_960.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 960
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_961.wav",
    "ground_truth": "            ",
    "prediction": "             ",
    "index": 961
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_962.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 962
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_963.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 963
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_964.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 964
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_965.wav",
    "ground_truth": "              ",
    "prediction": "                    ",
    "index": 965
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_966.wav",
    "ground_truth": "          ",
    "prediction": "             ",
    "index": 966
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_967.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 967
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_968.wav",
    "ground_truth": "              ",
    "prediction": "               ",
    "index": 968
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_969.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 969
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_970.wav",
    "ground_truth": "           ",
    "prediction": "            ",
    "index": 970
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_971.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 971
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_972.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 972
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_973.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 973
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_974.wav",
    "ground_truth": "            ",
    "prediction": "            ",
    "index": 974
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_975.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 975
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_976.wav",
    "ground_truth": "             ",
    "prediction": "              ",
    "index": 976
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_977.wav",
    "ground_truth": "             ",
    "prediction": "               ",
    "index": 977
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_978.wav",
    "ground_truth": "            ",
    "prediction": "             ",
    "index": 978
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_979.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 979
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_980.wav",
    "ground_truth": "            ",
    "prediction": "              ",
    "index": 980
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_981.wav",
    "ground_truth": "           ",
    "prediction": "            ",
    "index": 981
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_982.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 982
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_983.wav",
    "ground_truth": "           ",
    "prediction": "            ",
    "index": 983
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_984.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 984
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_985.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 985
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_986.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 986
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_987.wav",
    "ground_truth": "           ",
    "prediction": "            ",
    "index": 987
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_988.wav",
    "ground_truth": "        ",
    "prediction": "          ",
    "index": 988
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_989.wav",
    "ground_truth": "            ",
    "prediction": "             ",
    "index": 989
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_990.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 990
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_991.wav",
    "ground_truth": "              ",
    "prediction": "               ",
    "index": 991
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_992.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 992
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_993.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 993
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_994.wav",
    "ground_truth": "         ",
    "prediction": "         ",
    "index": 994
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_995.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 995
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_996.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 996
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_997.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 997
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_998.wav",
    "ground_truth": "             ",
    "prediction": "              ",
    "index": 998
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_999.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 999
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1000.wav",
    "ground_truth": "            ",
    "prediction": "             ",
    "index": 1000
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1001.wav",
    "ground_truth": "           ",
    "prediction": "             ",
    "index": 1001
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1002.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 1002
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1003.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 1003
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1004.wav",
    "ground_truth": "             ",
    "prediction": "            ",
    "index": 1004
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1005.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 1005
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1006.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 1006
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1007.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 1007
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1008.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 1008
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1009.wav",
    "ground_truth": "              ",
    "prediction": "             ",
    "index": 1009
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1010.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 1010
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1011.wav",
    "ground_truth": "        ",
    "prediction": "          ",
    "index": 1011
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1012.wav",
    "ground_truth": "            ",
    "prediction": "             ",
    "index": 1012
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1013.wav",
    "ground_truth": "            ",
    "prediction": "             ",
    "index": 1013
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1014.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 1014
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1015.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 1015
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1016.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 1016
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1017.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 1017
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1018.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 1018
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1019.wav",
    "ground_truth": "             ",
    "prediction": "              ",
    "index": 1019
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1020.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 1020
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1021.wav",
    "ground_truth": "             ",
    "prediction": "              ",
    "index": 1021
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1022.wav",
    "ground_truth": "            ",
    "prediction": "             ",
    "index": 1022
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1023.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 1023
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1024.wav",
    "ground_truth": "          ",
    "prediction": "          ",
    "index": 1024
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1025.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 1025
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1026.wav",
    "ground_truth": "            ",
    "prediction": "             ",
    "index": 1026
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1027.wav",
    "ground_truth": "          ",
    "prediction": "          ",
    "index": 1027
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1028.wav",
    "ground_truth": "          ",
    "prediction": "          <0xE0><0xB2><0x94> ",
    "index": 1028
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1029.wav",
    "ground_truth": "             ",
    "prediction": "               ",
    "index": 1029
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1030.wav",
    "ground_truth": "           ",
    "prediction": "            ",
    "index": 1030
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1031.wav",
    "ground_truth": "             ",
    "prediction": "              ",
    "index": 1031
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1032.wav",
    "ground_truth": "           ",
    "prediction": "            ",
    "index": 1032
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1033.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 1033
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1034.wav",
    "ground_truth": "         ",
    "prediction": "           ",
    "index": 1034
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1035.wav",
    "ground_truth": "            ",
    "prediction": "             ",
    "index": 1035
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1036.wav",
    "ground_truth": "             ",
    "prediction": "              ",
    "index": 1036
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1037.wav",
    "ground_truth": "           ",
    "prediction": "            ",
    "index": 1037
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1038.wav",
    "ground_truth": "             ",
    "prediction": "               ",
    "index": 1038
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1039.wav",
    "ground_truth": "        ",
    "prediction": "          ",
    "index": 1039
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1040.wav",
    "ground_truth": "            ",
    "prediction": "             ",
    "index": 1040
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1041.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 1041
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1042.wav",
    "ground_truth": "          ",
    "prediction": "          ",
    "index": 1042
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1043.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 1043
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1044.wav",
    "ground_truth": "            ",
    "prediction": "            ",
    "index": 1044
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1045.wav",
    "ground_truth": "             ",
    "prediction": "              ",
    "index": 1045
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1046.wav",
    "ground_truth": "            ",
    "prediction": "      <0xE0><0xB2><0x94>      ",
    "index": 1046
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1047.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 1047
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1048.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 1048
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1049.wav",
    "ground_truth": "           ",
    "prediction": "           ",
    "index": 1049
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1050.wav",
    "ground_truth": "           ",
    "prediction": "            ",
    "index": 1050
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1051.wav",
    "ground_truth": "           ",
    "prediction": "            ",
    "index": 1051
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1052.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 1052
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1053.wav",
    "ground_truth": "              ",
    "prediction": "              ",
    "index": 1053
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1054.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 1054
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1055.wav",
    "ground_truth": "            ",
    "prediction": "            ",
    "index": 1055
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1056.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 1056
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1057.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 1057
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1058.wav",
    "ground_truth": "            ",
    "prediction": "              ",
    "index": 1058
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1059.wav",
    "ground_truth": "            ",
    "prediction": "             ",
    "index": 1059
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1060.wav",
    "ground_truth": "              ",
    "prediction": "               ",
    "index": 1060
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1061.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 1061
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1062.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 1062
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1063.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 1063
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1064.wav",
    "ground_truth": "            ",
    "prediction": "          <0xE0><0xB2><0x94>  ",
    "index": 1064
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1065.wav",
    "ground_truth": "            ",
    "prediction": "              ",
    "index": 1065
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1066.wav",
    "ground_truth": "         ",
    "prediction": "        ",
    "index": 1066
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1067.wav",
    "ground_truth": "         ",
    "prediction": "           ",
    "index": 1067
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1068.wav",
    "ground_truth": "             ",
    "prediction": "             ",
    "index": 1068
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1069.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 1069
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1070.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 1070
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1071.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 1071
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1072.wav",
    "ground_truth": "            ",
    "prediction": "             ",
    "index": 1072
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1073.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 1073
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1074.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 1074
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1075.wav",
    "ground_truth": "          ",
    "prediction": "       <0xE0><0xB2><0xA2>    ",
    "index": 1075
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1076.wav",
    "ground_truth": "             ",
    "prediction": "             ",
    "index": 1076
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1077.wav",
    "ground_truth": "            ",
    "prediction": "             ",
    "index": 1077
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1078.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 1078
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1079.wav",
    "ground_truth": "         ",
    "prediction": "        ",
    "index": 1079
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1080.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 1080
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1081.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 1081
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1082.wav",
    "ground_truth": "            ",
    "prediction": "             ",
    "index": 1082
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1083.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 1083
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1084.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 1084
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1085.wav",
    "ground_truth": "             ",
    "prediction": "            <0xE0><0xB2><0x8A>  <0xE0><0xB2><0xA2>",
    "index": 1085
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1086.wav",
    "ground_truth": "           ",
    "prediction": "            ",
    "index": 1086
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1087.wav",
    "ground_truth": "             ",
    "prediction": "              ",
    "index": 1087
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1088.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 1088
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1089.wav",
    "ground_truth": "           ",
    "prediction": "            ",
    "index": 1089
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1090.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 1090
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1091.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 1091
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1092.wav",
    "ground_truth": "           ",
    "prediction": "            ",
    "index": 1092
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1093.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 1093
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1094.wav",
    "ground_truth": "              ",
    "prediction": "             ",
    "index": 1094
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1095.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 1095
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1096.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 1096
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1097.wav",
    "ground_truth": "           ",
    "prediction": "            ",
    "index": 1097
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1098.wav",
    "ground_truth": "          ",
    "prediction": "            ",
    "index": 1098
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1099.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 1099
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1100.wav",
    "ground_truth": "           ",
    "prediction": "          ",
    "index": 1100
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1101.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 1101
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1102.wav",
    "ground_truth": "           ",
    "prediction": "            ",
    "index": 1102
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1103.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 1103
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1104.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 1104
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1105.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 1105
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1106.wav",
    "ground_truth": "           ",
    "prediction": "            ",
    "index": 1106
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1107.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 1107
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1108.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 1108
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1109.wav",
    "ground_truth": "           ",
    "prediction": "            ",
    "index": 1109
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1110.wav",
    "ground_truth": "          ",
    "prediction": "          ",
    "index": 1110
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1111.wav",
    "ground_truth": "        ",
    "prediction": "          ",
    "index": 1111
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1112.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 1112
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1113.wav",
    "ground_truth": "         ",
    "prediction": "         ",
    "index": 1113
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1114.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 1114
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1115.wav",
    "ground_truth": "            ",
    "prediction": "              ",
    "index": 1115
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1116.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 1116
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1117.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 1117
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1118.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 1118
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1119.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 1119
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1120.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 1120
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1121.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 1121
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1122.wav",
    "ground_truth": "            ",
    "prediction": "            ",
    "index": 1122
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1123.wav",
    "ground_truth": "          ",
    "prediction": "         ",
    "index": 1123
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1124.wav",
    "ground_truth": "             ",
    "prediction": "             ",
    "index": 1124
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1125.wav",
    "ground_truth": "            ",
    "prediction": "             ",
    "index": 1125
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1126.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 1126
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1127.wav",
    "ground_truth": "           ",
    "prediction": "          ",
    "index": 1127
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1128.wav",
    "ground_truth": "        ",
    "prediction": "        ",
    "index": 1128
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1129.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 1129
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1130.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 1130
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1131.wav",
    "ground_truth": "              ",
    "prediction": "               ",
    "index": 1131
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1132.wav",
    "ground_truth": "        ",
    "prediction": "          ",
    "index": 1132
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1133.wav",
    "ground_truth": "            ",
    "prediction": "            ",
    "index": 1133
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1134.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 1134
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1135.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 1135
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1136.wav",
    "ground_truth": "            ",
    "prediction": "                ",
    "index": 1136
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1137.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 1137
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1138.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 1138
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1139.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 1139
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1140.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 1140
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1141.wav",
    "ground_truth": "           ",
    "prediction": "       <0xE0><0xB2><0x94>     ",
    "index": 1141
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1142.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 1142
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1143.wav",
    "ground_truth": "            ",
    "prediction": "             ",
    "index": 1143
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1144.wav",
    "ground_truth": "         ",
    "prediction": "           ",
    "index": 1144
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1145.wav",
    "ground_truth": "          ",
    "prediction": "          ",
    "index": 1145
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1146.wav",
    "ground_truth": "        ",
    "prediction": "          ",
    "index": 1146
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1147.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 1147
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1148.wav",
    "ground_truth": "            ",
    "prediction": "             ",
    "index": 1148
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1149.wav",
    "ground_truth": "              ",
    "prediction": "              ",
    "index": 1149
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1150.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 1150
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1151.wav",
    "ground_truth": "            ",
    "prediction": "             ",
    "index": 1151
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1152.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 1152
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1153.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 1153
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1154.wav",
    "ground_truth": "            ",
    "prediction": "             ",
    "index": 1154
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1155.wav",
    "ground_truth": "             ",
    "prediction": "             ",
    "index": 1155
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1156.wav",
    "ground_truth": "            ",
    "prediction": "             ",
    "index": 1156
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1157.wav",
    "ground_truth": "         ",
    "prediction": "         ",
    "index": 1157
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1158.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 1158
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1159.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 1159
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1160.wav",
    "ground_truth": "        ",
    "prediction": "          ",
    "index": 1160
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1161.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 1161
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1162.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 1162
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1163.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 1163
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1164.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 1164
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1165.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 1165
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1166.wav",
    "ground_truth": "            ",
    "prediction": "             ",
    "index": 1166
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1167.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 1167
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1168.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 1168
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1169.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 1169
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1170.wav",
    "ground_truth": "              ",
    "prediction": "               ",
    "index": 1170
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1171.wav",
    "ground_truth": "              ",
    "prediction": "               ",
    "index": 1171
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1172.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 1172
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1173.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 1173
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1174.wav",
    "ground_truth": "              ",
    "prediction": "         <0xE0><0xB2><0xA2>      ",
    "index": 1174
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1175.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 1175
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1176.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 1176
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1177.wav",
    "ground_truth": "             ",
    "prediction": "            ",
    "index": 1177
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1178.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 1178
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1179.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 1179
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1180.wav",
    "ground_truth": "             ",
    "prediction": "              ",
    "index": 1180
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1181.wav",
    "ground_truth": "             ",
    "prediction": "              ",
    "index": 1181
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1182.wav",
    "ground_truth": "           ",
    "prediction": "            ",
    "index": 1182
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1183.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 1183
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1184.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 1184
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1185.wav",
    "ground_truth": "            ",
    "prediction": "            ",
    "index": 1185
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1186.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 1186
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1187.wav",
    "ground_truth": "          ",
    "prediction": "          ",
    "index": 1187
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1188.wav",
    "ground_truth": "           ",
    "prediction": "            ",
    "index": 1188
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1189.wav",
    "ground_truth": "           ",
    "prediction": "           ",
    "index": 1189
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1190.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 1190
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1191.wav",
    "ground_truth": "           ",
    "prediction": "            ",
    "index": 1191
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1192.wav",
    "ground_truth": "        ",
    "prediction": "          ",
    "index": 1192
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1193.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 1193
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1194.wav",
    "ground_truth": "           ",
    "prediction": "            ",
    "index": 1194
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1195.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 1195
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1196.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 1196
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1197.wav",
    "ground_truth": "           ",
    "prediction": "           ",
    "index": 1197
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1198.wav",
    "ground_truth": "            ",
    "prediction": "            ",
    "index": 1198
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1199.wav",
    "ground_truth": "           ",
    "prediction": "           ",
    "index": 1199
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1200.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 1200
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1201.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 1201
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1202.wav",
    "ground_truth": "         ",
    "prediction": "           ",
    "index": 1202
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1203.wav",
    "ground_truth": "        ",
    "prediction": "          ",
    "index": 1203
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1204.wav",
    "ground_truth": "          ",
    "prediction": "      <0xE0><0xB2><0x8A>     ",
    "index": 1204
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1205.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 1205
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1206.wav",
    "ground_truth": "           ",
    "prediction": "            ",
    "index": 1206
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1207.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 1207
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1208.wav",
    "ground_truth": "              ",
    "prediction": "               ",
    "index": 1208
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1209.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 1209
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1210.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 1210
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1211.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 1211
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1212.wav",
    "ground_truth": "              ",
    "prediction": "               ",
    "index": 1212
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1213.wav",
    "ground_truth": "          ",
    "prediction": "          ",
    "index": 1213
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1214.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 1214
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1215.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 1215
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1216.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 1216
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1217.wav",
    "ground_truth": "           ",
    "prediction": "            ",
    "index": 1217
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1218.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 1218
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1219.wav",
    "ground_truth": "             ",
    "prediction": "             ",
    "index": 1219
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1220.wav",
    "ground_truth": "             ",
    "prediction": "               ",
    "index": 1220
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1221.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 1221
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1222.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 1222
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1223.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 1223
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1224.wav",
    "ground_truth": "             ",
    "prediction": "              ",
    "index": 1224
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1225.wav",
    "ground_truth": "            ",
    "prediction": "             ",
    "index": 1225
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1226.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 1226
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1227.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 1227
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1228.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 1228
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1229.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 1229
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1230.wav",
    "ground_truth": "         ",
    "prediction": "           ",
    "index": 1230
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1231.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 1231
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1232.wav",
    "ground_truth": "              ",
    "prediction": "               ",
    "index": 1232
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1233.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 1233
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1234.wav",
    "ground_truth": "         ",
    "prediction": "           ",
    "index": 1234
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1235.wav",
    "ground_truth": "              ",
    "prediction": "                ",
    "index": 1235
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1236.wav",
    "ground_truth": "            ",
    "prediction": "             ",
    "index": 1236
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1237.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 1237
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1238.wav",
    "ground_truth": "        ",
    "prediction": "          ",
    "index": 1238
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1239.wav",
    "ground_truth": "          ",
    "prediction": "          ",
    "index": 1239
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1240.wav",
    "ground_truth": "          ",
    "prediction": "            ",
    "index": 1240
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1241.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 1241
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1242.wav",
    "ground_truth": "            ",
    "prediction": "             ",
    "index": 1242
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1243.wav",
    "ground_truth": "           ",
    "prediction": "           ",
    "index": 1243
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1244.wav",
    "ground_truth": "            ",
    "prediction": "            ",
    "index": 1244
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1245.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 1245
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1246.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 1246
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1247.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 1247
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1248.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 1248
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1249.wav",
    "ground_truth": "        ",
    "prediction": "      <0xE0><0xB2><0x8A>   ",
    "index": 1249
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1250.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 1250
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1251.wav",
    "ground_truth": "              ",
    "prediction": "               ",
    "index": 1251
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1252.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 1252
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1253.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 1253
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1254.wav",
    "ground_truth": "         ",
    "prediction": "           ",
    "index": 1254
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1255.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 1255
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1256.wav",
    "ground_truth": "              ",
    "prediction": "               ",
    "index": 1256
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1257.wav",
    "ground_truth": "          ",
    "prediction": "            ",
    "index": 1257
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1258.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 1258
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1259.wav",
    "ground_truth": "           ",
    "prediction": "            ",
    "index": 1259
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1260.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 1260
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1261.wav",
    "ground_truth": "         ",
    "prediction": "         ",
    "index": 1261
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1262.wav",
    "ground_truth": "              ",
    "prediction": "              ",
    "index": 1262
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1263.wav",
    "ground_truth": "          ",
    "prediction": "            ",
    "index": 1263
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1264.wav",
    "ground_truth": "        ",
    "prediction": "          ",
    "index": 1264
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1265.wav",
    "ground_truth": "            ",
    "prediction": "             ",
    "index": 1265
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1266.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 1266
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1267.wav",
    "ground_truth": "              ",
    "prediction": "               ",
    "index": 1267
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1268.wav",
    "ground_truth": "           ",
    "prediction": "             ",
    "index": 1268
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1269.wav",
    "ground_truth": "            ",
    "prediction": "             ",
    "index": 1269
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1270.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 1270
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1271.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 1271
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1272.wav",
    "ground_truth": "        ",
    "prediction": "        ",
    "index": 1272
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1273.wav",
    "ground_truth": "          ",
    "prediction": "          ",
    "index": 1273
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1274.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 1274
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1275.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 1275
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1276.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 1276
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1277.wav",
    "ground_truth": "            ",
    "prediction": "            ",
    "index": 1277
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1278.wav",
    "ground_truth": "             ",
    "prediction": "              ",
    "index": 1278
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1279.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 1279
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1280.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 1280
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1281.wav",
    "ground_truth": "              ",
    "prediction": "               ",
    "index": 1281
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1282.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 1282
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1283.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 1283
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1284.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 1284
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1285.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 1285
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1286.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 1286
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1287.wav",
    "ground_truth": "             ",
    "prediction": "              ",
    "index": 1287
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1288.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 1288
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1289.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 1289
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1290.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 1290
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1291.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 1291
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1292.wav",
    "ground_truth": "        ",
    "prediction": "          ",
    "index": 1292
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1293.wav",
    "ground_truth": "            ",
    "prediction": "            ",
    "index": 1293
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1294.wav",
    "ground_truth": "        ",
    "prediction": "          ",
    "index": 1294
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1295.wav",
    "ground_truth": "            ",
    "prediction": "            ",
    "index": 1295
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1296.wav",
    "ground_truth": "            ",
    "prediction": "             ",
    "index": 1296
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1297.wav",
    "ground_truth": "            ",
    "prediction": "             ",
    "index": 1297
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1298.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 1298
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1299.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 1299
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1300.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 1300
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1301.wav",
    "ground_truth": "              ",
    "prediction": "                ",
    "index": 1301
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1302.wav",
    "ground_truth": "         ",
    "prediction": "           ",
    "index": 1302
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1303.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 1303
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1304.wav",
    "ground_truth": "              ",
    "prediction": "               ",
    "index": 1304
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1305.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 1305
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1306.wav",
    "ground_truth": "              ",
    "prediction": "                ",
    "index": 1306
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1307.wav",
    "ground_truth": "            ",
    "prediction": "             ",
    "index": 1307
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1308.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 1308
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1309.wav",
    "ground_truth": "             ",
    "prediction": "              ",
    "index": 1309
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1310.wav",
    "ground_truth": "            ",
    "prediction": "                ",
    "index": 1310
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1311.wav",
    "ground_truth": "           ",
    "prediction": "            ",
    "index": 1311
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1312.wav",
    "ground_truth": "            ",
    "prediction": "             ",
    "index": 1312
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1313.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 1313
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1314.wav",
    "ground_truth": "        ",
    "prediction": "          ",
    "index": 1314
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1315.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 1315
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1316.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 1316
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1317.wav",
    "ground_truth": "            ",
    "prediction": "             ",
    "index": 1317
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1318.wav",
    "ground_truth": "              ",
    "prediction": "               ",
    "index": 1318
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1319.wav",
    "ground_truth": "              ",
    "prediction": "               ",
    "index": 1319
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1320.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 1320
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1321.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 1321
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1322.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 1322
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1323.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 1323
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1324.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 1324
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1325.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 1325
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1326.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 1326
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1327.wav",
    "ground_truth": "         ",
    "prediction": "           ",
    "index": 1327
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1328.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 1328
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1329.wav",
    "ground_truth": "              ",
    "prediction": "               ",
    "index": 1329
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1330.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 1330
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1331.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 1331
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1332.wav",
    "ground_truth": "          ",
    "prediction": "         ",
    "index": 1332
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1333.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 1333
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1334.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 1334
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1335.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 1335
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1336.wav",
    "ground_truth": "        ",
    "prediction": "        ",
    "index": 1336
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1337.wav",
    "ground_truth": "        ",
    "prediction": "          ",
    "index": 1337
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1338.wav",
    "ground_truth": "            ",
    "prediction": "             ",
    "index": 1338
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1339.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 1339
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1340.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 1340
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1341.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 1341
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1342.wav",
    "ground_truth": "          ",
    "prediction": "          ",
    "index": 1342
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1343.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 1343
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1344.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 1344
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1345.wav",
    "ground_truth": "            ",
    "prediction": "             ",
    "index": 1345
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1346.wav",
    "ground_truth": "           ",
    "prediction": "           ",
    "index": 1346
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1347.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 1347
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1348.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 1348
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1349.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 1349
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1350.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 1350
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1351.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 1351
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1352.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 1352
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1353.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 1353
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1354.wav",
    "ground_truth": "             ",
    "prediction": "              ",
    "index": 1354
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1355.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 1355
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1356.wav",
    "ground_truth": "        ",
    "prediction": "           ",
    "index": 1356
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1357.wav",
    "ground_truth": "              ",
    "prediction": "              ",
    "index": 1357
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1358.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 1358
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1359.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 1359
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1360.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 1360
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1361.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 1361
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1362.wav",
    "ground_truth": "        ",
    "prediction": "          ",
    "index": 1362
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1363.wav",
    "ground_truth": "          ",
    "prediction": "          ",
    "index": 1363
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1364.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 1364
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1365.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 1365
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1366.wav",
    "ground_truth": "           ",
    "prediction": "            ",
    "index": 1366
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1367.wav",
    "ground_truth": "            ",
    "prediction": "             ",
    "index": 1367
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1368.wav",
    "ground_truth": "          ",
    "prediction": "          ",
    "index": 1368
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1369.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 1369
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1370.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 1370
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1371.wav",
    "ground_truth": "          ",
    "prediction": "          ",
    "index": 1371
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1372.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 1372
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1373.wav",
    "ground_truth": "              ",
    "prediction": "               ",
    "index": 1373
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1374.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 1374
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1375.wav",
    "ground_truth": "              ",
    "prediction": "              ",
    "index": 1375
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1376.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 1376
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1377.wav",
    "ground_truth": "         ",
    "prediction": "           ",
    "index": 1377
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1378.wav",
    "ground_truth": "       ",
    "prediction": "        ",
    "index": 1378
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1379.wav",
    "ground_truth": "             ",
    "prediction": "              ",
    "index": 1379
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1380.wav",
    "ground_truth": "       ",
    "prediction": "        ",
    "index": 1380
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1381.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 1381
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1382.wav",
    "ground_truth": "        ",
    "prediction": "          ",
    "index": 1382
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1383.wav",
    "ground_truth": "        ",
    "prediction": "          ",
    "index": 1383
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1384.wav",
    "ground_truth": "         ",
    "prediction": "         ",
    "index": 1384
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1385.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 1385
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1386.wav",
    "ground_truth": "       ",
    "prediction": "        ",
    "index": 1386
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1387.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 1387
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1388.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 1388
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1389.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 1389
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1390.wav",
    "ground_truth": "             ",
    "prediction": "              ",
    "index": 1390
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1391.wav",
    "ground_truth": "         ",
    "prediction": "           ",
    "index": 1391
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1392.wav",
    "ground_truth": "       ",
    "prediction": "        ",
    "index": 1392
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1393.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 1393
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1394.wav",
    "ground_truth": "          ",
    "prediction": "        ",
    "index": 1394
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1395.wav",
    "ground_truth": "       ",
    "prediction": "        ",
    "index": 1395
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1396.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 1396
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1397.wav",
    "ground_truth": "        ",
    "prediction": "          ",
    "index": 1397
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1398.wav",
    "ground_truth": "            ",
    "prediction": "             ",
    "index": 1398
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1399.wav",
    "ground_truth": "          ",
    "prediction": "          ",
    "index": 1399
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1400.wav",
    "ground_truth": "           ",
    "prediction": "           ",
    "index": 1400
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1401.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 1401
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1402.wav",
    "ground_truth": "          ",
    "prediction": "            ",
    "index": 1402
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1403.wav",
    "ground_truth": "       ",
    "prediction": "         ",
    "index": 1403
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1404.wav",
    "ground_truth": "             ",
    "prediction": "              ",
    "index": 1404
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1405.wav",
    "ground_truth": "           ",
    "prediction": "            ",
    "index": 1405
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1406.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 1406
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1407.wav",
    "ground_truth": "       ",
    "prediction": "        ",
    "index": 1407
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1408.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 1408
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1409.wav",
    "ground_truth": "             ",
    "prediction": "             ",
    "index": 1409
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1410.wav",
    "ground_truth": "            ",
    "prediction": "             ",
    "index": 1410
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1411.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 1411
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1412.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 1412
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1413.wav",
    "ground_truth": "             ",
    "prediction": "              ",
    "index": 1413
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1414.wav",
    "ground_truth": "             ",
    "prediction": "               ",
    "index": 1414
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1415.wav",
    "ground_truth": "          ",
    "prediction": "            ",
    "index": 1415
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1416.wav",
    "ground_truth": "       ",
    "prediction": "        ",
    "index": 1416
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1417.wav",
    "ground_truth": "       ",
    "prediction": "        ",
    "index": 1417
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1418.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 1418
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1419.wav",
    "ground_truth": "       ",
    "prediction": "        ",
    "index": 1419
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1420.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 1420
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1421.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 1421
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1422.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 1422
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1423.wav",
    "ground_truth": "       ",
    "prediction": "        ",
    "index": 1423
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1424.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 1424
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1425.wav",
    "ground_truth": "        ",
    "prediction": "          ",
    "index": 1425
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1426.wav",
    "ground_truth": "            ",
    "prediction": "             ",
    "index": 1426
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1427.wav",
    "ground_truth": "           ",
    "prediction": "            ",
    "index": 1427
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1428.wav",
    "ground_truth": "        ",
    "prediction": "          ",
    "index": 1428
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1429.wav",
    "ground_truth": "         ",
    "prediction": "         ",
    "index": 1429
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1430.wav",
    "ground_truth": "         ",
    "prediction": "         ",
    "index": 1430
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1431.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 1431
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1432.wav",
    "ground_truth": "           ",
    "prediction": "            ",
    "index": 1432
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1433.wav",
    "ground_truth": "         ",
    "prediction": "           ",
    "index": 1433
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1434.wav",
    "ground_truth": "           ",
    "prediction": "            ",
    "index": 1434
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1435.wav",
    "ground_truth": "             ",
    "prediction": "              ",
    "index": 1435
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1436.wav",
    "ground_truth": "             ",
    "prediction": "              ",
    "index": 1436
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1437.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 1437
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1438.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 1438
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1439.wav",
    "ground_truth": "           ",
    "prediction": "            ",
    "index": 1439
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1440.wav",
    "ground_truth": "           ",
    "prediction": "             ",
    "index": 1440
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1441.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 1441
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1442.wav",
    "ground_truth": "             ",
    "prediction": "               ",
    "index": 1442
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1443.wav",
    "ground_truth": "           ",
    "prediction": "            ",
    "index": 1443
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1444.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 1444
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1445.wav",
    "ground_truth": "          ",
    "prediction": "          ",
    "index": 1445
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1446.wav",
    "ground_truth": "       ",
    "prediction": "         ",
    "index": 1446
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1447.wav",
    "ground_truth": "             ",
    "prediction": "              ",
    "index": 1447
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1448.wav",
    "ground_truth": "       ",
    "prediction": "        ",
    "index": 1448
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1449.wav",
    "ground_truth": "             ",
    "prediction": "              ",
    "index": 1449
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1450.wav",
    "ground_truth": "              ",
    "prediction": "  <0xE0><0xB2><0x94>            ",
    "index": 1450
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1451.wav",
    "ground_truth": "             ",
    "prediction": "               ",
    "index": 1451
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1452.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 1452
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1453.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 1453
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1454.wav",
    "ground_truth": "       ",
    "prediction": "        ",
    "index": 1454
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1455.wav",
    "ground_truth": "         ",
    "prediction": "           ",
    "index": 1455
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1456.wav",
    "ground_truth": "            ",
    "prediction": "            ",
    "index": 1456
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1457.wav",
    "ground_truth": "          ",
    "prediction": "            ",
    "index": 1457
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1458.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 1458
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1459.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 1459
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1460.wav",
    "ground_truth": "            ",
    "prediction": "  <0xE0><0xB2><0x8A>            ",
    "index": 1460
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1461.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 1461
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1462.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 1462
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1463.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 1463
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1464.wav",
    "ground_truth": "           ",
    "prediction": "            ",
    "index": 1464
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1465.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 1465
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1466.wav",
    "ground_truth": "       ",
    "prediction": "       ",
    "index": 1466
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1467.wav",
    "ground_truth": "              ",
    "prediction": "    <0xE0><0xB2><0xA2>          ",
    "index": 1467
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1468.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 1468
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1469.wav",
    "ground_truth": "        ",
    "prediction": "        ",
    "index": 1469
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1470.wav",
    "ground_truth": "              ",
    "prediction": "              ",
    "index": 1470
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1471.wav",
    "ground_truth": "            ",
    "prediction": "             ",
    "index": 1471
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1472.wav",
    "ground_truth": "       ",
    "prediction": "         ",
    "index": 1472
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1473.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 1473
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1474.wav",
    "ground_truth": "            ",
    "prediction": "             ",
    "index": 1474
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1475.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 1475
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1476.wav",
    "ground_truth": "          ",
    "prediction": "          ",
    "index": 1476
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1477.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 1477
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1478.wav",
    "ground_truth": "             ",
    "prediction": "              ",
    "index": 1478
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1479.wav",
    "ground_truth": "             ",
    "prediction": "                ",
    "index": 1479
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1480.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 1480
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1481.wav",
    "ground_truth": "           ",
    "prediction": "            ",
    "index": 1481
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1482.wav",
    "ground_truth": "              ",
    "prediction": "               ",
    "index": 1482
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1483.wav",
    "ground_truth": "           ",
    "prediction": "            ",
    "index": 1483
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1484.wav",
    "ground_truth": "        ",
    "prediction": "          ",
    "index": 1484
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1485.wav",
    "ground_truth": "       ",
    "prediction": "        ",
    "index": 1485
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1486.wav",
    "ground_truth": "       ",
    "prediction": "        ",
    "index": 1486
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1487.wav",
    "ground_truth": "       ",
    "prediction": "        ",
    "index": 1487
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1488.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 1488
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1489.wav",
    "ground_truth": "        ",
    "prediction": "        ",
    "index": 1489
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1490.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 1490
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1491.wav",
    "ground_truth": "            ",
    "prediction": "             ",
    "index": 1491
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1492.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 1492
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1493.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 1493
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1494.wav",
    "ground_truth": "              ",
    "prediction": "              ",
    "index": 1494
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1495.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 1495
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1496.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 1496
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1497.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 1497
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1498.wav",
    "ground_truth": "       ",
    "prediction": "         ",
    "index": 1498
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1499.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 1499
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1500.wav",
    "ground_truth": "           ",
    "prediction": "            ",
    "index": 1500
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1501.wav",
    "ground_truth": "       ",
    "prediction": "        ",
    "index": 1501
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1502.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 1502
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1503.wav",
    "ground_truth": "             ",
    "prediction": "             ",
    "index": 1503
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1504.wav",
    "ground_truth": "              ",
    "prediction": "               ",
    "index": 1504
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1505.wav",
    "ground_truth": "         ",
    "prediction": "           ",
    "index": 1505
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1506.wav",
    "ground_truth": "        ",
    "prediction": "          ",
    "index": 1506
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1507.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 1507
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1508.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 1508
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1509.wav",
    "ground_truth": "             ",
    "prediction": "              ",
    "index": 1509
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1510.wav",
    "ground_truth": "       ",
    "prediction": "        ",
    "index": 1510
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1511.wav",
    "ground_truth": "            ",
    "prediction": "             ",
    "index": 1511
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1512.wav",
    "ground_truth": "             ",
    "prediction": "           <0xE0><0xB2><0x8A>   ",
    "index": 1512
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1513.wav",
    "ground_truth": "       ",
    "prediction": "        ",
    "index": 1513
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1514.wav",
    "ground_truth": "             ",
    "prediction": "              ",
    "index": 1514
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1515.wav",
    "ground_truth": "           ",
    "prediction": "           ",
    "index": 1515
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1516.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 1516
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1517.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 1517
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1518.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 1518
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1519.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 1519
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1520.wav",
    "ground_truth": "            ",
    "prediction": "             ",
    "index": 1520
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1521.wav",
    "ground_truth": "       ",
    "prediction": "         ",
    "index": 1521
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1522.wav",
    "ground_truth": "       ",
    "prediction": "        ",
    "index": 1522
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1523.wav",
    "ground_truth": "          ",
    "prediction": "  <0xE0><0xB2><0x8A>      <0xE0><0xB2><0x8A>   ",
    "index": 1523
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1524.wav",
    "ground_truth": "          ",
    "prediction": "     <0xE0><0xB2><0x8B>       ",
    "index": 1524
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1525.wav",
    "ground_truth": "         ",
    "prediction": "         ",
    "index": 1525
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1526.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 1526
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1527.wav",
    "ground_truth": "           ",
    "prediction": "            ",
    "index": 1527
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1528.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 1528
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1529.wav",
    "ground_truth": "       ",
    "prediction": "        ",
    "index": 1529
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1530.wav",
    "ground_truth": "       ",
    "prediction": "        ",
    "index": 1530
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1531.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 1531
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1532.wav",
    "ground_truth": "           ",
    "prediction": "            ",
    "index": 1532
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1533.wav",
    "ground_truth": "          ",
    "prediction": "          ",
    "index": 1533
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1534.wav",
    "ground_truth": "           ",
    "prediction": "           ",
    "index": 1534
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1535.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 1535
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1536.wav",
    "ground_truth": "            ",
    "prediction": "             ",
    "index": 1536
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1537.wav",
    "ground_truth": "          ",
    "prediction": "            ",
    "index": 1537
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1538.wav",
    "ground_truth": "       ",
    "prediction": "        ",
    "index": 1538
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1539.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 1539
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1540.wav",
    "ground_truth": "       ",
    "prediction": "        ",
    "index": 1540
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1541.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 1541
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1542.wav",
    "ground_truth": "       ",
    "prediction": "         ",
    "index": 1542
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1543.wav",
    "ground_truth": "           ",
    "prediction": "           ",
    "index": 1543
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1544.wav",
    "ground_truth": "       ",
    "prediction": "       ",
    "index": 1544
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1545.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 1545
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1546.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 1546
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1547.wav",
    "ground_truth": "       ",
    "prediction": "         ",
    "index": 1547
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1548.wav",
    "ground_truth": "       ",
    "prediction": "         ",
    "index": 1548
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1549.wav",
    "ground_truth": "          ",
    "prediction": "      <0xE0><0xB2><0x94>    ",
    "index": 1549
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1550.wav",
    "ground_truth": "        ",
    "prediction": "        ",
    "index": 1550
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1551.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 1551
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1552.wav",
    "ground_truth": "             ",
    "prediction": "               ",
    "index": 1552
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1553.wav",
    "ground_truth": "              ",
    "prediction": "              <0xE0><0xB2><0x94>  ",
    "index": 1553
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1554.wav",
    "ground_truth": "            ",
    "prediction": "           ",
    "index": 1554
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1555.wav",
    "ground_truth": "            ",
    "prediction": "            ",
    "index": 1555
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1556.wav",
    "ground_truth": "              ",
    "prediction": "              ",
    "index": 1556
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1557.wav",
    "ground_truth": "            ",
    "prediction": "            ",
    "index": 1557
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1558.wav",
    "ground_truth": "       ",
    "prediction": "        ",
    "index": 1558
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1559.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 1559
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1560.wav",
    "ground_truth": "        ",
    "prediction": "          ",
    "index": 1560
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1561.wav",
    "ground_truth": "            ",
    "prediction": "             ",
    "index": 1561
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1562.wav",
    "ground_truth": "           ",
    "prediction": "           ",
    "index": 1562
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1563.wav",
    "ground_truth": "       ",
    "prediction": "           ",
    "index": 1563
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1564.wav",
    "ground_truth": "        ",
    "prediction": "          ",
    "index": 1564
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1565.wav",
    "ground_truth": "            ",
    "prediction": "            ",
    "index": 1565
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1566.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 1566
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1567.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 1567
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1568.wav",
    "ground_truth": "       ",
    "prediction": "        ",
    "index": 1568
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1569.wav",
    "ground_truth": "        ",
    "prediction": " <0xE0><0xB2><0xA2>        ",
    "index": 1569
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1570.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 1570
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1571.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 1571
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1572.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 1572
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1573.wav",
    "ground_truth": "           ",
    "prediction": "            ",
    "index": 1573
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1574.wav",
    "ground_truth": "           ",
    "prediction": "            ",
    "index": 1574
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1575.wav",
    "ground_truth": "        ",
    "prediction": "          ",
    "index": 1575
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1576.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 1576
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1577.wav",
    "ground_truth": "             ",
    "prediction": "              ",
    "index": 1577
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1578.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 1578
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1579.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 1579
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1580.wav",
    "ground_truth": "             ",
    "prediction": "              ",
    "index": 1580
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1581.wav",
    "ground_truth": "           ",
    "prediction": "            ",
    "index": 1581
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1582.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 1582
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1583.wav",
    "ground_truth": "            ",
    "prediction": "             ",
    "index": 1583
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1584.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 1584
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1585.wav",
    "ground_truth": "            ",
    "prediction": "              ",
    "index": 1585
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1586.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 1586
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1587.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 1587
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1588.wav",
    "ground_truth": "            ",
    "prediction": "            ",
    "index": 1588
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1589.wav",
    "ground_truth": "            ",
    "prediction": "              ",
    "index": 1589
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1590.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 1590
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1591.wav",
    "ground_truth": "       ",
    "prediction": "         ",
    "index": 1591
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1592.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 1592
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1593.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 1593
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1594.wav",
    "ground_truth": "             ",
    "prediction": "              ",
    "index": 1594
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1595.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 1595
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1596.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 1596
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1597.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 1597
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1598.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 1598
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1599.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 1599
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1600.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 1600
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1601.wav",
    "ground_truth": "           ",
    "prediction": "            ",
    "index": 1601
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1602.wav",
    "ground_truth": "             ",
    "prediction": "             ",
    "index": 1602
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1603.wav",
    "ground_truth": "             ",
    "prediction": "              ",
    "index": 1603
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1604.wav",
    "ground_truth": "          ",
    "prediction": "             ",
    "index": 1604
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1605.wav",
    "ground_truth": "        ",
    "prediction": "        ",
    "index": 1605
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1606.wav",
    "ground_truth": "             ",
    "prediction": "              ",
    "index": 1606
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1607.wav",
    "ground_truth": "            ",
    "prediction": "             ",
    "index": 1607
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1608.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 1608
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1609.wav",
    "ground_truth": "              ",
    "prediction": "              <0xE0><0xB2><0x8A> ",
    "index": 1609
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1610.wav",
    "ground_truth": "       ",
    "prediction": "        ",
    "index": 1610
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1611.wav",
    "ground_truth": "           ",
    "prediction": "           ",
    "index": 1611
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1612.wav",
    "ground_truth": "       ",
    "prediction": "        ",
    "index": 1612
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1613.wav",
    "ground_truth": "       ",
    "prediction": "        ",
    "index": 1613
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1614.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 1614
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1615.wav",
    "ground_truth": "           ",
    "prediction": "             ",
    "index": 1615
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1616.wav",
    "ground_truth": "             ",
    "prediction": "              ",
    "index": 1616
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1617.wav",
    "ground_truth": "       ",
    "prediction": "         ",
    "index": 1617
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1618.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 1618
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1619.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 1619
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1620.wav",
    "ground_truth": "           ",
    "prediction": "            ",
    "index": 1620
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1621.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 1621
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1622.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 1622
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1623.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 1623
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1624.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 1624
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1625.wav",
    "ground_truth": "              ",
    "prediction": "               ",
    "index": 1625
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1626.wav",
    "ground_truth": "             ",
    "prediction": "              ",
    "index": 1626
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1627.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 1627
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1628.wav",
    "ground_truth": "            ",
    "prediction": "             ",
    "index": 1628
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1629.wav",
    "ground_truth": "             ",
    "prediction": "              ",
    "index": 1629
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1630.wav",
    "ground_truth": "       ",
    "prediction": "        ",
    "index": 1630
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1631.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 1631
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1632.wav",
    "ground_truth": "             ",
    "prediction": "           ",
    "index": 1632
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1633.wav",
    "ground_truth": "        ",
    "prediction": "          ",
    "index": 1633
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1634.wav",
    "ground_truth": "           ",
    "prediction": "            ",
    "index": 1634
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1635.wav",
    "ground_truth": "        ",
    "prediction": "          ",
    "index": 1635
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1636.wav",
    "ground_truth": "           ",
    "prediction": "            ",
    "index": 1636
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1637.wav",
    "ground_truth": "       ",
    "prediction": "        ",
    "index": 1637
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1638.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 1638
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1639.wav",
    "ground_truth": "            ",
    "prediction": "           ",
    "index": 1639
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1640.wav",
    "ground_truth": "        ",
    "prediction": "          ",
    "index": 1640
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1641.wav",
    "ground_truth": "       ",
    "prediction": "        ",
    "index": 1641
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1642.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 1642
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1643.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 1643
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1644.wav",
    "ground_truth": "          ",
    "prediction": "          ",
    "index": 1644
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1645.wav",
    "ground_truth": "       ",
    "prediction": "        ",
    "index": 1645
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1646.wav",
    "ground_truth": "              ",
    "prediction": "              ",
    "index": 1646
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1647.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 1647
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1648.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 1648
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1649.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 1649
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1650.wav",
    "ground_truth": "           ",
    "prediction": "   <0xE0><0xB2><0x94>         ",
    "index": 1650
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1651.wav",
    "ground_truth": "           ",
    "prediction": "            ",
    "index": 1651
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1652.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 1652
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1653.wav",
    "ground_truth": "           ",
    "prediction": "            ",
    "index": 1653
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1654.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 1654
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1655.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 1655
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1656.wav",
    "ground_truth": "       ",
    "prediction": "        ",
    "index": 1656
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1657.wav",
    "ground_truth": "         ",
    "prediction": "         ",
    "index": 1657
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1658.wav",
    "ground_truth": "            ",
    "prediction": "             ",
    "index": 1658
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1659.wav",
    "ground_truth": "         ",
    "prediction": "         ",
    "index": 1659
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1660.wav",
    "ground_truth": "         ",
    "prediction": "            ",
    "index": 1660
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1661.wav",
    "ground_truth": "         ",
    "prediction": "            ",
    "index": 1661
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1662.wav",
    "ground_truth": "           ",
    "prediction": "             ",
    "index": 1662
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1663.wav",
    "ground_truth": "             ",
    "prediction": "               ",
    "index": 1663
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1664.wav",
    "ground_truth": "       ",
    "prediction": "        ",
    "index": 1664
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1665.wav",
    "ground_truth": "       ",
    "prediction": "        ",
    "index": 1665
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1666.wav",
    "ground_truth": "        ",
    "prediction": "        ",
    "index": 1666
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1667.wav",
    "ground_truth": "        ",
    "prediction": "        ",
    "index": 1667
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1668.wav",
    "ground_truth": "             ",
    "prediction": "             ",
    "index": 1668
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1669.wav",
    "ground_truth": "       ",
    "prediction": "         ",
    "index": 1669
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1670.wav",
    "ground_truth": "         ",
    "prediction": "           ",
    "index": 1670
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1671.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 1671
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1672.wav",
    "ground_truth": "       ",
    "prediction": "        ",
    "index": 1672
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1673.wav",
    "ground_truth": "           ",
    "prediction": "             ",
    "index": 1673
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1674.wav",
    "ground_truth": "           ",
    "prediction": "            ",
    "index": 1674
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1675.wav",
    "ground_truth": "           ",
    "prediction": "             ",
    "index": 1675
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1676.wav",
    "ground_truth": "       ",
    "prediction": "        ",
    "index": 1676
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1677.wav",
    "ground_truth": "          ",
    "prediction": "            ",
    "index": 1677
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1678.wav",
    "ground_truth": "        ",
    "prediction": "           ",
    "index": 1678
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1679.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 1679
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1680.wav",
    "ground_truth": "             ",
    "prediction": "              ",
    "index": 1680
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1681.wav",
    "ground_truth": "        ",
    "prediction": "          ",
    "index": 1681
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1682.wav",
    "ground_truth": "             ",
    "prediction": "                ",
    "index": 1682
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1683.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 1683
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1684.wav",
    "ground_truth": "       ",
    "prediction": "        ",
    "index": 1684
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1685.wav",
    "ground_truth": "           ",
    "prediction": "           ",
    "index": 1685
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1686.wav",
    "ground_truth": "              ",
    "prediction": "               ",
    "index": 1686
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1687.wav",
    "ground_truth": "        ",
    "prediction": "   <0xE0><0xB2><0xA2>      ",
    "index": 1687
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1688.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 1688
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1689.wav",
    "ground_truth": "              ",
    "prediction": "              ",
    "index": 1689
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1690.wav",
    "ground_truth": "        ",
    "prediction": "          ",
    "index": 1690
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1691.wav",
    "ground_truth": "       ",
    "prediction": "         ",
    "index": 1691
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1692.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 1692
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1693.wav",
    "ground_truth": "           ",
    "prediction": "            ",
    "index": 1693
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1694.wav",
    "ground_truth": "           ",
    "prediction": "            ",
    "index": 1694
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1695.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 1695
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1696.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 1696
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1697.wav",
    "ground_truth": "       ",
    "prediction": "        ",
    "index": 1697
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1698.wav",
    "ground_truth": "       ",
    "prediction": "        ",
    "index": 1698
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1699.wav",
    "ground_truth": "       ",
    "prediction": "        ",
    "index": 1699
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1700.wav",
    "ground_truth": "            ",
    "prediction": "             ",
    "index": 1700
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1701.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 1701
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1702.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 1702
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1703.wav",
    "ground_truth": "           ",
    "prediction": "           ",
    "index": 1703
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1704.wav",
    "ground_truth": "              ",
    "prediction": "             ",
    "index": 1704
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1705.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 1705
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1706.wav",
    "ground_truth": "             ",
    "prediction": "              ",
    "index": 1706
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1707.wav",
    "ground_truth": "       ",
    "prediction": "        ",
    "index": 1707
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1708.wav",
    "ground_truth": "           ",
    "prediction": "            ",
    "index": 1708
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1709.wav",
    "ground_truth": "       ",
    "prediction": "        ",
    "index": 1709
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1710.wav",
    "ground_truth": "       ",
    "prediction": "       ",
    "index": 1710
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1711.wav",
    "ground_truth": "         ",
    "prediction": "            ",
    "index": 1711
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1712.wav",
    "ground_truth": "            ",
    "prediction": "            ",
    "index": 1712
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1713.wav",
    "ground_truth": "        ",
    "prediction": "          ",
    "index": 1713
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1714.wav",
    "ground_truth": "       ",
    "prediction": "        ",
    "index": 1714
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1715.wav",
    "ground_truth": "           ",
    "prediction": "    <0xE0><0xB2><0x9D>        ",
    "index": 1715
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1716.wav",
    "ground_truth": "       ",
    "prediction": "       ",
    "index": 1716
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1717.wav",
    "ground_truth": "            ",
    "prediction": "             ",
    "index": 1717
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1718.wav",
    "ground_truth": "            ",
    "prediction": "            ",
    "index": 1718
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1719.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 1719
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1720.wav",
    "ground_truth": "              ",
    "prediction": "              ",
    "index": 1720
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1721.wav",
    "ground_truth": "            ",
    "prediction": "             ",
    "index": 1721
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1722.wav",
    "ground_truth": "           ",
    "prediction": "             ",
    "index": 1722
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1723.wav",
    "ground_truth": "             ",
    "prediction": "              ",
    "index": 1723
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1724.wav",
    "ground_truth": "       ",
    "prediction": "       ",
    "index": 1724
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1725.wav",
    "ground_truth": "       ",
    "prediction": "        ",
    "index": 1725
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1726.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 1726
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1727.wav",
    "ground_truth": "            ",
    "prediction": "            ",
    "index": 1727
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1728.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 1728
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1729.wav",
    "ground_truth": "       ",
    "prediction": "         ",
    "index": 1729
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1730.wav",
    "ground_truth": "          ",
    "prediction": "            ",
    "index": 1730
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1731.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 1731
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1732.wav",
    "ground_truth": "       ",
    "prediction": "    <0xE0><0xB2><0x8A>    ",
    "index": 1732
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1733.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 1733
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1734.wav",
    "ground_truth": "            ",
    "prediction": "             ",
    "index": 1734
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1735.wav",
    "ground_truth": "           ",
    "prediction": "             ",
    "index": 1735
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1736.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 1736
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1737.wav",
    "ground_truth": "       ",
    "prediction": "       ",
    "index": 1737
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1738.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 1738
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1739.wav",
    "ground_truth": "        ",
    "prediction": "        ",
    "index": 1739
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1740.wav",
    "ground_truth": "             ",
    "prediction": "                ",
    "index": 1740
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1741.wav",
    "ground_truth": "             ",
    "prediction": "              ",
    "index": 1741
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1742.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 1742
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1743.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 1743
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1744.wav",
    "ground_truth": "             ",
    "prediction": "               ",
    "index": 1744
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1745.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 1745
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1746.wav",
    "ground_truth": "             ",
    "prediction": "             ",
    "index": 1746
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1747.wav",
    "ground_truth": "            ",
    "prediction": "            ",
    "index": 1747
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1748.wav",
    "ground_truth": "        ",
    "prediction": "          ",
    "index": 1748
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1749.wav",
    "ground_truth": "              ",
    "prediction": "              ",
    "index": 1749
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1750.wav",
    "ground_truth": "           ",
    "prediction": "           ",
    "index": 1750
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1751.wav",
    "ground_truth": "       ",
    "prediction": "        ",
    "index": 1751
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1752.wav",
    "ground_truth": "              ",
    "prediction": "              ",
    "index": 1752
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1753.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 1753
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1754.wav",
    "ground_truth": "              ",
    "prediction": "               ",
    "index": 1754
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1755.wav",
    "ground_truth": "       ",
    "prediction": "         ",
    "index": 1755
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1756.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 1756
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1757.wav",
    "ground_truth": "             ",
    "prediction": "             ",
    "index": 1757
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1758.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 1758
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1759.wav",
    "ground_truth": "        ",
    "prediction": "          ",
    "index": 1759
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1760.wav",
    "ground_truth": "       ",
    "prediction": "        ",
    "index": 1760
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1761.wav",
    "ground_truth": "            ",
    "prediction": "             ",
    "index": 1761
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1762.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 1762
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1763.wav",
    "ground_truth": "       ",
    "prediction": "        ",
    "index": 1763
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1764.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 1764
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1765.wav",
    "ground_truth": "           ",
    "prediction": "             ",
    "index": 1765
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1766.wav",
    "ground_truth": "          ",
    "prediction": "             ",
    "index": 1766
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1767.wav",
    "ground_truth": "            ",
    "prediction": "             ",
    "index": 1767
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1768.wav",
    "ground_truth": "             ",
    "prediction": "              ",
    "index": 1768
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1769.wav",
    "ground_truth": "              ",
    "prediction": "                ",
    "index": 1769
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1770.wav",
    "ground_truth": "       ",
    "prediction": "       ",
    "index": 1770
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1771.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 1771
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1772.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 1772
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1773.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 1773
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1774.wav",
    "ground_truth": "             ",
    "prediction": "              ",
    "index": 1774
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1775.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 1775
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1776.wav",
    "ground_truth": "             ",
    "prediction": "             ",
    "index": 1776
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1777.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 1777
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1778.wav",
    "ground_truth": "       ",
    "prediction": "        ",
    "index": 1778
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1779.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 1779
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1780.wav",
    "ground_truth": "       ",
    "prediction": "        ",
    "index": 1780
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1781.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 1781
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1782.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 1782
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1783.wav",
    "ground_truth": "          ",
    "prediction": "            ",
    "index": 1783
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1784.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 1784
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1785.wav",
    "ground_truth": "             ",
    "prediction": "               ",
    "index": 1785
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1786.wav",
    "ground_truth": "       ",
    "prediction": "        ",
    "index": 1786
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1787.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 1787
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1788.wav",
    "ground_truth": "             ",
    "prediction": "            ",
    "index": 1788
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1789.wav",
    "ground_truth": "            ",
    "prediction": "             ",
    "index": 1789
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1790.wav",
    "ground_truth": "       ",
    "prediction": "   <0xE0><0xB2><0x8A>     ",
    "index": 1790
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1791.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 1791
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1792.wav",
    "ground_truth": "             ",
    "prediction": "             ",
    "index": 1792
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1793.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 1793
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1794.wav",
    "ground_truth": "           ",
    "prediction": "             ",
    "index": 1794
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1795.wav",
    "ground_truth": "       ",
    "prediction": "         ",
    "index": 1795
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1796.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 1796
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1797.wav",
    "ground_truth": "           ",
    "prediction": "            ",
    "index": 1797
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1798.wav",
    "ground_truth": "             ",
    "prediction": "              ",
    "index": 1798
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1799.wav",
    "ground_truth": "              ",
    "prediction": "                ",
    "index": 1799
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1800.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 1800
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1801.wav",
    "ground_truth": "       ",
    "prediction": "        ",
    "index": 1801
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1802.wav",
    "ground_truth": "       ",
    "prediction": "        ",
    "index": 1802
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1803.wav",
    "ground_truth": "          ",
    "prediction": "            ",
    "index": 1803
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1804.wav",
    "ground_truth": "       ",
    "prediction": "        ",
    "index": 1804
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1805.wav",
    "ground_truth": "       ",
    "prediction": "        ",
    "index": 1805
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1806.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 1806
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1807.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 1807
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1808.wav",
    "ground_truth": "         ",
    "prediction": "        ",
    "index": 1808
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1809.wav",
    "ground_truth": "       ",
    "prediction": "        ",
    "index": 1809
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1810.wav",
    "ground_truth": "             ",
    "prediction": "              ",
    "index": 1810
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1811.wav",
    "ground_truth": "           ",
    "prediction": "            ",
    "index": 1811
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1812.wav",
    "ground_truth": "            ",
    "prediction": "             ",
    "index": 1812
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1813.wav",
    "ground_truth": "        ",
    "prediction": "       ",
    "index": 1813
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1814.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 1814
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1815.wav",
    "ground_truth": "             ",
    "prediction": "            ",
    "index": 1815
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1816.wav",
    "ground_truth": "       ",
    "prediction": "        ",
    "index": 1816
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1817.wav",
    "ground_truth": "           ",
    "prediction": "            ",
    "index": 1817
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1818.wav",
    "ground_truth": "           ",
    "prediction": "           ",
    "index": 1818
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1819.wav",
    "ground_truth": "          ",
    "prediction": "          ",
    "index": 1819
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1820.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 1820
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1821.wav",
    "ground_truth": "         ",
    "prediction": "           ",
    "index": 1821
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1822.wav",
    "ground_truth": "           ",
    "prediction": "          ",
    "index": 1822
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1823.wav",
    "ground_truth": "           ",
    "prediction": "            ",
    "index": 1823
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1824.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 1824
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1825.wav",
    "ground_truth": "          ",
    "prediction": "             ",
    "index": 1825
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1826.wav",
    "ground_truth": "       ",
    "prediction": "        ",
    "index": 1826
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1827.wav",
    "ground_truth": "           ",
    "prediction": "             ",
    "index": 1827
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1828.wav",
    "ground_truth": "         ",
    "prediction": "           ",
    "index": 1828
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1829.wav",
    "ground_truth": "          ",
    "prediction": "            ",
    "index": 1829
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1830.wav",
    "ground_truth": "       ",
    "prediction": "        ",
    "index": 1830
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1831.wav",
    "ground_truth": "           ",
    "prediction": "            ",
    "index": 1831
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1832.wav",
    "ground_truth": "       ",
    "prediction": "        ",
    "index": 1832
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1833.wav",
    "ground_truth": "       ",
    "prediction": "        ",
    "index": 1833
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1834.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 1834
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1835.wav",
    "ground_truth": "       ",
    "prediction": "       ",
    "index": 1835
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1836.wav",
    "ground_truth": "        ",
    "prediction": "        ",
    "index": 1836
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1837.wav",
    "ground_truth": "         ",
    "prediction": "           ",
    "index": 1837
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1838.wav",
    "ground_truth": "        ",
    "prediction": "          ",
    "index": 1838
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1839.wav",
    "ground_truth": "           ",
    "prediction": "            ",
    "index": 1839
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1840.wav",
    "ground_truth": "            ",
    "prediction": "             ",
    "index": 1840
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1841.wav",
    "ground_truth": "           ",
    "prediction": "            ",
    "index": 1841
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1842.wav",
    "ground_truth": "              ",
    "prediction": "               ",
    "index": 1842
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1843.wav",
    "ground_truth": "            ",
    "prediction": "             ",
    "index": 1843
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1844.wav",
    "ground_truth": "         ",
    "prediction": "           ",
    "index": 1844
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1845.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 1845
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1846.wav",
    "ground_truth": "           ",
    "prediction": "          ",
    "index": 1846
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1847.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 1847
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1848.wav",
    "ground_truth": "       ",
    "prediction": "        ",
    "index": 1848
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1849.wav",
    "ground_truth": "          ",
    "prediction": "          ",
    "index": 1849
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1850.wav",
    "ground_truth": "       ",
    "prediction": "        ",
    "index": 1850
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1851.wav",
    "ground_truth": "       ",
    "prediction": "        ",
    "index": 1851
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1852.wav",
    "ground_truth": "           ",
    "prediction": "            ",
    "index": 1852
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1853.wav",
    "ground_truth": "            ",
    "prediction": "             ",
    "index": 1853
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1854.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 1854
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1855.wav",
    "ground_truth": "       ",
    "prediction": "          ",
    "index": 1855
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1856.wav",
    "ground_truth": "           ",
    "prediction": "            ",
    "index": 1856
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1857.wav",
    "ground_truth": "             ",
    "prediction": "              ",
    "index": 1857
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1858.wav",
    "ground_truth": "           ",
    "prediction": "            ",
    "index": 1858
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1859.wav",
    "ground_truth": "        ",
    "prediction": "        ",
    "index": 1859
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1860.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 1860
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1861.wav",
    "ground_truth": "       ",
    "prediction": "        ",
    "index": 1861
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1862.wav",
    "ground_truth": "       ",
    "prediction": "        ",
    "index": 1862
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1863.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 1863
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1864.wav",
    "ground_truth": "       ",
    "prediction": "         ",
    "index": 1864
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1865.wav",
    "ground_truth": "          ",
    "prediction": "          ",
    "index": 1865
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1866.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 1866
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1867.wav",
    "ground_truth": "       ",
    "prediction": "        ",
    "index": 1867
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1868.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 1868
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1869.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 1869
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1870.wav",
    "ground_truth": "          ",
    "prediction": "            ",
    "index": 1870
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1871.wav",
    "ground_truth": "         ",
    "prediction": "         ",
    "index": 1871
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1872.wav",
    "ground_truth": "           ",
    "prediction": "             ",
    "index": 1872
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1873.wav",
    "ground_truth": "          ",
    "prediction": "          ",
    "index": 1873
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1874.wav",
    "ground_truth": "       ",
    "prediction": "        ",
    "index": 1874
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1875.wav",
    "ground_truth": "              ",
    "prediction": "               ",
    "index": 1875
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1876.wav",
    "ground_truth": "           ",
    "prediction": "            ",
    "index": 1876
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1877.wav",
    "ground_truth": "           ",
    "prediction": "           ",
    "index": 1877
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1878.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 1878
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1879.wav",
    "ground_truth": "             ",
    "prediction": "              ",
    "index": 1879
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1880.wav",
    "ground_truth": "        ",
    "prediction": "          ",
    "index": 1880
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1881.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 1881
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1882.wav",
    "ground_truth": "       ",
    "prediction": "         ",
    "index": 1882
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1883.wav",
    "ground_truth": "       ",
    "prediction": "         ",
    "index": 1883
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1884.wav",
    "ground_truth": "             ",
    "prediction": "              ",
    "index": 1884
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1885.wav",
    "ground_truth": "             ",
    "prediction": "             ",
    "index": 1885
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1886.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 1886
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1887.wav",
    "ground_truth": "            ",
    "prediction": "             ",
    "index": 1887
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1888.wav",
    "ground_truth": "       ",
    "prediction": "           ",
    "index": 1888
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1889.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 1889
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1890.wav",
    "ground_truth": "       ",
    "prediction": "        ",
    "index": 1890
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1891.wav",
    "ground_truth": "             ",
    "prediction": "              ",
    "index": 1891
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1892.wav",
    "ground_truth": "           ",
    "prediction": "                 ",
    "index": 1892
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1893.wav",
    "ground_truth": "           ",
    "prediction": "             ",
    "index": 1893
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1894.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 1894
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1895.wav",
    "ground_truth": "              ",
    "prediction": "               ",
    "index": 1895
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1896.wav",
    "ground_truth": "         ",
    "prediction": "            ",
    "index": 1896
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1897.wav",
    "ground_truth": "          ",
    "prediction": "            ",
    "index": 1897
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1898.wav",
    "ground_truth": "         ",
    "prediction": "         ",
    "index": 1898
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1899.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 1899
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1900.wav",
    "ground_truth": "         ",
    "prediction": "           ",
    "index": 1900
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1901.wav",
    "ground_truth": "            ",
    "prediction": "               ",
    "index": 1901
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1902.wav",
    "ground_truth": "              ",
    "prediction": "              ",
    "index": 1902
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1903.wav",
    "ground_truth": "              ",
    "prediction": "               ",
    "index": 1903
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1904.wav",
    "ground_truth": "            ",
    "prediction": "              ",
    "index": 1904
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1905.wav",
    "ground_truth": "            ",
    "prediction": "            ",
    "index": 1905
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1906.wav",
    "ground_truth": "              ",
    "prediction": "              ",
    "index": 1906
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1907.wav",
    "ground_truth": "            ",
    "prediction": "            ",
    "index": 1907
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1908.wav",
    "ground_truth": "       ",
    "prediction": "         ",
    "index": 1908
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1909.wav",
    "ground_truth": "       ",
    "prediction": "        ",
    "index": 1909
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1910.wav",
    "ground_truth": "            ",
    "prediction": "             ",
    "index": 1910
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1911.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 1911
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1912.wav",
    "ground_truth": "       ",
    "prediction": "        ",
    "index": 1912
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1913.wav",
    "ground_truth": "       ",
    "prediction": "        ",
    "index": 1913
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1914.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 1914
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1915.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 1915
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1916.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 1916
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1917.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 1917
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1918.wav",
    "ground_truth": "             ",
    "prediction": " <0xE0><0xB2><0xA2>             ",
    "index": 1918
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1919.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 1919
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1920.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 1920
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1921.wav",
    "ground_truth": "         ",
    "prediction": "         ",
    "index": 1921
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1922.wav",
    "ground_truth": "           ",
    "prediction": "            ",
    "index": 1922
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1923.wav",
    "ground_truth": "        ",
    "prediction": "           ",
    "index": 1923
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1924.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 1924
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1925.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 1925
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1926.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 1926
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1927.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 1927
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1928.wav",
    "ground_truth": "          ",
    "prediction": "          ",
    "index": 1928
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1929.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 1929
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1930.wav",
    "ground_truth": "       ",
    "prediction": "        ",
    "index": 1930
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1931.wav",
    "ground_truth": "             ",
    "prediction": "              ",
    "index": 1931
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1932.wav",
    "ground_truth": "           ",
    "prediction": "            ",
    "index": 1932
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1933.wav",
    "ground_truth": "            ",
    "prediction": "            ",
    "index": 1933
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1934.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 1934
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1935.wav",
    "ground_truth": "            ",
    "prediction": "             ",
    "index": 1935
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1936.wav",
    "ground_truth": "       ",
    "prediction": "        ",
    "index": 1936
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1937.wav",
    "ground_truth": "             ",
    "prediction": "            ",
    "index": 1937
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1938.wav",
    "ground_truth": "       ",
    "prediction": "       ",
    "index": 1938
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1939.wav",
    "ground_truth": "       ",
    "prediction": "        ",
    "index": 1939
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1940.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 1940
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1941.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 1941
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1942.wav",
    "ground_truth": "       ",
    "prediction": "        ",
    "index": 1942
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1943.wav",
    "ground_truth": "       ",
    "prediction": "        ",
    "index": 1943
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1944.wav",
    "ground_truth": "           ",
    "prediction": "            ",
    "index": 1944
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1945.wav",
    "ground_truth": "              ",
    "prediction": "               ",
    "index": 1945
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1946.wav",
    "ground_truth": "       ",
    "prediction": "        ",
    "index": 1946
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1947.wav",
    "ground_truth": "         ",
    "prediction": "           ",
    "index": 1947
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1948.wav",
    "ground_truth": "           ",
    "prediction": "            ",
    "index": 1948
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1949.wav",
    "ground_truth": "              ",
    "prediction": "               ",
    "index": 1949
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1950.wav",
    "ground_truth": "       ",
    "prediction": "        ",
    "index": 1950
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1951.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 1951
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1952.wav",
    "ground_truth": "           ",
    "prediction": "            ",
    "index": 1952
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1953.wav",
    "ground_truth": "       ",
    "prediction": "        ",
    "index": 1953
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1954.wav",
    "ground_truth": "        ",
    "prediction": "        ",
    "index": 1954
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1955.wav",
    "ground_truth": "              ",
    "prediction": "                ",
    "index": 1955
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1956.wav",
    "ground_truth": "           ",
    "prediction": "             ",
    "index": 1956
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1957.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 1957
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1958.wav",
    "ground_truth": "          ",
    "prediction": "          ",
    "index": 1958
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1959.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 1959
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1960.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 1960
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1961.wav",
    "ground_truth": "           ",
    "prediction": "            ",
    "index": 1961
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1962.wav",
    "ground_truth": "       ",
    "prediction": "        ",
    "index": 1962
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1963.wav",
    "ground_truth": "          ",
    "prediction": "          ",
    "index": 1963
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1964.wav",
    "ground_truth": "           ",
    "prediction": "            ",
    "index": 1964
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1965.wav",
    "ground_truth": "        ",
    "prediction": "          ",
    "index": 1965
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1966.wav",
    "ground_truth": "       ",
    "prediction": "        ",
    "index": 1966
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1967.wav",
    "ground_truth": "       ",
    "prediction": "         ",
    "index": 1967
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1968.wav",
    "ground_truth": "       ",
    "prediction": "        ",
    "index": 1968
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1969.wav",
    "ground_truth": "             ",
    "prediction": "              ",
    "index": 1969
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1970.wav",
    "ground_truth": "         ",
    "prediction": "         ",
    "index": 1970
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1971.wav",
    "ground_truth": "        ",
    "prediction": "          ",
    "index": 1971
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1972.wav",
    "ground_truth": "         ",
    "prediction": "        <0xE0><0xB2><0x94>  ",
    "index": 1972
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1973.wav",
    "ground_truth": "          ",
    "prediction": "       ",
    "index": 1973
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1974.wav",
    "ground_truth": "              ",
    "prediction": "           ",
    "index": 1974
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1975.wav",
    "ground_truth": "            ",
    "prediction": "             ",
    "index": 1975
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1976.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 1976
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1977.wav",
    "ground_truth": "             ",
    "prediction": "              ",
    "index": 1977
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1978.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 1978
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1979.wav",
    "ground_truth": "       ",
    "prediction": "        ",
    "index": 1979
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1980.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 1980
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1981.wav",
    "ground_truth": "        ",
    "prediction": "            ",
    "index": 1981
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1982.wav",
    "ground_truth": "              ",
    "prediction": "               ",
    "index": 1982
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1983.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 1983
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1984.wav",
    "ground_truth": "            ",
    "prediction": "             ",
    "index": 1984
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1985.wav",
    "ground_truth": "       ",
    "prediction": "        ",
    "index": 1985
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1986.wav",
    "ground_truth": "           ",
    "prediction": "           ",
    "index": 1986
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1987.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 1987
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1988.wav",
    "ground_truth": "       ",
    "prediction": "        ",
    "index": 1988
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1989.wav",
    "ground_truth": "       ",
    "prediction": "         ",
    "index": 1989
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1990.wav",
    "ground_truth": "       ",
    "prediction": "        ",
    "index": 1990
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1991.wav",
    "ground_truth": "           ",
    "prediction": "            ",
    "index": 1991
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1992.wav",
    "ground_truth": "             ",
    "prediction": "           <0xE0><0xB2><0x8B>  ",
    "index": 1992
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1993.wav",
    "ground_truth": "       ",
    "prediction": "         ",
    "index": 1993
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1994.wav",
    "ground_truth": "             ",
    "prediction": "              ",
    "index": 1994
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1995.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 1995
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1996.wav",
    "ground_truth": "             ",
    "prediction": "                 ",
    "index": 1996
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1997.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 1997
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1998.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 1998
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_1999.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 1999
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_2000.wav",
    "ground_truth": "             ",
    "prediction": "                 ",
    "index": 2000
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_2001.wav",
    "ground_truth": "       ",
    "prediction": "         ",
    "index": 2001
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_2002.wav",
    "ground_truth": "           ",
    "prediction": "            ",
    "index": 2002
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_2003.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 2003
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_2004.wav",
    "ground_truth": "            ",
    "prediction": "             ",
    "index": 2004
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_2005.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 2005
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_2006.wav",
    "ground_truth": "             ",
    "prediction": "              ",
    "index": 2006
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_2007.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 2007
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_2008.wav",
    "ground_truth": "       ",
    "prediction": "        ",
    "index": 2008
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_2009.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 2009
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_2010.wav",
    "ground_truth": "       ",
    "prediction": "        ",
    "index": 2010
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_2011.wav",
    "ground_truth": "           ",
    "prediction": "            ",
    "index": 2011
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_2012.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 2012
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_2013.wav",
    "ground_truth": "        ",
    "prediction": "          ",
    "index": 2013
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_2014.wav",
    "ground_truth": "            ",
    "prediction": "             ",
    "index": 2014
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_2015.wav",
    "ground_truth": "           ",
    "prediction": "           ",
    "index": 2015
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_2016.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 2016
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_2017.wav",
    "ground_truth": "              ",
    "prediction": "              ",
    "index": 2017
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_2018.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 2018
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_2019.wav",
    "ground_truth": "             ",
    "prediction": "              ",
    "index": 2019
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_2020.wav",
    "ground_truth": "            ",
    "prediction": "              ",
    "index": 2020
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_2021.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 2021
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_2022.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 2022
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_2023.wav",
    "ground_truth": "            ",
    "prediction": "              ",
    "index": 2023
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_2024.wav",
    "ground_truth": "              ",
    "prediction": "               ",
    "index": 2024
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_2025.wav",
    "ground_truth": "             ",
    "prediction": "              ",
    "index": 2025
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_2026.wav",
    "ground_truth": "            ",
    "prediction": "            ",
    "index": 2026
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_2027.wav",
    "ground_truth": "       ",
    "prediction": "         ",
    "index": 2027
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_2028.wav",
    "ground_truth": "       ",
    "prediction": "        ",
    "index": 2028
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_2029.wav",
    "ground_truth": "           ",
    "prediction": "              ",
    "index": 2029
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_2030.wav",
    "ground_truth": "       ",
    "prediction": "        ",
    "index": 2030
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_2031.wav",
    "ground_truth": "            ",
    "prediction": "           ",
    "index": 2031
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_2032.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 2032
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_2033.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 2033
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_2034.wav",
    "ground_truth": "         ",
    "prediction": "          ",
    "index": 2034
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_2035.wav",
    "ground_truth": "           ",
    "prediction": "             ",
    "index": 2035
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_2036.wav",
    "ground_truth": "            ",
    "prediction": "             ",
    "index": 2036
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_2037.wav",
    "ground_truth": "        ",
    "prediction": "           ",
    "index": 2037
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_2038.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 2038
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_2039.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 2039
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_2040.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 2040
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_2041.wav",
    "ground_truth": "          ",
    "prediction": "            ",
    "index": 2041
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_2042.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 2042
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_2043.wav",
    "ground_truth": "              ",
    "prediction": "               ",
    "index": 2043
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_2044.wav",
    "ground_truth": "          ",
    "prediction": "           ",
    "index": 2044
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_2045.wav",
    "ground_truth": "       ",
    "prediction": "        ",
    "index": 2045
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_2046.wav",
    "ground_truth": "           ",
    "prediction": "            ",
    "index": 2046
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_2047.wav",
    "ground_truth": "       ",
    "prediction": "        ",
    "index": 2047
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_2048.wav",
    "ground_truth": "         ",
    "prediction": "          <0xE0><0xB2><0xA2>",
    "index": 2048
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_2049.wav",
    "ground_truth": "       ",
    "prediction": "        ",
    "index": 2049
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_2050.wav",
    "ground_truth": "          ",
    "prediction": "          ",
    "index": 2050
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_2051.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 2051
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_2052.wav",
    "ground_truth": "       ",
    "prediction": "        ",
    "index": 2052
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_2053.wav",
    "ground_truth": "            ",
    "prediction": "             ",
    "index": 2053
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_2054.wav",
    "ground_truth": "        ",
    "prediction": "          ",
    "index": 2054
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_2055.wav",
    "ground_truth": "            ",
    "prediction": "             ",
    "index": 2055
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_2056.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 2056
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_2057.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 2057
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_2058.wav",
    "ground_truth": "          ",
    "prediction": "          ",
    "index": 2058
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_2059.wav",
    "ground_truth": "        ",
    "prediction": "          ",
    "index": 2059
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_2060.wav",
    "ground_truth": "        ",
    "prediction": "         ",
    "index": 2060
  },
  {
    "audio_filepath": "/mnt/data/asr-finetuning/evaluation/benchmarking/curation/test_data/Kathbath/wavs/Kathbath_2061.wav",
    "ground_truth": "       ",
    "prediction": "        ",
    "index": 2061
  }
](asr-env) root@h200-nvl-2x:/mnt/data/asr-finetuning# 
