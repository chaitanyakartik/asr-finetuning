import os
import json
import re
import soundfile as sf
from datasets import load_dataset, Audio
from dotenv import load_dotenv

# --- CONFIGURATION ---
DATASET_NAME = "Vaani"
HF_DATASET_ID = "ARTPARK-IISc/Vaani-transcription-part"
HF_CONFIG = "Kannada"  # Verified in your simulation
N_SAMPLES = 50         # Set to -1 for full download
OUTPUT_DIR = "/Users/chaitanyakartik/Projects/asr-finetuning/evaluation/benchmarking/data/v2/Vaani"
WAV_DIR = os.path.join(OUTPUT_DIR, "wavs")

# Ensure directories exist
os.makedirs(WAV_DIR, exist_ok=True)

def clean_text(text):
    """Remove noise tags and English translations wrapped in {}"""
    # Remove only the tags themselves, keep the content inside
    text = re.sub(r'<[^>]+>', '', text)
    
    # Remove English words wrapped in {} like {chair}, {picture}, etc.
    text = re.sub(r'\s*\{[^}]+\}', '', text)
    
    # Clean up multiple spaces
    text = re.sub(r'\s+', ' ', text)
    
    return text.strip()

def run_vaani_pipeline():
    print(f"--- üöÄ Starting Pipeline: {DATASET_NAME} ---")

    # 1. SETUP & AUTH
    load_dotenv()
    hf_token = os.getenv("HF_TOKEN")
    if not hf_token:
        print("‚ùå Error: HF_TOKEN not found in .env file.")
        return

    try:
        # 2. STREAMING INGESTION
        print(f"   üì° Connecting to Hugging Face ({HF_DATASET_ID})...")
        ds = load_dataset(
            HF_DATASET_ID, 
            HF_CONFIG, 
            split="test", 
            streaming=True, 
            token=hf_token
        )
        
        # --- CRITICAL STEP ---
        # Vaani uses 'audio' as the key. We cast it to ensure 16kHz.
        ds = ds.cast_column("audio", Audio(sampling_rate=16000))
        
        manifest_entries = []
        raw_metadata = []

        print(f"   ‚¨áÔ∏è  Streaming & Processing first {N_SAMPLES} samples...")

        for i, item in enumerate(ds):
            # Stop condition
            if N_SAMPLES != -1 and i >= N_SAMPLES:
                break

            # --- A. INSPECTION (First Item Only) ---
            if i == 0:
                print(f"\n   üëÄ [INSPECTION] Keys: {list(item.keys())}")
                print(f"   üëÄ [INSPECTION] Audio Data: {type(item['audio'])}")
                print(f"   üëÄ [INSPECTION] Text: {item.get('transcript', 'No Text')[:50]}...\n")

            # --- B. EXTRACT DATA ---
            # Access 'audio' dictionary
            audio_data_dict = item['audio']
            
            audio_array = audio_data_dict['array']
            sr = audio_data_dict['sampling_rate']
            
            # Vaani uses 'transcript' for the text
            text = item.get('transcript', "")
            
            # Clean the text: remove noise tags and English translations
            text = clean_text(text)
            
            # --- C. SAVE AUDIO ---
            filename = f"{DATASET_NAME}_{i}.wav"
            file_path = os.path.join(WAV_DIR, filename)
            abs_path = os.path.abspath(file_path)
            
            sf.write(file_path, audio_array, sr)

            # --- D. METADATA COLLECTION ---
            raw_metadata.append({
                "original_index": i,
                "filename": filename,
                "sr": sr,
                "district": item.get('district', 'unknown'),
                "gender": item.get('gender', 'unknown')
            })

            # NeMo Manifest Entry
            duration = len(audio_array) / sr
            
            manifest_entry = {
                "audio_filepath": abs_path,
                "text": text,
                "duration": duration,
                "lang": "kn",
                "source": "vaani_dialect"
            }
            manifest_entries.append(manifest_entry)

        # --- E. SAVE FILES ---
        meta_path = os.path.join(OUTPUT_DIR, "raw_metadata.json")
        with open(meta_path, "w", encoding="utf-8") as f:
            json.dump(raw_metadata, f, indent=4, ensure_ascii=False)

        manifest_path = os.path.join(OUTPUT_DIR, "train_manifest.json")
        with open(manifest_path, "w", encoding="utf-8") as f:
            for entry in manifest_entries:
                json.dump(entry, f, ensure_ascii=False)
                f.write('\n')

        print(f"\n‚úÖ Pipeline Complete!")
        print(f"   üìÇ Audio: {WAV_DIR}")
        print(f"   üìÑ Manifest: {manifest_path}")
        print(f"   üìä Processed: {len(manifest_entries)} items")

    except Exception as e:
        print(f"\n‚ùå Pipeline Failed: {e}")

if __name__ == "__main__":
    run_vaani_pipeline()