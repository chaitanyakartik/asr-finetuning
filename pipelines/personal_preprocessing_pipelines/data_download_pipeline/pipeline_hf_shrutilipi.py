import os
import json
import soundfile as sf
from datasets import load_dataset, Audio
from dotenv import load_dotenv

# --- CONFIGURATION ---
DATASET_NAME = "Shrutilipi"
HF_DATASET_ID = "ai4bharat/Shrutilipi"
HF_CONFIG = "kannada"

### Set to -1 for full download
N_SAMPLES = 10  
OUTPUT_DIR = "processed_data/Shrutilipi"
WAV_DIR = os.path.join(OUTPUT_DIR, "wavs")

# Ensure directories exist
os.makedirs(WAV_DIR, exist_ok=True)

def run_shrutilipi_pipeline():
    print(f"--- ğŸš€ Starting Pipeline: {DATASET_NAME} ---")

    # 1. SETUP & AUTH
    load_dotenv()
    hf_token = os.getenv("HF_TOKEN")
    if not hf_token:
        print("âŒ Error: HF_TOKEN not found in .env file.")
        return

    try:
        # 2. STREAMING INGESTION
        print(f"   ğŸ“¡ Connecting to Hugging Face ({HF_DATASET_ID})...")
        ds = load_dataset(
            HF_DATASET_ID, 
            HF_CONFIG, 
            split="train", 
            streaming=True, 
            token=hf_token
        )
        
        # --- CRITICAL FIX ---
        # The dataset has 'audio_filepath' as the key. 
        # We MUST cast it to Audio() so Hugging Face downloads and decodes it for us.
        # We also force 16kHz here to be safe.
        ds = ds.cast_column("audio_filepath", Audio(sampling_rate=16000))
        
        manifest_entries = []
        raw_metadata = []

        print(f"   â¬‡ï¸  Streaming & Processing first {N_SAMPLES} samples...")

        for i, item in enumerate(ds):
            # Stop condition
            if N_SAMPLES != -1 and i >= N_SAMPLES:
                break

            # --- A. INSPECTION (First Item Only) ---
            if i == 0:
                print(f"\n   ğŸ‘€ [INSPECTION] Keys: {list(item.keys())}")
                # Now that we cast it, 'audio_filepath' should be a dict with 'array'
                print(f"   ğŸ‘€ [INSPECTION] Audio Data: {type(item['audio_filepath'])}")
                print(f"   ğŸ‘€ [INSPECTION] Text: {item.get('text', 'No Text')[:50]}...\n")

            # --- B. EXTRACT DATA ---
            # FIX: Access 'audio_filepath' instead of 'audio'
            audio_data_dict = item['audio_filepath']
            
            # The cast_column ensures this dict has 'array' and 'sampling_rate'
            audio_array = audio_data_dict['array']
            sr = audio_data_dict['sampling_rate']
            
            text = item.get('text', "")
            
            # --- C. SAVE AUDIO ---
            filename = f"{DATASET_NAME}_{i}.wav"
            file_path = os.path.join(WAV_DIR, filename)
            abs_path = os.path.abspath(file_path)
            
            sf.write(file_path, audio_array, sr)

            # --- D. METADATA COLLECTION ---
            raw_metadata.append({
                "original_index": i,
                "filename": filename,
                "sr": sr,
                "text_snippet": text[:30]
            })

            # NeMo Manifest Entry
            duration = len(audio_array) / sr
            
            manifest_entry = {
                "audio_filepath": abs_path,
                "text": text,
                "duration": duration,
                "lang": "kn",
                "source": "shrutilipi_news"
            }
            manifest_entries.append(manifest_entry)

        # --- E. SAVE FILES ---
        meta_path = os.path.join(OUTPUT_DIR, "raw_metadata.json")
        with open(meta_path, "w", encoding="utf-8") as f:
            json.dump(raw_metadata, f, indent=4, ensure_ascii=False)

        manifest_path = os.path.join(OUTPUT_DIR, "train_manifest.json")
        with open(manifest_path, "w", encoding="utf-8") as f:
            for entry in manifest_entries:
                json.dump(entry, f, ensure_ascii=False)
                f.write('\n')

        print(f"\nâœ… Pipeline Complete!")
        print(f"   ğŸ“‚ Audio: {WAV_DIR}")
        print(f"   ğŸ“„ Manifest: {manifest_path}")
        print(f"   ğŸ“Š Processed: {len(manifest_entries)} items")

    except Exception as e:
        print(f"\nâŒ Pipeline Failed: {e}")

if __name__ == "__main__":
    run_shrutilipi_pipeline()